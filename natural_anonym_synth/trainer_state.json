{
  "best_metric": 7.572452477407292,
  "best_model_checkpoint": "./outputs/whisper-medium_lr_1e-4_rec_hum_anonym_synth_2025-03-17/checkpoint-3000",
  "epoch": 11.00025,
  "eval_steps": 100,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 3.782177686691284,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 1.9907,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.698542594909668,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 1.9725,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.6965771913528442,
      "learning_rate": 6.000000000000001e-07,
      "loss": 2.0969,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.993401050567627,
      "learning_rate": 8.000000000000001e-07,
      "loss": 1.9569,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.912487983703613,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 2.0249,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.2136101722717285,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 1.9925,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.2732789516448975,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 1.9511,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.688178777694702,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 1.9214,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.789302349090576,
      "learning_rate": 1.8e-06,
      "loss": 2.0602,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.536766290664673,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.045,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1442298889160156,
      "learning_rate": 2.2e-06,
      "loss": 1.9726,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.073307514190674,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 1.9151,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.6767754554748535,
      "learning_rate": 2.6e-06,
      "loss": 2.1048,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7385421991348267,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 1.9638,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.8870387077331543,
      "learning_rate": 3e-06,
      "loss": 1.9404,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.5341761112213135,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 1.9094,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.159894347190857,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 1.9342,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.2314229011535645,
      "learning_rate": 3.6e-06,
      "loss": 1.9172,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.6929357051849365,
      "learning_rate": 3.8e-06,
      "loss": 1.9502,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.1004812717437744,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.0134,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.443497896194458,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 1.8899,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.2900443077087402,
      "learning_rate": 4.4e-06,
      "loss": 1.9371,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.997011423110962,
      "learning_rate": 4.6e-06,
      "loss": 1.9638,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.5376744270324707,
      "learning_rate": 4.800000000000001e-06,
      "loss": 1.9765,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.8173863887786865,
      "learning_rate": 5e-06,
      "loss": 2.0262,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2269086837768555,
      "learning_rate": 5.2e-06,
      "loss": 1.9495,
      "step": 26
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.370210647583008,
      "learning_rate": 5.4e-06,
      "loss": 1.9135,
      "step": 27
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.5306196212768555,
      "learning_rate": 5.600000000000001e-06,
      "loss": 1.8501,
      "step": 28
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.6782211065292358,
      "learning_rate": 5.8e-06,
      "loss": 1.8907,
      "step": 29
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.138407230377197,
      "learning_rate": 6e-06,
      "loss": 1.8708,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5565104484558105,
      "learning_rate": 6.2e-06,
      "loss": 2.0328,
      "step": 31
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.4996781051158905,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 1.8636,
      "step": 32
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.704023003578186,
      "learning_rate": 6.6e-06,
      "loss": 1.83,
      "step": 33
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9734171628952026,
      "learning_rate": 6.800000000000001e-06,
      "loss": 1.9149,
      "step": 34
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.447547435760498,
      "learning_rate": 7.000000000000001e-06,
      "loss": 1.9521,
      "step": 35
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.326237678527832,
      "learning_rate": 7.2e-06,
      "loss": 1.862,
      "step": 36
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2940610647201538,
      "learning_rate": 7.4e-06,
      "loss": 1.9746,
      "step": 37
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3951361179351807,
      "learning_rate": 7.6e-06,
      "loss": 1.9221,
      "step": 38
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.852292060852051,
      "learning_rate": 7.8e-06,
      "loss": 1.8746,
      "step": 39
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9158365726470947,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.9157,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7286941409111023,
      "learning_rate": 8.200000000000001e-06,
      "loss": 1.8846,
      "step": 41
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9634971618652344,
      "learning_rate": 8.400000000000001e-06,
      "loss": 1.887,
      "step": 42
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7051373720169067,
      "learning_rate": 8.599999999999999e-06,
      "loss": 1.7435,
      "step": 43
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.3464224338531494,
      "learning_rate": 8.8e-06,
      "loss": 2.0543,
      "step": 44
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.3760058879852295,
      "learning_rate": 9e-06,
      "loss": 1.8802,
      "step": 45
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4925163984298706,
      "learning_rate": 9.2e-06,
      "loss": 1.8688,
      "step": 46
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.37955960631370544,
      "learning_rate": 9.4e-06,
      "loss": 2.0343,
      "step": 47
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.379056841135025,
      "learning_rate": 9.600000000000001e-06,
      "loss": 1.9177,
      "step": 48
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.5871400237083435,
      "learning_rate": 9.800000000000001e-06,
      "loss": 1.9375,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.40740448236465454,
      "learning_rate": 1e-05,
      "loss": 1.8563,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5194180607795715,
      "learning_rate": 1.02e-05,
      "loss": 1.9257,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3538413643836975,
      "learning_rate": 1.04e-05,
      "loss": 2.002,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4127403199672699,
      "learning_rate": 1.06e-05,
      "loss": 1.8611,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3403721749782562,
      "learning_rate": 1.08e-05,
      "loss": 1.9376,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6838916540145874,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.8965,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5685254335403442,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 1.8504,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.34112149477005005,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 1.8889,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.34890016913414,
      "learning_rate": 1.16e-05,
      "loss": 1.8814,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7584407329559326,
      "learning_rate": 1.18e-05,
      "loss": 1.8905,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6417098641395569,
      "learning_rate": 1.2e-05,
      "loss": 1.9628,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6567792296409607,
      "learning_rate": 1.22e-05,
      "loss": 1.9419,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7148586511611938,
      "learning_rate": 1.24e-05,
      "loss": 1.8201,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.755657970905304,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 1.8484,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4582751989364624,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 1.8866,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.35040852427482605,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.924,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4577142298221588,
      "learning_rate": 1.32e-05,
      "loss": 1.8838,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.051778793334961,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 1.8758,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3173122704029083,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 1.9224,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7951263189315796,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 1.8498,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2251149415969849,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.9056,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5454584956169128,
      "learning_rate": 1.42e-05,
      "loss": 1.8497,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0179494619369507,
      "learning_rate": 1.44e-05,
      "loss": 1.8759,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3878835439682007,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 1.7791,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9409505724906921,
      "learning_rate": 1.48e-05,
      "loss": 1.8544,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9269212484359741,
      "learning_rate": 1.5e-05,
      "loss": 1.8783,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5577906966209412,
      "learning_rate": 1.52e-05,
      "loss": 1.8438,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.518746018409729,
      "learning_rate": 1.54e-05,
      "loss": 1.8812,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5263887047767639,
      "learning_rate": 1.56e-05,
      "loss": 1.8888,
      "step": 78
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6630628705024719,
      "learning_rate": 1.58e-05,
      "loss": 1.8107,
      "step": 79
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46995043754577637,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.9213,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.215691089630127,
      "learning_rate": 1.62e-05,
      "loss": 1.8385,
      "step": 81
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7396010160446167,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 1.8336,
      "step": 82
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7764611840248108,
      "learning_rate": 1.66e-05,
      "loss": 1.7291,
      "step": 83
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.545802891254425,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 1.8327,
      "step": 84
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1297874450683594,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.8981,
      "step": 85
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6298626661300659,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 1.7987,
      "step": 86
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46490728855133057,
      "learning_rate": 1.74e-05,
      "loss": 1.7982,
      "step": 87
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7912402749061584,
      "learning_rate": 1.76e-05,
      "loss": 1.8011,
      "step": 88
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4619271457195282,
      "learning_rate": 1.78e-05,
      "loss": 1.8296,
      "step": 89
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.632027804851532,
      "learning_rate": 1.8e-05,
      "loss": 1.8452,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7296019792556763,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 1.7972,
      "step": 91
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5735658407211304,
      "learning_rate": 1.84e-05,
      "loss": 1.7722,
      "step": 92
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.089997410774231,
      "learning_rate": 1.86e-05,
      "loss": 1.7159,
      "step": 93
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0877244472503662,
      "learning_rate": 1.88e-05,
      "loss": 1.773,
      "step": 94
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7070674896240234,
      "learning_rate": 1.9e-05,
      "loss": 1.7096,
      "step": 95
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7553006410598755,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 1.7727,
      "step": 96
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6916640996932983,
      "learning_rate": 1.94e-05,
      "loss": 1.7334,
      "step": 97
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8733441829681396,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 1.6635,
      "step": 98
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7805576920509338,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 1.7144,
      "step": 99
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0293172597885132,
      "learning_rate": 2e-05,
      "loss": 1.7569,
      "step": 100
    },
    {
      "epoch": 0.01,
      "eval_loss": 1.6506503820419312,
      "eval_runtime": 812.8668,
      "eval_samples_per_second": 3.063,
      "eval_steps_per_second": 0.048,
      "eval_wer": 20.46198192583359,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.829711377620697,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 1.6818,
      "step": 101
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0298058986663818,
      "learning_rate": 2.04e-05,
      "loss": 1.6143,
      "step": 102
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9878931045532227,
      "learning_rate": 2.06e-05,
      "loss": 1.6201,
      "step": 103
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2404762506484985,
      "learning_rate": 2.08e-05,
      "loss": 1.5399,
      "step": 104
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1962342262268066,
      "learning_rate": 2.1e-05,
      "loss": 1.5841,
      "step": 105
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6740301847457886,
      "learning_rate": 2.12e-05,
      "loss": 1.6273,
      "step": 106
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.281548023223877,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 1.6061,
      "step": 107
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3783401250839233,
      "learning_rate": 2.16e-05,
      "loss": 1.6302,
      "step": 108
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.015912652015686,
      "learning_rate": 2.18e-05,
      "loss": 1.4995,
      "step": 109
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.509555459022522,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.563,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.121475100517273,
      "learning_rate": 2.22e-05,
      "loss": 1.4557,
      "step": 111
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3951892852783203,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 1.4967,
      "step": 112
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8649551868438721,
      "learning_rate": 2.26e-05,
      "loss": 1.4446,
      "step": 113
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0523897409439087,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 1.4695,
      "step": 114
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7523117065429688,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.4072,
      "step": 115
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7682850360870361,
      "learning_rate": 2.32e-05,
      "loss": 1.4961,
      "step": 116
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.550602376461029,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 1.4672,
      "step": 117
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5531795620918274,
      "learning_rate": 2.36e-05,
      "loss": 1.5189,
      "step": 118
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46566033363342285,
      "learning_rate": 2.38e-05,
      "loss": 1.4648,
      "step": 119
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42773711681365967,
      "learning_rate": 2.4e-05,
      "loss": 1.5156,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.41916757822036743,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 1.5035,
      "step": 121
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.38495850563049316,
      "learning_rate": 2.44e-05,
      "loss": 1.4093,
      "step": 122
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3074878454208374,
      "learning_rate": 2.46e-05,
      "loss": 1.3458,
      "step": 123
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.328609824180603,
      "learning_rate": 2.48e-05,
      "loss": 1.4767,
      "step": 124
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.27523261308670044,
      "learning_rate": 2.5e-05,
      "loss": 1.4027,
      "step": 125
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3317992389202118,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 1.3901,
      "step": 126
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2719029188156128,
      "learning_rate": 2.54e-05,
      "loss": 1.4296,
      "step": 127
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.249983012676239,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 1.3809,
      "step": 128
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25747495889663696,
      "learning_rate": 2.58e-05,
      "loss": 1.3378,
      "step": 129
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2646150290966034,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.4072,
      "step": 130
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25123435258865356,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 1.3514,
      "step": 131
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.24660153687000275,
      "learning_rate": 2.64e-05,
      "loss": 1.3591,
      "step": 132
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.26167136430740356,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 1.4602,
      "step": 133
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.258546382188797,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 1.3751,
      "step": 134
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2672257721424103,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.4088,
      "step": 135
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2614607810974121,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 1.3412,
      "step": 136
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25452449917793274,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 1.2698,
      "step": 137
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25946110486984253,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 1.3505,
      "step": 138
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.32489556074142456,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 1.2921,
      "step": 139
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25283879041671753,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.3089,
      "step": 140
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2603034973144531,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 1.3711,
      "step": 141
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.31170982122421265,
      "learning_rate": 2.84e-05,
      "loss": 1.4288,
      "step": 142
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2718154489994049,
      "learning_rate": 2.86e-05,
      "loss": 1.3969,
      "step": 143
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25995057821273804,
      "learning_rate": 2.88e-05,
      "loss": 1.3298,
      "step": 144
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.26786407828330994,
      "learning_rate": 2.9e-05,
      "loss": 1.3596,
      "step": 145
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2690494954586029,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 1.3097,
      "step": 146
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2820426821708679,
      "learning_rate": 2.94e-05,
      "loss": 1.3705,
      "step": 147
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2854262590408325,
      "learning_rate": 2.96e-05,
      "loss": 1.3389,
      "step": 148
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.27950477600097656,
      "learning_rate": 2.98e-05,
      "loss": 1.3012,
      "step": 149
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2887052893638611,
      "learning_rate": 3e-05,
      "loss": 1.2808,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2794536352157593,
      "learning_rate": 3.02e-05,
      "loss": 1.3132,
      "step": 151
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27701666951179504,
      "learning_rate": 3.04e-05,
      "loss": 1.2835,
      "step": 152
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2888679802417755,
      "learning_rate": 3.06e-05,
      "loss": 1.3105,
      "step": 153
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27843177318573,
      "learning_rate": 3.08e-05,
      "loss": 1.2686,
      "step": 154
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.30447402596473694,
      "learning_rate": 3.1e-05,
      "loss": 1.2972,
      "step": 155
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.31964585185050964,
      "learning_rate": 3.12e-05,
      "loss": 1.5243,
      "step": 156
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.31080594658851624,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 1.3662,
      "step": 157
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29143714904785156,
      "learning_rate": 3.16e-05,
      "loss": 1.2757,
      "step": 158
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.30254074931144714,
      "learning_rate": 3.18e-05,
      "loss": 1.2941,
      "step": 159
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3066195845603943,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.2656,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3236762285232544,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 1.364,
      "step": 161
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3177838921546936,
      "learning_rate": 3.24e-05,
      "loss": 1.2942,
      "step": 162
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29506322741508484,
      "learning_rate": 3.26e-05,
      "loss": 1.1983,
      "step": 163
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3027633726596832,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 1.2292,
      "step": 164
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.31580835580825806,
      "learning_rate": 3.3e-05,
      "loss": 1.2259,
      "step": 165
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.327269971370697,
      "learning_rate": 3.32e-05,
      "loss": 1.2101,
      "step": 166
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3131442368030548,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 1.1568,
      "step": 167
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.31098002195358276,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 1.2574,
      "step": 168
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.339773952960968,
      "learning_rate": 3.38e-05,
      "loss": 1.245,
      "step": 169
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3367580473423004,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.2359,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33780649304389954,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 1.2588,
      "step": 171
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3561837673187256,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 1.2252,
      "step": 172
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33797645568847656,
      "learning_rate": 3.46e-05,
      "loss": 1.1745,
      "step": 173
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3482077717781067,
      "learning_rate": 3.48e-05,
      "loss": 1.2133,
      "step": 174
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.396149605512619,
      "learning_rate": 3.5e-05,
      "loss": 1.1961,
      "step": 175
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3506738543510437,
      "learning_rate": 3.52e-05,
      "loss": 1.1439,
      "step": 176
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3514496982097626,
      "learning_rate": 3.54e-05,
      "loss": 1.2957,
      "step": 177
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.343712717294693,
      "learning_rate": 3.56e-05,
      "loss": 1.2142,
      "step": 178
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.34187403321266174,
      "learning_rate": 3.58e-05,
      "loss": 1.1306,
      "step": 179
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3421798646450043,
      "learning_rate": 3.6e-05,
      "loss": 1.2045,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.34351101517677307,
      "learning_rate": 3.62e-05,
      "loss": 1.1485,
      "step": 181
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3387378752231598,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 1.166,
      "step": 182
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32885318994522095,
      "learning_rate": 3.66e-05,
      "loss": 1.1939,
      "step": 183
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3394010365009308,
      "learning_rate": 3.68e-05,
      "loss": 1.0807,
      "step": 184
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3620411455631256,
      "learning_rate": 3.7e-05,
      "loss": 1.1151,
      "step": 185
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.36088186502456665,
      "learning_rate": 3.72e-05,
      "loss": 1.1234,
      "step": 186
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33137622475624084,
      "learning_rate": 3.74e-05,
      "loss": 1.1324,
      "step": 187
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.34646323323249817,
      "learning_rate": 3.76e-05,
      "loss": 1.1484,
      "step": 188
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32632550597190857,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 1.188,
      "step": 189
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32269442081451416,
      "learning_rate": 3.8e-05,
      "loss": 1.1494,
      "step": 190
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3319393992424011,
      "learning_rate": 3.82e-05,
      "loss": 1.1397,
      "step": 191
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.30638957023620605,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 1.1144,
      "step": 192
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2880196273326874,
      "learning_rate": 3.86e-05,
      "loss": 1.0861,
      "step": 193
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29941225051879883,
      "learning_rate": 3.88e-05,
      "loss": 1.1362,
      "step": 194
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29402047395706177,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.115,
      "step": 195
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26903632283210754,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 1.0885,
      "step": 196
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2827853262424469,
      "learning_rate": 3.94e-05,
      "loss": 1.0611,
      "step": 197
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2691005766391754,
      "learning_rate": 3.960000000000001e-05,
      "loss": 1.0273,
      "step": 198
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25598639249801636,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 1.0836,
      "step": 199
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24717311561107635,
      "learning_rate": 4e-05,
      "loss": 1.0456,
      "step": 200
    },
    {
      "epoch": 0.02,
      "eval_loss": 1.0296043157577515,
      "eval_runtime": 801.397,
      "eval_samples_per_second": 3.107,
      "eval_steps_per_second": 0.049,
      "eval_wer": 19.671237145528202,
      "step": 200
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24719834327697754,
      "learning_rate": 4.02e-05,
      "loss": 1.0477,
      "step": 201
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2471485435962677,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 1.0805,
      "step": 202
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22860248386859894,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 1.081,
      "step": 203
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22999390959739685,
      "learning_rate": 4.08e-05,
      "loss": 1.0842,
      "step": 204
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22211423516273499,
      "learning_rate": 4.1e-05,
      "loss": 1.0718,
      "step": 205
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20220232009887695,
      "learning_rate": 4.12e-05,
      "loss": 0.9931,
      "step": 206
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21541321277618408,
      "learning_rate": 4.14e-05,
      "loss": 0.9996,
      "step": 207
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21179968118667603,
      "learning_rate": 4.16e-05,
      "loss": 0.9861,
      "step": 208
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21677811443805695,
      "learning_rate": 4.18e-05,
      "loss": 1.0861,
      "step": 209
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20630541443824768,
      "learning_rate": 4.2e-05,
      "loss": 1.0575,
      "step": 210
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20216478407382965,
      "learning_rate": 4.22e-05,
      "loss": 1.0334,
      "step": 211
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19194303452968597,
      "learning_rate": 4.24e-05,
      "loss": 1.0144,
      "step": 212
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19658614695072174,
      "learning_rate": 4.26e-05,
      "loss": 1.1176,
      "step": 213
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1941639930009842,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 1.0354,
      "step": 214
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20370621979236603,
      "learning_rate": 4.3e-05,
      "loss": 1.0581,
      "step": 215
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19180795550346375,
      "learning_rate": 4.32e-05,
      "loss": 1.002,
      "step": 216
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19655004143714905,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 1.0471,
      "step": 217
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19790470600128174,
      "learning_rate": 4.36e-05,
      "loss": 1.0684,
      "step": 218
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19687040150165558,
      "learning_rate": 4.38e-05,
      "loss": 1.0003,
      "step": 219
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20600856840610504,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.9851,
      "step": 220
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19990204274654388,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 1.001,
      "step": 221
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19834722578525543,
      "learning_rate": 4.44e-05,
      "loss": 1.0489,
      "step": 222
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19937515258789062,
      "learning_rate": 4.46e-05,
      "loss": 1.0128,
      "step": 223
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1915847212076187,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.995,
      "step": 224
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2017356902360916,
      "learning_rate": 4.5e-05,
      "loss": 1.0622,
      "step": 225
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19220130145549774,
      "learning_rate": 4.52e-05,
      "loss": 0.9951,
      "step": 226
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20884248614311218,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 1.0101,
      "step": 227
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20601709187030792,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 1.0269,
      "step": 228
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20320594310760498,
      "learning_rate": 4.58e-05,
      "loss": 1.0027,
      "step": 229
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.19957703351974487,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.0604,
      "step": 230
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.209646075963974,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 1.0565,
      "step": 231
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20739595592021942,
      "learning_rate": 4.64e-05,
      "loss": 1.0576,
      "step": 232
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2133803814649582,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.9952,
      "step": 233
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21479493379592896,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.9866,
      "step": 234
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20056866109371185,
      "learning_rate": 4.7e-05,
      "loss": 0.9248,
      "step": 235
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2163337618112564,
      "learning_rate": 4.72e-05,
      "loss": 1.0208,
      "step": 236
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21150915324687958,
      "learning_rate": 4.74e-05,
      "loss": 0.9963,
      "step": 237
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2226182371377945,
      "learning_rate": 4.76e-05,
      "loss": 1.03,
      "step": 238
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20908720791339874,
      "learning_rate": 4.78e-05,
      "loss": 0.9738,
      "step": 239
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21630243957042694,
      "learning_rate": 4.8e-05,
      "loss": 1.0018,
      "step": 240
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21600545942783356,
      "learning_rate": 4.82e-05,
      "loss": 0.9956,
      "step": 241
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20709353685379028,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.98,
      "step": 242
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20743773877620697,
      "learning_rate": 4.86e-05,
      "loss": 0.9219,
      "step": 243
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21734793484210968,
      "learning_rate": 4.88e-05,
      "loss": 0.9721,
      "step": 244
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22777698934078217,
      "learning_rate": 4.9e-05,
      "loss": 0.976,
      "step": 245
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20042578876018524,
      "learning_rate": 4.92e-05,
      "loss": 0.8991,
      "step": 246
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20748281478881836,
      "learning_rate": 4.94e-05,
      "loss": 0.9618,
      "step": 247
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2245628535747528,
      "learning_rate": 4.96e-05,
      "loss": 0.9785,
      "step": 248
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22263981401920319,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.9113,
      "step": 249
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21839040517807007,
      "learning_rate": 5e-05,
      "loss": 0.9293,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21345219016075134,
      "learning_rate": 5.02e-05,
      "loss": 0.9075,
      "step": 251
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.22234344482421875,
      "learning_rate": 5.0400000000000005e-05,
      "loss": 0.9347,
      "step": 252
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20948739349842072,
      "learning_rate": 5.0600000000000003e-05,
      "loss": 0.9182,
      "step": 253
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21825186908245087,
      "learning_rate": 5.08e-05,
      "loss": 0.9041,
      "step": 254
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21763546764850616,
      "learning_rate": 5.1000000000000006e-05,
      "loss": 0.8927,
      "step": 255
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2300015091896057,
      "learning_rate": 5.1200000000000004e-05,
      "loss": 0.9715,
      "step": 256
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23285073041915894,
      "learning_rate": 5.14e-05,
      "loss": 0.9082,
      "step": 257
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21854038536548615,
      "learning_rate": 5.16e-05,
      "loss": 0.8976,
      "step": 258
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23812685906887054,
      "learning_rate": 5.1800000000000005e-05,
      "loss": 0.9129,
      "step": 259
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2490854263305664,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 0.9141,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3197532892227173,
      "learning_rate": 5.22e-05,
      "loss": 0.9564,
      "step": 261
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24467764794826508,
      "learning_rate": 5.2400000000000007e-05,
      "loss": 0.9706,
      "step": 262
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.25058361887931824,
      "learning_rate": 5.2600000000000005e-05,
      "loss": 0.9541,
      "step": 263
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23314617574214935,
      "learning_rate": 5.28e-05,
      "loss": 0.8695,
      "step": 264
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23510120809078217,
      "learning_rate": 5.300000000000001e-05,
      "loss": 0.8257,
      "step": 265
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2394399791955948,
      "learning_rate": 5.3200000000000006e-05,
      "loss": 0.8672,
      "step": 266
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23700331151485443,
      "learning_rate": 5.3400000000000004e-05,
      "loss": 0.8151,
      "step": 267
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23756074905395508,
      "learning_rate": 5.360000000000001e-05,
      "loss": 0.9169,
      "step": 268
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24621699750423431,
      "learning_rate": 5.380000000000001e-05,
      "loss": 0.8672,
      "step": 269
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.244352325797081,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.8602,
      "step": 270
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24237145483493805,
      "learning_rate": 5.420000000000001e-05,
      "loss": 0.8515,
      "step": 271
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24863645434379578,
      "learning_rate": 5.440000000000001e-05,
      "loss": 0.8353,
      "step": 272
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2398129552602768,
      "learning_rate": 5.4600000000000006e-05,
      "loss": 0.7756,
      "step": 273
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.24918794631958008,
      "learning_rate": 5.4800000000000004e-05,
      "loss": 0.7821,
      "step": 274
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.26684266328811646,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.7936,
      "step": 275
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.24549566209316254,
      "learning_rate": 5.520000000000001e-05,
      "loss": 0.7525,
      "step": 276
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2579353153705597,
      "learning_rate": 5.5400000000000005e-05,
      "loss": 0.8817,
      "step": 277
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2502259910106659,
      "learning_rate": 5.560000000000001e-05,
      "loss": 0.8059,
      "step": 278
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2671497166156769,
      "learning_rate": 5.580000000000001e-05,
      "loss": 0.8058,
      "step": 279
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.26070672273635864,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 0.808,
      "step": 280
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.26931270956993103,
      "learning_rate": 5.620000000000001e-05,
      "loss": 0.7596,
      "step": 281
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.26058271527290344,
      "learning_rate": 5.6399999999999995e-05,
      "loss": 0.7218,
      "step": 282
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2628845274448395,
      "learning_rate": 5.66e-05,
      "loss": 0.7207,
      "step": 283
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.30022546648979187,
      "learning_rate": 5.68e-05,
      "loss": 0.8127,
      "step": 284
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2642339766025543,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 0.7469,
      "step": 285
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2857198715209961,
      "learning_rate": 5.72e-05,
      "loss": 0.7993,
      "step": 286
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2643411159515381,
      "learning_rate": 5.74e-05,
      "loss": 0.7109,
      "step": 287
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.27660027146339417,
      "learning_rate": 5.76e-05,
      "loss": 0.7056,
      "step": 288
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2752079665660858,
      "learning_rate": 5.7799999999999995e-05,
      "loss": 0.7436,
      "step": 289
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.27865105867385864,
      "learning_rate": 5.8e-05,
      "loss": 0.6636,
      "step": 290
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.27711221575737,
      "learning_rate": 5.82e-05,
      "loss": 0.6959,
      "step": 291
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2939106225967407,
      "learning_rate": 5.8399999999999997e-05,
      "loss": 0.7687,
      "step": 292
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2841791808605194,
      "learning_rate": 5.86e-05,
      "loss": 0.7687,
      "step": 293
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2942488491535187,
      "learning_rate": 5.88e-05,
      "loss": 0.7058,
      "step": 294
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2913355827331543,
      "learning_rate": 5.9e-05,
      "loss": 0.6851,
      "step": 295
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3099311888217926,
      "learning_rate": 5.92e-05,
      "loss": 0.7285,
      "step": 296
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.29750707745552063,
      "learning_rate": 5.94e-05,
      "loss": 0.744,
      "step": 297
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.29916903376579285,
      "learning_rate": 5.96e-05,
      "loss": 0.6089,
      "step": 298
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.34067317843437195,
      "learning_rate": 5.9800000000000003e-05,
      "loss": 0.6329,
      "step": 299
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3079257011413574,
      "learning_rate": 6e-05,
      "loss": 0.6779,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6361521482467651,
      "eval_runtime": 807.5392,
      "eval_samples_per_second": 3.083,
      "eval_steps_per_second": 0.048,
      "eval_wer": 17.78201932066064,
      "step": 300
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.31872040033340454,
      "learning_rate": 6.02e-05,
      "loss": 0.6198,
      "step": 301
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.32201656699180603,
      "learning_rate": 6.04e-05,
      "loss": 0.7444,
      "step": 302
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3033120930194855,
      "learning_rate": 6.06e-05,
      "loss": 0.6241,
      "step": 303
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3257031738758087,
      "learning_rate": 6.08e-05,
      "loss": 0.6098,
      "step": 304
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.33150410652160645,
      "learning_rate": 6.1e-05,
      "loss": 0.6441,
      "step": 305
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.36634930968284607,
      "learning_rate": 6.12e-05,
      "loss": 0.6186,
      "step": 306
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.35903772711753845,
      "learning_rate": 6.14e-05,
      "loss": 0.6758,
      "step": 307
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3369480073451996,
      "learning_rate": 6.16e-05,
      "loss": 0.5719,
      "step": 308
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.35223162174224854,
      "learning_rate": 6.18e-05,
      "loss": 0.6035,
      "step": 309
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3624025285243988,
      "learning_rate": 6.2e-05,
      "loss": 0.5687,
      "step": 310
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3625550866127014,
      "learning_rate": 6.220000000000001e-05,
      "loss": 0.5053,
      "step": 311
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.35375553369522095,
      "learning_rate": 6.24e-05,
      "loss": 0.5818,
      "step": 312
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.36061400175094604,
      "learning_rate": 6.26e-05,
      "loss": 0.5315,
      "step": 313
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3803900480270386,
      "learning_rate": 6.280000000000001e-05,
      "loss": 0.5911,
      "step": 314
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.372794508934021,
      "learning_rate": 6.3e-05,
      "loss": 0.5817,
      "step": 315
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3981311023235321,
      "learning_rate": 6.32e-05,
      "loss": 0.4917,
      "step": 316
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3988941013813019,
      "learning_rate": 6.340000000000001e-05,
      "loss": 0.5382,
      "step": 317
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.37490224838256836,
      "learning_rate": 6.36e-05,
      "loss": 0.466,
      "step": 318
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3623771369457245,
      "learning_rate": 6.38e-05,
      "loss": 0.4602,
      "step": 319
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.37675392627716064,
      "learning_rate": 6.400000000000001e-05,
      "loss": 0.3816,
      "step": 320
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.41062700748443604,
      "learning_rate": 6.42e-05,
      "loss": 0.4539,
      "step": 321
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3824600875377655,
      "learning_rate": 6.440000000000001e-05,
      "loss": 0.4487,
      "step": 322
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.36306288838386536,
      "learning_rate": 6.460000000000001e-05,
      "loss": 0.3928,
      "step": 323
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3881344497203827,
      "learning_rate": 6.48e-05,
      "loss": 0.4578,
      "step": 324
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.30075204372406006,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.3949,
      "step": 325
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.42034029960632324,
      "learning_rate": 6.52e-05,
      "loss": 0.3791,
      "step": 326
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2626543939113617,
      "learning_rate": 6.54e-05,
      "loss": 0.3489,
      "step": 327
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24982449412345886,
      "learning_rate": 6.560000000000001e-05,
      "loss": 0.3926,
      "step": 328
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21887333691120148,
      "learning_rate": 6.58e-05,
      "loss": 0.3218,
      "step": 329
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24838243424892426,
      "learning_rate": 6.6e-05,
      "loss": 0.2807,
      "step": 330
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20542925596237183,
      "learning_rate": 6.620000000000001e-05,
      "loss": 0.3485,
      "step": 331
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19924688339233398,
      "learning_rate": 6.64e-05,
      "loss": 0.3803,
      "step": 332
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1775830239057541,
      "learning_rate": 6.66e-05,
      "loss": 0.2808,
      "step": 333
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19626715779304504,
      "learning_rate": 6.680000000000001e-05,
      "loss": 0.3982,
      "step": 334
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18121103942394257,
      "learning_rate": 6.7e-05,
      "loss": 0.322,
      "step": 335
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.172463521361351,
      "learning_rate": 6.720000000000001e-05,
      "loss": 0.3104,
      "step": 336
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18183016777038574,
      "learning_rate": 6.740000000000001e-05,
      "loss": 0.3175,
      "step": 337
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.16865940392017365,
      "learning_rate": 6.76e-05,
      "loss": 0.2954,
      "step": 338
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.209854394197464,
      "learning_rate": 6.780000000000001e-05,
      "loss": 0.3663,
      "step": 339
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21269935369491577,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.3847,
      "step": 340
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18378563225269318,
      "learning_rate": 6.82e-05,
      "loss": 0.3629,
      "step": 341
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1809612363576889,
      "learning_rate": 6.840000000000001e-05,
      "loss": 0.2997,
      "step": 342
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18595385551452637,
      "learning_rate": 6.860000000000001e-05,
      "loss": 0.3364,
      "step": 343
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1977444589138031,
      "learning_rate": 6.879999999999999e-05,
      "loss": 0.3551,
      "step": 344
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20381221175193787,
      "learning_rate": 6.9e-05,
      "loss": 0.3659,
      "step": 345
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17862935364246368,
      "learning_rate": 6.92e-05,
      "loss": 0.329,
      "step": 346
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18225114047527313,
      "learning_rate": 6.939999999999999e-05,
      "loss": 0.4002,
      "step": 347
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1834196299314499,
      "learning_rate": 6.96e-05,
      "loss": 0.3493,
      "step": 348
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17270565032958984,
      "learning_rate": 6.98e-05,
      "loss": 0.3125,
      "step": 349
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1969367265701294,
      "learning_rate": 7e-05,
      "loss": 0.3445,
      "step": 350
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20063060522079468,
      "learning_rate": 7.02e-05,
      "loss": 0.3755,
      "step": 351
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19544148445129395,
      "learning_rate": 7.04e-05,
      "loss": 0.3683,
      "step": 352
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1906142234802246,
      "learning_rate": 7.06e-05,
      "loss": 0.3022,
      "step": 353
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18005798757076263,
      "learning_rate": 7.08e-05,
      "loss": 0.3288,
      "step": 354
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1748594492673874,
      "learning_rate": 7.1e-05,
      "loss": 0.3007,
      "step": 355
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19211235642433167,
      "learning_rate": 7.12e-05,
      "loss": 0.3509,
      "step": 356
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17916198074817657,
      "learning_rate": 7.14e-05,
      "loss": 0.3083,
      "step": 357
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20435747504234314,
      "learning_rate": 7.16e-05,
      "loss": 0.4266,
      "step": 358
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17228934168815613,
      "learning_rate": 7.18e-05,
      "loss": 0.3121,
      "step": 359
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19787389039993286,
      "learning_rate": 7.2e-05,
      "loss": 0.2963,
      "step": 360
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19428648054599762,
      "learning_rate": 7.22e-05,
      "loss": 0.3507,
      "step": 361
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21133367717266083,
      "learning_rate": 7.24e-05,
      "loss": 0.3603,
      "step": 362
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17419594526290894,
      "learning_rate": 7.26e-05,
      "loss": 0.2627,
      "step": 363
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18898442387580872,
      "learning_rate": 7.280000000000001e-05,
      "loss": 0.3126,
      "step": 364
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19681523740291595,
      "learning_rate": 7.3e-05,
      "loss": 0.3436,
      "step": 365
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18543389439582825,
      "learning_rate": 7.32e-05,
      "loss": 0.3154,
      "step": 366
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1961585283279419,
      "learning_rate": 7.340000000000001e-05,
      "loss": 0.3243,
      "step": 367
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19043558835983276,
      "learning_rate": 7.36e-05,
      "loss": 0.3224,
      "step": 368
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19061991572380066,
      "learning_rate": 7.38e-05,
      "loss": 0.3416,
      "step": 369
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1980261504650116,
      "learning_rate": 7.4e-05,
      "loss": 0.3366,
      "step": 370
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2015640288591385,
      "learning_rate": 7.42e-05,
      "loss": 0.3869,
      "step": 371
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20130270719528198,
      "learning_rate": 7.44e-05,
      "loss": 0.3739,
      "step": 372
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18016573786735535,
      "learning_rate": 7.46e-05,
      "loss": 0.3173,
      "step": 373
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18029211461544037,
      "learning_rate": 7.48e-05,
      "loss": 0.2825,
      "step": 374
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18051205575466156,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.2866,
      "step": 375
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20463068783283234,
      "learning_rate": 7.52e-05,
      "loss": 0.3553,
      "step": 376
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19793766736984253,
      "learning_rate": 7.54e-05,
      "loss": 0.3046,
      "step": 377
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2107568383216858,
      "learning_rate": 7.560000000000001e-05,
      "loss": 0.3375,
      "step": 378
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19924841821193695,
      "learning_rate": 7.58e-05,
      "loss": 0.3064,
      "step": 379
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2047189623117447,
      "learning_rate": 7.6e-05,
      "loss": 0.3335,
      "step": 380
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20030571520328522,
      "learning_rate": 7.620000000000001e-05,
      "loss": 0.3282,
      "step": 381
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21090325713157654,
      "learning_rate": 7.64e-05,
      "loss": 0.3084,
      "step": 382
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1920361965894699,
      "learning_rate": 7.66e-05,
      "loss": 0.3042,
      "step": 383
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19907881319522858,
      "learning_rate": 7.680000000000001e-05,
      "loss": 0.3652,
      "step": 384
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2138243466615677,
      "learning_rate": 7.7e-05,
      "loss": 0.3292,
      "step": 385
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20718149840831757,
      "learning_rate": 7.72e-05,
      "loss": 0.3273,
      "step": 386
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20674724876880646,
      "learning_rate": 7.740000000000001e-05,
      "loss": 0.3208,
      "step": 387
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20565900206565857,
      "learning_rate": 7.76e-05,
      "loss": 0.3046,
      "step": 388
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22092103958129883,
      "learning_rate": 7.780000000000001e-05,
      "loss": 0.352,
      "step": 389
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2036062628030777,
      "learning_rate": 7.800000000000001e-05,
      "loss": 0.3453,
      "step": 390
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21280217170715332,
      "learning_rate": 7.82e-05,
      "loss": 0.3291,
      "step": 391
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19440370798110962,
      "learning_rate": 7.840000000000001e-05,
      "loss": 0.3088,
      "step": 392
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21310733258724213,
      "learning_rate": 7.860000000000001e-05,
      "loss": 0.3393,
      "step": 393
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1909486949443817,
      "learning_rate": 7.88e-05,
      "loss": 0.325,
      "step": 394
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17687544226646423,
      "learning_rate": 7.900000000000001e-05,
      "loss": 0.2334,
      "step": 395
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20252984762191772,
      "learning_rate": 7.920000000000001e-05,
      "loss": 0.3523,
      "step": 396
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2199467122554779,
      "learning_rate": 7.94e-05,
      "loss": 0.3367,
      "step": 397
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2193784862756729,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.3175,
      "step": 398
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2135520577430725,
      "learning_rate": 7.98e-05,
      "loss": 0.3135,
      "step": 399
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24475537240505219,
      "learning_rate": 8e-05,
      "loss": 0.3927,
      "step": 400
    },
    {
      "epoch": 1.01,
      "eval_loss": 0.280251145362854,
      "eval_runtime": 820.4776,
      "eval_samples_per_second": 3.035,
      "eval_steps_per_second": 0.048,
      "eval_wer": 16.500467435338113,
      "step": 400
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2087864726781845,
      "learning_rate": 8.020000000000001e-05,
      "loss": 0.3104,
      "step": 401
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22025741636753082,
      "learning_rate": 8.04e-05,
      "loss": 0.3536,
      "step": 402
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21522679924964905,
      "learning_rate": 8.060000000000001e-05,
      "loss": 0.3123,
      "step": 403
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19630490243434906,
      "learning_rate": 8.080000000000001e-05,
      "loss": 0.2994,
      "step": 404
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2252015620470047,
      "learning_rate": 8.1e-05,
      "loss": 0.3134,
      "step": 405
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2115161120891571,
      "learning_rate": 8.120000000000001e-05,
      "loss": 0.3095,
      "step": 406
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22329171001911163,
      "learning_rate": 8.14e-05,
      "loss": 0.3059,
      "step": 407
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20733675360679626,
      "learning_rate": 8.16e-05,
      "loss": 0.2957,
      "step": 408
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19938726723194122,
      "learning_rate": 8.18e-05,
      "loss": 0.2851,
      "step": 409
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2169998288154602,
      "learning_rate": 8.2e-05,
      "loss": 0.3024,
      "step": 410
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2236190289258957,
      "learning_rate": 8.22e-05,
      "loss": 0.2912,
      "step": 411
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19384761154651642,
      "learning_rate": 8.24e-05,
      "loss": 0.2629,
      "step": 412
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20049649477005005,
      "learning_rate": 8.26e-05,
      "loss": 0.2591,
      "step": 413
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19711436331272125,
      "learning_rate": 8.28e-05,
      "loss": 0.283,
      "step": 414
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21745117008686066,
      "learning_rate": 8.3e-05,
      "loss": 0.2927,
      "step": 415
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22002024948596954,
      "learning_rate": 8.32e-05,
      "loss": 0.2834,
      "step": 416
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20296917855739594,
      "learning_rate": 8.34e-05,
      "loss": 0.2561,
      "step": 417
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21155214309692383,
      "learning_rate": 8.36e-05,
      "loss": 0.2977,
      "step": 418
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22787843644618988,
      "learning_rate": 8.38e-05,
      "loss": 0.3451,
      "step": 419
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.22464005649089813,
      "learning_rate": 8.4e-05,
      "loss": 0.3184,
      "step": 420
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2281302511692047,
      "learning_rate": 8.42e-05,
      "loss": 0.3216,
      "step": 421
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24903731048107147,
      "learning_rate": 8.44e-05,
      "loss": 0.3103,
      "step": 422
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21139509975910187,
      "learning_rate": 8.46e-05,
      "loss": 0.2951,
      "step": 423
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21589910984039307,
      "learning_rate": 8.48e-05,
      "loss": 0.293,
      "step": 424
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21341080963611603,
      "learning_rate": 8.5e-05,
      "loss": 0.2611,
      "step": 425
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2438979595899582,
      "learning_rate": 8.52e-05,
      "loss": 0.362,
      "step": 426
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.19188913702964783,
      "learning_rate": 8.54e-05,
      "loss": 0.3254,
      "step": 427
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21643254160881042,
      "learning_rate": 8.560000000000001e-05,
      "loss": 0.3073,
      "step": 428
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21603840589523315,
      "learning_rate": 8.58e-05,
      "loss": 0.281,
      "step": 429
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23239870369434357,
      "learning_rate": 8.6e-05,
      "loss": 0.3174,
      "step": 430
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23213066160678864,
      "learning_rate": 8.620000000000001e-05,
      "loss": 0.3166,
      "step": 431
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.209380641579628,
      "learning_rate": 8.64e-05,
      "loss": 0.2705,
      "step": 432
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2319996953010559,
      "learning_rate": 8.66e-05,
      "loss": 0.3273,
      "step": 433
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22280462086200714,
      "learning_rate": 8.680000000000001e-05,
      "loss": 0.2646,
      "step": 434
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2464459091424942,
      "learning_rate": 8.7e-05,
      "loss": 0.405,
      "step": 435
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.20814302563667297,
      "learning_rate": 8.72e-05,
      "loss": 0.259,
      "step": 436
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23175746202468872,
      "learning_rate": 8.740000000000001e-05,
      "loss": 0.3073,
      "step": 437
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22513963282108307,
      "learning_rate": 8.76e-05,
      "loss": 0.2999,
      "step": 438
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21060530841350555,
      "learning_rate": 8.78e-05,
      "loss": 0.3028,
      "step": 439
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2127162218093872,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.3055,
      "step": 440
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2438308149576187,
      "learning_rate": 8.82e-05,
      "loss": 0.3091,
      "step": 441
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2145686149597168,
      "learning_rate": 8.840000000000001e-05,
      "loss": 0.2641,
      "step": 442
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2080579400062561,
      "learning_rate": 8.86e-05,
      "loss": 0.2844,
      "step": 443
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23217429220676422,
      "learning_rate": 8.88e-05,
      "loss": 0.2875,
      "step": 444
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2351812869310379,
      "learning_rate": 8.900000000000001e-05,
      "loss": 0.3359,
      "step": 445
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2023210972547531,
      "learning_rate": 8.92e-05,
      "loss": 0.2577,
      "step": 446
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2224423885345459,
      "learning_rate": 8.94e-05,
      "loss": 0.2847,
      "step": 447
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21382537484169006,
      "learning_rate": 8.960000000000001e-05,
      "loss": 0.2735,
      "step": 448
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2381601631641388,
      "learning_rate": 8.98e-05,
      "loss": 0.3124,
      "step": 449
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22752141952514648,
      "learning_rate": 9e-05,
      "loss": 0.3241,
      "step": 450
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21625299751758575,
      "learning_rate": 9.020000000000001e-05,
      "loss": 0.2814,
      "step": 451
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.25673097372055054,
      "learning_rate": 9.04e-05,
      "loss": 0.2941,
      "step": 452
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2133817970752716,
      "learning_rate": 9.06e-05,
      "loss": 0.2449,
      "step": 453
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23466257750988007,
      "learning_rate": 9.080000000000001e-05,
      "loss": 0.2772,
      "step": 454
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23800158500671387,
      "learning_rate": 9.1e-05,
      "loss": 0.3486,
      "step": 455
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.20734591782093048,
      "learning_rate": 9.120000000000001e-05,
      "loss": 0.2678,
      "step": 456
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24006883800029755,
      "learning_rate": 9.140000000000001e-05,
      "loss": 0.2896,
      "step": 457
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.262967050075531,
      "learning_rate": 9.16e-05,
      "loss": 0.3419,
      "step": 458
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2026890367269516,
      "learning_rate": 9.180000000000001e-05,
      "loss": 0.213,
      "step": 459
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23914720118045807,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.2957,
      "step": 460
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2322704941034317,
      "learning_rate": 9.22e-05,
      "loss": 0.2872,
      "step": 461
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23141203820705414,
      "learning_rate": 9.240000000000001e-05,
      "loss": 0.2775,
      "step": 462
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2222837656736374,
      "learning_rate": 9.260000000000001e-05,
      "loss": 0.2668,
      "step": 463
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23412996530532837,
      "learning_rate": 9.28e-05,
      "loss": 0.2858,
      "step": 464
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2451399862766266,
      "learning_rate": 9.300000000000001e-05,
      "loss": 0.2644,
      "step": 465
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2240569293498993,
      "learning_rate": 9.320000000000002e-05,
      "loss": 0.2979,
      "step": 466
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.25497618317604065,
      "learning_rate": 9.340000000000001e-05,
      "loss": 0.3044,
      "step": 467
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2138393372297287,
      "learning_rate": 9.360000000000001e-05,
      "loss": 0.2398,
      "step": 468
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22127047181129456,
      "learning_rate": 9.38e-05,
      "loss": 0.2898,
      "step": 469
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24012728035449982,
      "learning_rate": 9.4e-05,
      "loss": 0.3304,
      "step": 470
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24931015074253082,
      "learning_rate": 9.42e-05,
      "loss": 0.2773,
      "step": 471
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2525688111782074,
      "learning_rate": 9.44e-05,
      "loss": 0.3395,
      "step": 472
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23732952773571014,
      "learning_rate": 9.46e-05,
      "loss": 0.2924,
      "step": 473
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24722249805927277,
      "learning_rate": 9.48e-05,
      "loss": 0.316,
      "step": 474
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.25770655274391174,
      "learning_rate": 9.5e-05,
      "loss": 0.2643,
      "step": 475
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24207694828510284,
      "learning_rate": 9.52e-05,
      "loss": 0.3011,
      "step": 476
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.243463933467865,
      "learning_rate": 9.54e-05,
      "loss": 0.3124,
      "step": 477
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23415067791938782,
      "learning_rate": 9.56e-05,
      "loss": 0.2474,
      "step": 478
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22483721375465393,
      "learning_rate": 9.58e-05,
      "loss": 0.2743,
      "step": 479
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23131731152534485,
      "learning_rate": 9.6e-05,
      "loss": 0.2758,
      "step": 480
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22976872324943542,
      "learning_rate": 9.620000000000001e-05,
      "loss": 0.2578,
      "step": 481
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23774071037769318,
      "learning_rate": 9.64e-05,
      "loss": 0.2475,
      "step": 482
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2388826310634613,
      "learning_rate": 9.66e-05,
      "loss": 0.2617,
      "step": 483
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23769314587116241,
      "learning_rate": 9.680000000000001e-05,
      "loss": 0.2556,
      "step": 484
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.26472797989845276,
      "learning_rate": 9.7e-05,
      "loss": 0.3012,
      "step": 485
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2510959208011627,
      "learning_rate": 9.72e-05,
      "loss": 0.2673,
      "step": 486
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23769429326057434,
      "learning_rate": 9.74e-05,
      "loss": 0.2591,
      "step": 487
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24959763884544373,
      "learning_rate": 9.76e-05,
      "loss": 0.2452,
      "step": 488
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23830927908420563,
      "learning_rate": 9.78e-05,
      "loss": 0.2454,
      "step": 489
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2374192774295807,
      "learning_rate": 9.8e-05,
      "loss": 0.2333,
      "step": 490
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2351909577846527,
      "learning_rate": 9.82e-05,
      "loss": 0.2766,
      "step": 491
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2633665204048157,
      "learning_rate": 9.84e-05,
      "loss": 0.3125,
      "step": 492
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.27817174792289734,
      "learning_rate": 9.86e-05,
      "loss": 0.281,
      "step": 493
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.25119128823280334,
      "learning_rate": 9.88e-05,
      "loss": 0.2641,
      "step": 494
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21341882646083832,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.2449,
      "step": 495
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23525851964950562,
      "learning_rate": 9.92e-05,
      "loss": 0.2383,
      "step": 496
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24074457585811615,
      "learning_rate": 9.94e-05,
      "loss": 0.2828,
      "step": 497
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24159358441829681,
      "learning_rate": 9.960000000000001e-05,
      "loss": 0.2717,
      "step": 498
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2249632030725479,
      "learning_rate": 9.98e-05,
      "loss": 0.205,
      "step": 499
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24636855721473694,
      "learning_rate": 0.0001,
      "loss": 0.2542,
      "step": 500
    },
    {
      "epoch": 1.02,
      "eval_loss": 0.24805526435375214,
      "eval_runtime": 825.0539,
      "eval_samples_per_second": 3.018,
      "eval_steps_per_second": 0.047,
      "eval_wer": 14.977407291991273,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23917172849178314,
      "learning_rate": 9.998947368421053e-05,
      "loss": 0.2358,
      "step": 501
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2702760100364685,
      "learning_rate": 9.997894736842107e-05,
      "loss": 0.2524,
      "step": 502
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23460665345191956,
      "learning_rate": 9.996842105263159e-05,
      "loss": 0.2483,
      "step": 503
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2624615728855133,
      "learning_rate": 9.99578947368421e-05,
      "loss": 0.3085,
      "step": 504
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23389141261577606,
      "learning_rate": 9.994736842105263e-05,
      "loss": 0.2095,
      "step": 505
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2405523806810379,
      "learning_rate": 9.993684210526317e-05,
      "loss": 0.2316,
      "step": 506
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24187558889389038,
      "learning_rate": 9.992631578947369e-05,
      "loss": 0.2255,
      "step": 507
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2355700582265854,
      "learning_rate": 9.991578947368422e-05,
      "loss": 0.2944,
      "step": 508
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2520108222961426,
      "learning_rate": 9.990526315789474e-05,
      "loss": 0.3177,
      "step": 509
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22328832745552063,
      "learning_rate": 9.989473684210526e-05,
      "loss": 0.2195,
      "step": 510
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24362891912460327,
      "learning_rate": 9.988421052631579e-05,
      "loss": 0.2632,
      "step": 511
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2556741535663605,
      "learning_rate": 9.987368421052631e-05,
      "loss": 0.3093,
      "step": 512
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24602992832660675,
      "learning_rate": 9.986315789473685e-05,
      "loss": 0.2155,
      "step": 513
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2635270655155182,
      "learning_rate": 9.985263157894738e-05,
      "loss": 0.2801,
      "step": 514
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.27488836646080017,
      "learning_rate": 9.98421052631579e-05,
      "loss": 0.2735,
      "step": 515
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24215292930603027,
      "learning_rate": 9.983157894736843e-05,
      "loss": 0.2538,
      "step": 516
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2640974521636963,
      "learning_rate": 9.982105263157895e-05,
      "loss": 0.3228,
      "step": 517
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23674029111862183,
      "learning_rate": 9.981052631578948e-05,
      "loss": 0.2268,
      "step": 518
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2571859359741211,
      "learning_rate": 9.98e-05,
      "loss": 0.2892,
      "step": 519
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23808178305625916,
      "learning_rate": 9.978947368421054e-05,
      "loss": 0.2186,
      "step": 520
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24838222563266754,
      "learning_rate": 9.977894736842106e-05,
      "loss": 0.2263,
      "step": 521
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.25460848212242126,
      "learning_rate": 9.976842105263159e-05,
      "loss": 0.2723,
      "step": 522
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.23686319589614868,
      "learning_rate": 9.975789473684211e-05,
      "loss": 0.2442,
      "step": 523
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2580706477165222,
      "learning_rate": 9.974736842105264e-05,
      "loss": 0.2276,
      "step": 524
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2654748558998108,
      "learning_rate": 9.973684210526316e-05,
      "loss": 0.3053,
      "step": 525
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.24850520491600037,
      "learning_rate": 9.972631578947369e-05,
      "loss": 0.2503,
      "step": 526
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.269266813993454,
      "learning_rate": 9.971578947368422e-05,
      "loss": 0.3012,
      "step": 527
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.24934561550617218,
      "learning_rate": 9.970526315789475e-05,
      "loss": 0.2715,
      "step": 528
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.26221948862075806,
      "learning_rate": 9.969473684210526e-05,
      "loss": 0.2594,
      "step": 529
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.22462832927703857,
      "learning_rate": 9.968421052631578e-05,
      "loss": 0.238,
      "step": 530
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.26545941829681396,
      "learning_rate": 9.967368421052632e-05,
      "loss": 0.2953,
      "step": 531
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2740411162376404,
      "learning_rate": 9.966315789473685e-05,
      "loss": 0.2857,
      "step": 532
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2509988844394684,
      "learning_rate": 9.965263157894737e-05,
      "loss": 0.2532,
      "step": 533
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2968403697013855,
      "learning_rate": 9.96421052631579e-05,
      "loss": 0.2552,
      "step": 534
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2581062912940979,
      "learning_rate": 9.963157894736843e-05,
      "loss": 0.2526,
      "step": 535
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.25250616669654846,
      "learning_rate": 9.962105263157895e-05,
      "loss": 0.268,
      "step": 536
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.24164338409900665,
      "learning_rate": 9.961052631578947e-05,
      "loss": 0.237,
      "step": 537
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2970675826072693,
      "learning_rate": 9.960000000000001e-05,
      "loss": 0.2646,
      "step": 538
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2513038218021393,
      "learning_rate": 9.958947368421053e-05,
      "loss": 0.2972,
      "step": 539
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.24872907996177673,
      "learning_rate": 9.957894736842106e-05,
      "loss": 0.2528,
      "step": 540
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.25004348158836365,
      "learning_rate": 9.956842105263158e-05,
      "loss": 0.2181,
      "step": 541
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2668984830379486,
      "learning_rate": 9.955789473684211e-05,
      "loss": 0.2528,
      "step": 542
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2904389202594757,
      "learning_rate": 9.954736842105263e-05,
      "loss": 0.3383,
      "step": 543
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.28269827365875244,
      "learning_rate": 9.953684210526316e-05,
      "loss": 0.2349,
      "step": 544
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.24892078340053558,
      "learning_rate": 9.95263157894737e-05,
      "loss": 0.242,
      "step": 545
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2330522984266281,
      "learning_rate": 9.951578947368422e-05,
      "loss": 0.18,
      "step": 546
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.25209030508995056,
      "learning_rate": 9.950526315789474e-05,
      "loss": 0.2393,
      "step": 547
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2718767821788788,
      "learning_rate": 9.949473684210527e-05,
      "loss": 0.2663,
      "step": 548
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24313367903232574,
      "learning_rate": 9.948421052631579e-05,
      "loss": 0.2192,
      "step": 549
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.28156131505966187,
      "learning_rate": 9.947368421052632e-05,
      "loss": 0.2937,
      "step": 550
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23880364000797272,
      "learning_rate": 9.946315789473684e-05,
      "loss": 0.252,
      "step": 551
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2450999617576599,
      "learning_rate": 9.945263157894738e-05,
      "loss": 0.2228,
      "step": 552
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2461985945701599,
      "learning_rate": 9.94421052631579e-05,
      "loss": 0.1994,
      "step": 553
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24035963416099548,
      "learning_rate": 9.943157894736843e-05,
      "loss": 0.2205,
      "step": 554
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24349191784858704,
      "learning_rate": 9.942105263157895e-05,
      "loss": 0.2059,
      "step": 555
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24507704377174377,
      "learning_rate": 9.941052631578948e-05,
      "loss": 0.2219,
      "step": 556
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23108051717281342,
      "learning_rate": 9.94e-05,
      "loss": 0.1872,
      "step": 557
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.27628418803215027,
      "learning_rate": 9.938947368421053e-05,
      "loss": 0.2862,
      "step": 558
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2667631208896637,
      "learning_rate": 9.937894736842107e-05,
      "loss": 0.2047,
      "step": 559
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2606129050254822,
      "learning_rate": 9.936842105263159e-05,
      "loss": 0.2959,
      "step": 560
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2686132490634918,
      "learning_rate": 9.93578947368421e-05,
      "loss": 0.2836,
      "step": 561
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.255843847990036,
      "learning_rate": 9.934736842105263e-05,
      "loss": 0.2789,
      "step": 562
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23700763285160065,
      "learning_rate": 9.933684210526317e-05,
      "loss": 0.2203,
      "step": 563
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2448267638683319,
      "learning_rate": 9.932631578947369e-05,
      "loss": 0.2169,
      "step": 564
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2844921946525574,
      "learning_rate": 9.931578947368421e-05,
      "loss": 0.359,
      "step": 565
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.22802653908729553,
      "learning_rate": 9.930526315789474e-05,
      "loss": 0.1998,
      "step": 566
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.21241290867328644,
      "learning_rate": 9.929473684210526e-05,
      "loss": 0.1756,
      "step": 567
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24655188620090485,
      "learning_rate": 9.928421052631579e-05,
      "loss": 0.2045,
      "step": 568
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2548687756061554,
      "learning_rate": 9.927368421052631e-05,
      "loss": 0.2656,
      "step": 569
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24854324758052826,
      "learning_rate": 9.926315789473685e-05,
      "loss": 0.2183,
      "step": 570
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24699020385742188,
      "learning_rate": 9.925263157894738e-05,
      "loss": 0.203,
      "step": 571
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2538633346557617,
      "learning_rate": 9.92421052631579e-05,
      "loss": 0.2206,
      "step": 572
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2607180178165436,
      "learning_rate": 9.923157894736842e-05,
      "loss": 0.2316,
      "step": 573
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.21815328299999237,
      "learning_rate": 9.922105263157895e-05,
      "loss": 0.1949,
      "step": 574
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23725935816764832,
      "learning_rate": 9.921052631578947e-05,
      "loss": 0.2503,
      "step": 575
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24209409952163696,
      "learning_rate": 9.92e-05,
      "loss": 0.2079,
      "step": 576
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.242576465010643,
      "learning_rate": 9.918947368421054e-05,
      "loss": 0.1822,
      "step": 577
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.30234289169311523,
      "learning_rate": 9.917894736842106e-05,
      "loss": 0.2603,
      "step": 578
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.25388649106025696,
      "learning_rate": 9.916842105263159e-05,
      "loss": 0.2184,
      "step": 579
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24123699963092804,
      "learning_rate": 9.915789473684211e-05,
      "loss": 0.1912,
      "step": 580
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24456913769245148,
      "learning_rate": 9.914736842105264e-05,
      "loss": 0.1988,
      "step": 581
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.30697059631347656,
      "learning_rate": 9.913684210526316e-05,
      "loss": 0.2742,
      "step": 582
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23987658321857452,
      "learning_rate": 9.912631578947368e-05,
      "loss": 0.23,
      "step": 583
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2498040348291397,
      "learning_rate": 9.911578947368422e-05,
      "loss": 0.2088,
      "step": 584
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2631518840789795,
      "learning_rate": 9.910526315789475e-05,
      "loss": 0.2414,
      "step": 585
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.25524526834487915,
      "learning_rate": 9.909473684210526e-05,
      "loss": 0.2276,
      "step": 586
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.20751667022705078,
      "learning_rate": 9.90842105263158e-05,
      "loss": 0.161,
      "step": 587
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24634107947349548,
      "learning_rate": 9.907368421052632e-05,
      "loss": 0.1865,
      "step": 588
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24959394335746765,
      "learning_rate": 9.906315789473685e-05,
      "loss": 0.1975,
      "step": 589
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.26647600531578064,
      "learning_rate": 9.905263157894737e-05,
      "loss": 0.2848,
      "step": 590
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2467929869890213,
      "learning_rate": 9.904210526315791e-05,
      "loss": 0.196,
      "step": 591
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2657546401023865,
      "learning_rate": 9.903157894736843e-05,
      "loss": 0.2687,
      "step": 592
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2631601095199585,
      "learning_rate": 9.902105263157894e-05,
      "loss": 0.2765,
      "step": 593
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.24234852194786072,
      "learning_rate": 9.901052631578947e-05,
      "loss": 0.1977,
      "step": 594
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2920092046260834,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.291,
      "step": 595
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27790194749832153,
      "learning_rate": 9.898947368421053e-05,
      "loss": 0.2385,
      "step": 596
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2409232258796692,
      "learning_rate": 9.897894736842106e-05,
      "loss": 0.1685,
      "step": 597
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25211426615715027,
      "learning_rate": 9.896842105263158e-05,
      "loss": 0.226,
      "step": 598
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2511035203933716,
      "learning_rate": 9.89578947368421e-05,
      "loss": 0.2518,
      "step": 599
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2429226040840149,
      "learning_rate": 9.894736842105263e-05,
      "loss": 0.1872,
      "step": 600
    },
    {
      "epoch": 2.01,
      "eval_loss": 0.22379127144813538,
      "eval_runtime": 831.195,
      "eval_samples_per_second": 2.996,
      "eval_steps_per_second": 0.047,
      "eval_wer": 13.7425989404799,
      "step": 600
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.24653729796409607,
      "learning_rate": 9.893684210526316e-05,
      "loss": 0.1838,
      "step": 601
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2647036015987396,
      "learning_rate": 9.89263157894737e-05,
      "loss": 0.2463,
      "step": 602
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2585391104221344,
      "learning_rate": 9.891578947368422e-05,
      "loss": 0.2241,
      "step": 603
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2607826292514801,
      "learning_rate": 9.890526315789474e-05,
      "loss": 0.2152,
      "step": 604
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2538122832775116,
      "learning_rate": 9.889473684210527e-05,
      "loss": 0.1905,
      "step": 605
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28801217675209045,
      "learning_rate": 9.888421052631579e-05,
      "loss": 0.2768,
      "step": 606
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25753915309906006,
      "learning_rate": 9.887368421052632e-05,
      "loss": 0.1938,
      "step": 607
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26980048418045044,
      "learning_rate": 9.886315789473684e-05,
      "loss": 0.2432,
      "step": 608
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.30141589045524597,
      "learning_rate": 9.885263157894738e-05,
      "loss": 0.2319,
      "step": 609
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2671985924243927,
      "learning_rate": 9.88421052631579e-05,
      "loss": 0.231,
      "step": 610
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2385152131319046,
      "learning_rate": 9.883157894736843e-05,
      "loss": 0.1941,
      "step": 611
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2569640576839447,
      "learning_rate": 9.882105263157895e-05,
      "loss": 0.2008,
      "step": 612
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26612889766693115,
      "learning_rate": 9.881052631578948e-05,
      "loss": 0.1935,
      "step": 613
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.267340749502182,
      "learning_rate": 9.88e-05,
      "loss": 0.175,
      "step": 614
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26624706387519836,
      "learning_rate": 9.878947368421053e-05,
      "loss": 0.2394,
      "step": 615
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2689056992530823,
      "learning_rate": 9.877894736842107e-05,
      "loss": 0.2133,
      "step": 616
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.24234271049499512,
      "learning_rate": 9.876842105263159e-05,
      "loss": 0.2169,
      "step": 617
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.29207152128219604,
      "learning_rate": 9.87578947368421e-05,
      "loss": 0.3113,
      "step": 618
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2752191424369812,
      "learning_rate": 9.874736842105264e-05,
      "loss": 0.2118,
      "step": 619
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.30075278878211975,
      "learning_rate": 9.873684210526316e-05,
      "loss": 0.272,
      "step": 620
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26390400528907776,
      "learning_rate": 9.872631578947369e-05,
      "loss": 0.2194,
      "step": 621
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2727772891521454,
      "learning_rate": 9.871578947368421e-05,
      "loss": 0.2194,
      "step": 622
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26980137825012207,
      "learning_rate": 9.870526315789475e-05,
      "loss": 0.1977,
      "step": 623
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28904569149017334,
      "learning_rate": 9.869473684210528e-05,
      "loss": 0.2063,
      "step": 624
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2722660005092621,
      "learning_rate": 9.868421052631579e-05,
      "loss": 0.227,
      "step": 625
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26949194073677063,
      "learning_rate": 9.867368421052631e-05,
      "loss": 0.2131,
      "step": 626
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.271896630525589,
      "learning_rate": 9.866315789473685e-05,
      "loss": 0.2423,
      "step": 627
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.29129838943481445,
      "learning_rate": 9.865263157894737e-05,
      "loss": 0.2691,
      "step": 628
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2718903124332428,
      "learning_rate": 9.86421052631579e-05,
      "loss": 0.2336,
      "step": 629
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27427205443382263,
      "learning_rate": 9.863157894736842e-05,
      "loss": 0.2387,
      "step": 630
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.24997566640377045,
      "learning_rate": 9.862105263157895e-05,
      "loss": 0.2129,
      "step": 631
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.278430700302124,
      "learning_rate": 9.861052631578947e-05,
      "loss": 0.22,
      "step": 632
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2709086239337921,
      "learning_rate": 9.86e-05,
      "loss": 0.2322,
      "step": 633
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2708875834941864,
      "learning_rate": 9.858947368421054e-05,
      "loss": 0.2492,
      "step": 634
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.31482332944869995,
      "learning_rate": 9.857894736842106e-05,
      "loss": 0.2752,
      "step": 635
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2607415020465851,
      "learning_rate": 9.856842105263159e-05,
      "loss": 0.2462,
      "step": 636
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2577612102031708,
      "learning_rate": 9.855789473684211e-05,
      "loss": 0.1804,
      "step": 637
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.29295942187309265,
      "learning_rate": 9.854736842105263e-05,
      "loss": 0.2454,
      "step": 638
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25676900148391724,
      "learning_rate": 9.853684210526316e-05,
      "loss": 0.2,
      "step": 639
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27957093715667725,
      "learning_rate": 9.852631578947368e-05,
      "loss": 0.2186,
      "step": 640
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2833866477012634,
      "learning_rate": 9.851578947368422e-05,
      "loss": 0.245,
      "step": 641
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.29102402925491333,
      "learning_rate": 9.850526315789475e-05,
      "loss": 0.2057,
      "step": 642
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26953914761543274,
      "learning_rate": 9.849473684210527e-05,
      "loss": 0.2257,
      "step": 643
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2780093252658844,
      "learning_rate": 9.84842105263158e-05,
      "loss": 0.2077,
      "step": 644
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28228896856307983,
      "learning_rate": 9.847368421052632e-05,
      "loss": 0.2023,
      "step": 645
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2612012028694153,
      "learning_rate": 9.846315789473685e-05,
      "loss": 0.2045,
      "step": 646
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2692549228668213,
      "learning_rate": 9.845263157894737e-05,
      "loss": 0.2395,
      "step": 647
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.24971701204776764,
      "learning_rate": 9.844210526315791e-05,
      "loss": 0.1926,
      "step": 648
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28210803866386414,
      "learning_rate": 9.843157894736843e-05,
      "loss": 0.2118,
      "step": 649
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25535550713539124,
      "learning_rate": 9.842105263157894e-05,
      "loss": 0.1962,
      "step": 650
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27228638529777527,
      "learning_rate": 9.841052631578948e-05,
      "loss": 0.2286,
      "step": 651
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27053898572921753,
      "learning_rate": 9.84e-05,
      "loss": 0.2273,
      "step": 652
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25819557905197144,
      "learning_rate": 9.838947368421053e-05,
      "loss": 0.1552,
      "step": 653
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.29346293210983276,
      "learning_rate": 9.837894736842106e-05,
      "loss": 0.2507,
      "step": 654
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27642568945884705,
      "learning_rate": 9.83684210526316e-05,
      "loss": 0.211,
      "step": 655
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28229260444641113,
      "learning_rate": 9.83578947368421e-05,
      "loss": 0.2228,
      "step": 656
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.25498127937316895,
      "learning_rate": 9.834736842105263e-05,
      "loss": 0.2001,
      "step": 657
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2695598006248474,
      "learning_rate": 9.833684210526315e-05,
      "loss": 0.2319,
      "step": 658
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26894259452819824,
      "learning_rate": 9.832631578947369e-05,
      "loss": 0.288,
      "step": 659
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2853916585445404,
      "learning_rate": 9.831578947368422e-05,
      "loss": 0.2601,
      "step": 660
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.3044170141220093,
      "learning_rate": 9.830526315789474e-05,
      "loss": 0.2217,
      "step": 661
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27966824173927307,
      "learning_rate": 9.829473684210527e-05,
      "loss": 0.2513,
      "step": 662
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2612883746623993,
      "learning_rate": 9.828421052631579e-05,
      "loss": 0.1875,
      "step": 663
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.300693154335022,
      "learning_rate": 9.827368421052632e-05,
      "loss": 0.2308,
      "step": 664
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2898908257484436,
      "learning_rate": 9.826315789473684e-05,
      "loss": 0.2403,
      "step": 665
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28531259298324585,
      "learning_rate": 9.825263157894738e-05,
      "loss": 0.2674,
      "step": 666
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2584491968154907,
      "learning_rate": 9.82421052631579e-05,
      "loss": 0.1848,
      "step": 667
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.31264621019363403,
      "learning_rate": 9.823157894736843e-05,
      "loss": 0.2206,
      "step": 668
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2816644310951233,
      "learning_rate": 9.822105263157895e-05,
      "loss": 0.1987,
      "step": 669
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2810782194137573,
      "learning_rate": 9.821052631578948e-05,
      "loss": 0.2372,
      "step": 670
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.31857195496559143,
      "learning_rate": 9.82e-05,
      "loss": 0.2548,
      "step": 671
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.27112385630607605,
      "learning_rate": 9.818947368421053e-05,
      "loss": 0.1974,
      "step": 672
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2896795868873596,
      "learning_rate": 9.817894736842106e-05,
      "loss": 0.2247,
      "step": 673
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2687084674835205,
      "learning_rate": 9.816842105263159e-05,
      "loss": 0.1946,
      "step": 674
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2836204469203949,
      "learning_rate": 9.815789473684211e-05,
      "loss": 0.2086,
      "step": 675
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2881893515586853,
      "learning_rate": 9.814736842105264e-05,
      "loss": 0.2432,
      "step": 676
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2915782034397125,
      "learning_rate": 9.813684210526316e-05,
      "loss": 0.1858,
      "step": 677
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.292094349861145,
      "learning_rate": 9.812631578947369e-05,
      "loss": 0.2314,
      "step": 678
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28689146041870117,
      "learning_rate": 9.811578947368421e-05,
      "loss": 0.2262,
      "step": 679
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.3186214864253998,
      "learning_rate": 9.810526315789475e-05,
      "loss": 0.2513,
      "step": 680
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2565285861492157,
      "learning_rate": 9.809473684210528e-05,
      "loss": 0.2014,
      "step": 681
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.3226298689842224,
      "learning_rate": 9.808421052631579e-05,
      "loss": 0.2497,
      "step": 682
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2574724853038788,
      "learning_rate": 9.807368421052631e-05,
      "loss": 0.1654,
      "step": 683
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.31421172618865967,
      "learning_rate": 9.806315789473685e-05,
      "loss": 0.2977,
      "step": 684
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2811964154243469,
      "learning_rate": 9.805263157894737e-05,
      "loss": 0.2311,
      "step": 685
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.30948406457901,
      "learning_rate": 9.80421052631579e-05,
      "loss": 0.1916,
      "step": 686
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26469752192497253,
      "learning_rate": 9.803157894736844e-05,
      "loss": 0.195,
      "step": 687
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.30103591084480286,
      "learning_rate": 9.802105263157895e-05,
      "loss": 0.2088,
      "step": 688
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2579236626625061,
      "learning_rate": 9.801052631578947e-05,
      "loss": 0.1691,
      "step": 689
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2823895514011383,
      "learning_rate": 9.8e-05,
      "loss": 0.2415,
      "step": 690
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.28905776143074036,
      "learning_rate": 9.798947368421054e-05,
      "loss": 0.2596,
      "step": 691
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.3075902760028839,
      "learning_rate": 9.797894736842106e-05,
      "loss": 0.2176,
      "step": 692
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.3418281376361847,
      "learning_rate": 9.796842105263158e-05,
      "loss": 0.2048,
      "step": 693
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2598305344581604,
      "learning_rate": 9.795789473684211e-05,
      "loss": 0.186,
      "step": 694
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.293375700712204,
      "learning_rate": 9.794736842105263e-05,
      "loss": 0.2256,
      "step": 695
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30969348549842834,
      "learning_rate": 9.793684210526316e-05,
      "loss": 0.3251,
      "step": 696
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29983019828796387,
      "learning_rate": 9.792631578947368e-05,
      "loss": 0.2362,
      "step": 697
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3339516520500183,
      "learning_rate": 9.791578947368422e-05,
      "loss": 0.2323,
      "step": 698
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30915525555610657,
      "learning_rate": 9.790526315789475e-05,
      "loss": 0.2059,
      "step": 699
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2877940833568573,
      "learning_rate": 9.789473684210527e-05,
      "loss": 0.2442,
      "step": 700
    },
    {
      "epoch": 2.02,
      "eval_loss": 0.20471152663230896,
      "eval_runtime": 833.5264,
      "eval_samples_per_second": 2.987,
      "eval_steps_per_second": 0.047,
      "eval_wer": 13.095980056092241,
      "step": 700
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2826087474822998,
      "learning_rate": 9.78842105263158e-05,
      "loss": 0.2271,
      "step": 701
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28618642687797546,
      "learning_rate": 9.787368421052632e-05,
      "loss": 0.2331,
      "step": 702
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2901795506477356,
      "learning_rate": 9.786315789473684e-05,
      "loss": 0.2077,
      "step": 703
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2719528079032898,
      "learning_rate": 9.785263157894737e-05,
      "loss": 0.1762,
      "step": 704
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2969333827495575,
      "learning_rate": 9.784210526315791e-05,
      "loss": 0.2273,
      "step": 705
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3046903908252716,
      "learning_rate": 9.783157894736843e-05,
      "loss": 0.2676,
      "step": 706
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2752586901187897,
      "learning_rate": 9.782105263157894e-05,
      "loss": 0.1866,
      "step": 707
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3232584595680237,
      "learning_rate": 9.781052631578948e-05,
      "loss": 0.3017,
      "step": 708
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.35281845927238464,
      "learning_rate": 9.78e-05,
      "loss": 0.232,
      "step": 709
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3260031044483185,
      "learning_rate": 9.778947368421053e-05,
      "loss": 0.2321,
      "step": 710
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3163772523403168,
      "learning_rate": 9.777894736842105e-05,
      "loss": 0.1964,
      "step": 711
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.372053325176239,
      "learning_rate": 9.776842105263159e-05,
      "loss": 0.2266,
      "step": 712
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30625662207603455,
      "learning_rate": 9.775789473684212e-05,
      "loss": 0.2201,
      "step": 713
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28425195813179016,
      "learning_rate": 9.774736842105263e-05,
      "loss": 0.2109,
      "step": 714
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29374799132347107,
      "learning_rate": 9.773684210526315e-05,
      "loss": 0.2024,
      "step": 715
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3023265302181244,
      "learning_rate": 9.772631578947369e-05,
      "loss": 0.1936,
      "step": 716
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3091413378715515,
      "learning_rate": 9.771578947368422e-05,
      "loss": 0.2165,
      "step": 717
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2698776125907898,
      "learning_rate": 9.770526315789474e-05,
      "loss": 0.2112,
      "step": 718
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2929629385471344,
      "learning_rate": 9.769473684210528e-05,
      "loss": 0.2299,
      "step": 719
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2752354145050049,
      "learning_rate": 9.768421052631579e-05,
      "loss": 0.2084,
      "step": 720
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.31322142481803894,
      "learning_rate": 9.767368421052631e-05,
      "loss": 0.2409,
      "step": 721
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3071504235267639,
      "learning_rate": 9.766315789473684e-05,
      "loss": 0.1948,
      "step": 722
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29595017433166504,
      "learning_rate": 9.765263157894738e-05,
      "loss": 0.1977,
      "step": 723
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2924153804779053,
      "learning_rate": 9.76421052631579e-05,
      "loss": 0.201,
      "step": 724
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2825627624988556,
      "learning_rate": 9.763157894736843e-05,
      "loss": 0.1824,
      "step": 725
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28035175800323486,
      "learning_rate": 9.762105263157895e-05,
      "loss": 0.1764,
      "step": 726
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2876114547252655,
      "learning_rate": 9.761052631578948e-05,
      "loss": 0.1826,
      "step": 727
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3165036141872406,
      "learning_rate": 9.76e-05,
      "loss": 0.2362,
      "step": 728
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29549381136894226,
      "learning_rate": 9.758947368421053e-05,
      "loss": 0.2089,
      "step": 729
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30859071016311646,
      "learning_rate": 9.757894736842106e-05,
      "loss": 0.1987,
      "step": 730
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2846211791038513,
      "learning_rate": 9.756842105263159e-05,
      "loss": 0.1812,
      "step": 731
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2728375792503357,
      "learning_rate": 9.755789473684211e-05,
      "loss": 0.1707,
      "step": 732
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3090757727622986,
      "learning_rate": 9.754736842105264e-05,
      "loss": 0.2122,
      "step": 733
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29170459508895874,
      "learning_rate": 9.753684210526316e-05,
      "loss": 0.2364,
      "step": 734
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2876460552215576,
      "learning_rate": 9.752631578947369e-05,
      "loss": 0.186,
      "step": 735
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2736218273639679,
      "learning_rate": 9.751578947368421e-05,
      "loss": 0.1856,
      "step": 736
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29384124279022217,
      "learning_rate": 9.750526315789475e-05,
      "loss": 0.2367,
      "step": 737
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2849638760089874,
      "learning_rate": 9.749473684210527e-05,
      "loss": 0.1956,
      "step": 738
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3164781630039215,
      "learning_rate": 9.748421052631579e-05,
      "loss": 0.1538,
      "step": 739
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30768704414367676,
      "learning_rate": 9.747368421052632e-05,
      "loss": 0.2165,
      "step": 740
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3480631411075592,
      "learning_rate": 9.746315789473685e-05,
      "loss": 0.2868,
      "step": 741
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.31616464257240295,
      "learning_rate": 9.745263157894737e-05,
      "loss": 0.2039,
      "step": 742
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30164635181427,
      "learning_rate": 9.74421052631579e-05,
      "loss": 0.2278,
      "step": 743
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29040881991386414,
      "learning_rate": 9.743157894736844e-05,
      "loss": 0.1945,
      "step": 744
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.31436511874198914,
      "learning_rate": 9.742105263157896e-05,
      "loss": 0.2414,
      "step": 745
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.32306304574012756,
      "learning_rate": 9.741052631578947e-05,
      "loss": 0.1643,
      "step": 746
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.33641090989112854,
      "learning_rate": 9.74e-05,
      "loss": 0.2222,
      "step": 747
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30154359340667725,
      "learning_rate": 9.738947368421053e-05,
      "loss": 0.2408,
      "step": 748
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.32292163372039795,
      "learning_rate": 9.737894736842106e-05,
      "loss": 0.221,
      "step": 749
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3328494131565094,
      "learning_rate": 9.736842105263158e-05,
      "loss": 0.2115,
      "step": 750
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28612515330314636,
      "learning_rate": 9.735789473684211e-05,
      "loss": 0.1745,
      "step": 751
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28476279973983765,
      "learning_rate": 9.734736842105263e-05,
      "loss": 0.1988,
      "step": 752
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2773245573043823,
      "learning_rate": 9.733684210526316e-05,
      "loss": 0.1872,
      "step": 753
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3171006441116333,
      "learning_rate": 9.732631578947368e-05,
      "loss": 0.2172,
      "step": 754
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3003760874271393,
      "learning_rate": 9.731578947368422e-05,
      "loss": 0.1895,
      "step": 755
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2964727282524109,
      "learning_rate": 9.730526315789474e-05,
      "loss": 0.2098,
      "step": 756
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30738452076911926,
      "learning_rate": 9.729473684210527e-05,
      "loss": 0.1951,
      "step": 757
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.25981611013412476,
      "learning_rate": 9.72842105263158e-05,
      "loss": 0.1768,
      "step": 758
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2708856761455536,
      "learning_rate": 9.727368421052632e-05,
      "loss": 0.1759,
      "step": 759
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.29980260133743286,
      "learning_rate": 9.726315789473684e-05,
      "loss": 0.2139,
      "step": 760
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3231894075870514,
      "learning_rate": 9.725263157894737e-05,
      "loss": 0.2786,
      "step": 761
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3170197904109955,
      "learning_rate": 9.72421052631579e-05,
      "loss": 0.2598,
      "step": 762
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2820824384689331,
      "learning_rate": 9.723157894736843e-05,
      "loss": 0.1903,
      "step": 763
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.35511085391044617,
      "learning_rate": 9.722105263157896e-05,
      "loss": 0.2567,
      "step": 764
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3172774314880371,
      "learning_rate": 9.721052631578948e-05,
      "loss": 0.2201,
      "step": 765
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3303271532058716,
      "learning_rate": 9.72e-05,
      "loss": 0.2819,
      "step": 766
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2770828306674957,
      "learning_rate": 9.718947368421053e-05,
      "loss": 0.1479,
      "step": 767
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.27594369649887085,
      "learning_rate": 9.717894736842105e-05,
      "loss": 0.1756,
      "step": 768
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3019154667854309,
      "learning_rate": 9.716842105263159e-05,
      "loss": 0.1615,
      "step": 769
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.31098780035972595,
      "learning_rate": 9.715789473684212e-05,
      "loss": 0.2749,
      "step": 770
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.27775388956069946,
      "learning_rate": 9.714736842105263e-05,
      "loss": 0.1844,
      "step": 771
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30439475178718567,
      "learning_rate": 9.713684210526317e-05,
      "loss": 0.1947,
      "step": 772
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3059980273246765,
      "learning_rate": 9.712631578947369e-05,
      "loss": 0.2015,
      "step": 773
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2880007326602936,
      "learning_rate": 9.711578947368422e-05,
      "loss": 0.2027,
      "step": 774
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2789674997329712,
      "learning_rate": 9.710526315789474e-05,
      "loss": 0.1949,
      "step": 775
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.32311826944351196,
      "learning_rate": 9.709473684210528e-05,
      "loss": 0.2505,
      "step": 776
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3048681616783142,
      "learning_rate": 9.708421052631579e-05,
      "loss": 0.173,
      "step": 777
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.27907052636146545,
      "learning_rate": 9.707368421052631e-05,
      "loss": 0.2015,
      "step": 778
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2998292148113251,
      "learning_rate": 9.706315789473684e-05,
      "loss": 0.2016,
      "step": 779
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30944621562957764,
      "learning_rate": 9.705263157894738e-05,
      "loss": 0.2358,
      "step": 780
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3090681731700897,
      "learning_rate": 9.70421052631579e-05,
      "loss": 0.2278,
      "step": 781
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.27855807542800903,
      "learning_rate": 9.703157894736843e-05,
      "loss": 0.2076,
      "step": 782
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2887408435344696,
      "learning_rate": 9.702105263157895e-05,
      "loss": 0.1888,
      "step": 783
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30138126015663147,
      "learning_rate": 9.701052631578948e-05,
      "loss": 0.243,
      "step": 784
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3121227025985718,
      "learning_rate": 9.7e-05,
      "loss": 0.1698,
      "step": 785
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.290066659450531,
      "learning_rate": 9.698947368421052e-05,
      "loss": 0.228,
      "step": 786
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2968388497829437,
      "learning_rate": 9.697894736842106e-05,
      "loss": 0.2356,
      "step": 787
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.27785083651542664,
      "learning_rate": 9.696842105263159e-05,
      "loss": 0.1719,
      "step": 788
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28800511360168457,
      "learning_rate": 9.695789473684211e-05,
      "loss": 0.1603,
      "step": 789
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28268441557884216,
      "learning_rate": 9.694736842105264e-05,
      "loss": 0.2145,
      "step": 790
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.30187156796455383,
      "learning_rate": 9.693684210526316e-05,
      "loss": 0.1754,
      "step": 791
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.28954169154167175,
      "learning_rate": 9.692631578947369e-05,
      "loss": 0.2064,
      "step": 792
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.31996190547943115,
      "learning_rate": 9.691578947368421e-05,
      "loss": 0.1987,
      "step": 793
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3136448860168457,
      "learning_rate": 9.690526315789475e-05,
      "loss": 0.2033,
      "step": 794
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2894825041294098,
      "learning_rate": 9.689473684210527e-05,
      "loss": 0.1531,
      "step": 795
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.3255253732204437,
      "learning_rate": 9.68842105263158e-05,
      "loss": 0.1977,
      "step": 796
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.31028246879577637,
      "learning_rate": 9.687368421052632e-05,
      "loss": 0.2261,
      "step": 797
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.3044380247592926,
      "learning_rate": 9.686315789473685e-05,
      "loss": 0.1945,
      "step": 798
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.29980790615081787,
      "learning_rate": 9.685263157894737e-05,
      "loss": 0.1968,
      "step": 799
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.35521000623703003,
      "learning_rate": 9.68421052631579e-05,
      "loss": 0.1876,
      "step": 800
    },
    {
      "epoch": 2.03,
      "eval_loss": 0.18926119804382324,
      "eval_runtime": 860.1198,
      "eval_samples_per_second": 2.895,
      "eval_steps_per_second": 0.045,
      "eval_wer": 13.695855406668745,
      "step": 800
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.30180513858795166,
      "learning_rate": 9.683157894736843e-05,
      "loss": 0.1493,
      "step": 801
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2842637300491333,
      "learning_rate": 9.682105263157896e-05,
      "loss": 0.1613,
      "step": 802
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.28713443875312805,
      "learning_rate": 9.681052631578947e-05,
      "loss": 0.1743,
      "step": 803
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.3446086645126343,
      "learning_rate": 9.680000000000001e-05,
      "loss": 0.1704,
      "step": 804
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2841840982437134,
      "learning_rate": 9.678947368421053e-05,
      "loss": 0.1862,
      "step": 805
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2747141420841217,
      "learning_rate": 9.677894736842106e-05,
      "loss": 0.1667,
      "step": 806
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.28294044733047485,
      "learning_rate": 9.676842105263158e-05,
      "loss": 0.1378,
      "step": 807
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.3192153871059418,
      "learning_rate": 9.675789473684212e-05,
      "loss": 0.1786,
      "step": 808
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2865828573703766,
      "learning_rate": 9.674736842105263e-05,
      "loss": 0.2118,
      "step": 809
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.28579822182655334,
      "learning_rate": 9.673684210526316e-05,
      "loss": 0.2201,
      "step": 810
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.31276801228523254,
      "learning_rate": 9.672631578947368e-05,
      "loss": 0.1847,
      "step": 811
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.3386453092098236,
      "learning_rate": 9.671578947368422e-05,
      "loss": 0.2088,
      "step": 812
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.30718153715133667,
      "learning_rate": 9.670526315789474e-05,
      "loss": 0.1747,
      "step": 813
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.355256587266922,
      "learning_rate": 9.669473684210527e-05,
      "loss": 0.1982,
      "step": 814
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.29937076568603516,
      "learning_rate": 9.668421052631579e-05,
      "loss": 0.191,
      "step": 815
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2587123215198517,
      "learning_rate": 9.667368421052632e-05,
      "loss": 0.1589,
      "step": 816
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2943353056907654,
      "learning_rate": 9.666315789473684e-05,
      "loss": 0.1528,
      "step": 817
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.33058926463127136,
      "learning_rate": 9.665263157894737e-05,
      "loss": 0.1811,
      "step": 818
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.28764036297798157,
      "learning_rate": 9.66421052631579e-05,
      "loss": 0.1083,
      "step": 819
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.23430022597312927,
      "learning_rate": 9.663157894736843e-05,
      "loss": 0.1139,
      "step": 820
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.27560415863990784,
      "learning_rate": 9.662105263157895e-05,
      "loss": 0.1445,
      "step": 821
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.26911813020706177,
      "learning_rate": 9.661052631578948e-05,
      "loss": 0.1684,
      "step": 822
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2811996638774872,
      "learning_rate": 9.66e-05,
      "loss": 0.173,
      "step": 823
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.25268277525901794,
      "learning_rate": 9.658947368421053e-05,
      "loss": 0.1732,
      "step": 824
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2571946978569031,
      "learning_rate": 9.657894736842105e-05,
      "loss": 0.2194,
      "step": 825
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2880355417728424,
      "learning_rate": 9.656842105263159e-05,
      "loss": 0.1781,
      "step": 826
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.276178240776062,
      "learning_rate": 9.655789473684212e-05,
      "loss": 0.1705,
      "step": 827
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2503052353858948,
      "learning_rate": 9.654736842105263e-05,
      "loss": 0.1536,
      "step": 828
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.28265663981437683,
      "learning_rate": 9.653684210526316e-05,
      "loss": 0.1831,
      "step": 829
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.32202479243278503,
      "learning_rate": 9.652631578947369e-05,
      "loss": 0.1815,
      "step": 830
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.27326270937919617,
      "learning_rate": 9.651578947368421e-05,
      "loss": 0.1622,
      "step": 831
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3132331967353821,
      "learning_rate": 9.650526315789474e-05,
      "loss": 0.1938,
      "step": 832
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2883826196193695,
      "learning_rate": 9.649473684210528e-05,
      "loss": 0.1363,
      "step": 833
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2833994925022125,
      "learning_rate": 9.64842105263158e-05,
      "loss": 0.2328,
      "step": 834
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.29740196466445923,
      "learning_rate": 9.647368421052631e-05,
      "loss": 0.1574,
      "step": 835
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2754467725753784,
      "learning_rate": 9.646315789473685e-05,
      "loss": 0.2075,
      "step": 836
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.27406081557273865,
      "learning_rate": 9.645263157894738e-05,
      "loss": 0.1989,
      "step": 837
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2731355130672455,
      "learning_rate": 9.64421052631579e-05,
      "loss": 0.1653,
      "step": 838
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.27221015095710754,
      "learning_rate": 9.643157894736842e-05,
      "loss": 0.1581,
      "step": 839
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.33819106221199036,
      "learning_rate": 9.642105263157896e-05,
      "loss": 0.1739,
      "step": 840
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2829468846321106,
      "learning_rate": 9.641052631578947e-05,
      "loss": 0.1559,
      "step": 841
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.29186978936195374,
      "learning_rate": 9.64e-05,
      "loss": 0.1632,
      "step": 842
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2961621880531311,
      "learning_rate": 9.638947368421052e-05,
      "loss": 0.1973,
      "step": 843
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.29168376326560974,
      "learning_rate": 9.637894736842106e-05,
      "loss": 0.1627,
      "step": 844
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.29657310247421265,
      "learning_rate": 9.636842105263159e-05,
      "loss": 0.1955,
      "step": 845
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2732866406440735,
      "learning_rate": 9.635789473684211e-05,
      "loss": 0.1577,
      "step": 846
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3125471770763397,
      "learning_rate": 9.634736842105264e-05,
      "loss": 0.2321,
      "step": 847
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2622344493865967,
      "learning_rate": 9.633684210526316e-05,
      "loss": 0.1525,
      "step": 848
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2642189860343933,
      "learning_rate": 9.632631578947368e-05,
      "loss": 0.139,
      "step": 849
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2872953712940216,
      "learning_rate": 9.631578947368421e-05,
      "loss": 0.1753,
      "step": 850
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.30057814717292786,
      "learning_rate": 9.630526315789475e-05,
      "loss": 0.1852,
      "step": 851
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2671486437320709,
      "learning_rate": 9.629473684210527e-05,
      "loss": 0.1882,
      "step": 852
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3436982333660126,
      "learning_rate": 9.62842105263158e-05,
      "loss": 0.1845,
      "step": 853
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2968534529209137,
      "learning_rate": 9.627368421052632e-05,
      "loss": 0.1733,
      "step": 854
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2944631278514862,
      "learning_rate": 9.626315789473685e-05,
      "loss": 0.1913,
      "step": 855
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.28916770219802856,
      "learning_rate": 9.625263157894737e-05,
      "loss": 0.1771,
      "step": 856
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3118036687374115,
      "learning_rate": 9.62421052631579e-05,
      "loss": 0.1898,
      "step": 857
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.256500244140625,
      "learning_rate": 9.623157894736843e-05,
      "loss": 0.1586,
      "step": 858
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2759123146533966,
      "learning_rate": 9.622105263157896e-05,
      "loss": 0.1584,
      "step": 859
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3231126666069031,
      "learning_rate": 9.621052631578947e-05,
      "loss": 0.2006,
      "step": 860
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.28980740904808044,
      "learning_rate": 9.620000000000001e-05,
      "loss": 0.1735,
      "step": 861
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2878541350364685,
      "learning_rate": 9.618947368421053e-05,
      "loss": 0.1575,
      "step": 862
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2808375060558319,
      "learning_rate": 9.617894736842106e-05,
      "loss": 0.1808,
      "step": 863
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3181682229042053,
      "learning_rate": 9.616842105263158e-05,
      "loss": 0.1741,
      "step": 864
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.29390770196914673,
      "learning_rate": 9.615789473684212e-05,
      "loss": 0.1565,
      "step": 865
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.32767361402511597,
      "learning_rate": 9.614736842105264e-05,
      "loss": 0.1551,
      "step": 866
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.34257417917251587,
      "learning_rate": 9.613684210526316e-05,
      "loss": 0.2537,
      "step": 867
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.29766449332237244,
      "learning_rate": 9.61263157894737e-05,
      "loss": 0.1457,
      "step": 868
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.29108765721321106,
      "learning_rate": 9.611578947368422e-05,
      "loss": 0.1367,
      "step": 869
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32739049196243286,
      "learning_rate": 9.610526315789474e-05,
      "loss": 0.2478,
      "step": 870
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2896397113800049,
      "learning_rate": 9.609473684210527e-05,
      "loss": 0.1563,
      "step": 871
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2800620198249817,
      "learning_rate": 9.60842105263158e-05,
      "loss": 0.1395,
      "step": 872
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2552597224712372,
      "learning_rate": 9.607368421052632e-05,
      "loss": 0.1414,
      "step": 873
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2641630470752716,
      "learning_rate": 9.606315789473684e-05,
      "loss": 0.1181,
      "step": 874
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32643482089042664,
      "learning_rate": 9.605263157894737e-05,
      "loss": 0.2451,
      "step": 875
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3016251027584076,
      "learning_rate": 9.60421052631579e-05,
      "loss": 0.1529,
      "step": 876
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28303974866867065,
      "learning_rate": 9.603157894736843e-05,
      "loss": 0.2066,
      "step": 877
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.30264952778816223,
      "learning_rate": 9.602105263157895e-05,
      "loss": 0.1676,
      "step": 878
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.37920820713043213,
      "learning_rate": 9.601052631578948e-05,
      "loss": 0.1473,
      "step": 879
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3113428056240082,
      "learning_rate": 9.6e-05,
      "loss": 0.1474,
      "step": 880
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28246504068374634,
      "learning_rate": 9.598947368421053e-05,
      "loss": 0.1167,
      "step": 881
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.27161505818367004,
      "learning_rate": 9.597894736842105e-05,
      "loss": 0.1289,
      "step": 882
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2924511432647705,
      "learning_rate": 9.596842105263159e-05,
      "loss": 0.1825,
      "step": 883
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.29950234293937683,
      "learning_rate": 9.595789473684211e-05,
      "loss": 0.1659,
      "step": 884
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2677803635597229,
      "learning_rate": 9.594736842105264e-05,
      "loss": 0.1159,
      "step": 885
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.26029056310653687,
      "learning_rate": 9.593684210526316e-05,
      "loss": 0.129,
      "step": 886
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3248835504055023,
      "learning_rate": 9.592631578947369e-05,
      "loss": 0.1658,
      "step": 887
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3163585066795349,
      "learning_rate": 9.591578947368421e-05,
      "loss": 0.1595,
      "step": 888
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3158514201641083,
      "learning_rate": 9.590526315789474e-05,
      "loss": 0.1601,
      "step": 889
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28598952293395996,
      "learning_rate": 9.589473684210528e-05,
      "loss": 0.1632,
      "step": 890
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.322284996509552,
      "learning_rate": 9.58842105263158e-05,
      "loss": 0.1744,
      "step": 891
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3880040645599365,
      "learning_rate": 9.587368421052631e-05,
      "loss": 0.1524,
      "step": 892
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3326827883720398,
      "learning_rate": 9.586315789473685e-05,
      "loss": 0.1916,
      "step": 893
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.35611891746520996,
      "learning_rate": 9.585263157894737e-05,
      "loss": 0.1715,
      "step": 894
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3051918148994446,
      "learning_rate": 9.58421052631579e-05,
      "loss": 0.1842,
      "step": 895
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.37348780035972595,
      "learning_rate": 9.583157894736842e-05,
      "loss": 0.1913,
      "step": 896
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.39424410462379456,
      "learning_rate": 9.582105263157896e-05,
      "loss": 0.1865,
      "step": 897
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3699371814727783,
      "learning_rate": 9.581052631578947e-05,
      "loss": 0.1663,
      "step": 898
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3256705403327942,
      "learning_rate": 9.58e-05,
      "loss": 0.1791,
      "step": 899
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3230287730693817,
      "learning_rate": 9.578947368421052e-05,
      "loss": 0.1762,
      "step": 900
    },
    {
      "epoch": 3.01,
      "eval_loss": 0.17756690084934235,
      "eval_runtime": 827.5719,
      "eval_samples_per_second": 3.009,
      "eval_steps_per_second": 0.047,
      "eval_wer": 12.223434091617326,
      "step": 900
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.33852899074554443,
      "learning_rate": 9.577894736842106e-05,
      "loss": 0.1472,
      "step": 901
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.307843416929245,
      "learning_rate": 9.576842105263159e-05,
      "loss": 0.1569,
      "step": 902
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.331548810005188,
      "learning_rate": 9.575789473684211e-05,
      "loss": 0.1954,
      "step": 903
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3374323844909668,
      "learning_rate": 9.574736842105265e-05,
      "loss": 0.1717,
      "step": 904
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.34257328510284424,
      "learning_rate": 9.573684210526316e-05,
      "loss": 0.1512,
      "step": 905
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2853412330150604,
      "learning_rate": 9.572631578947368e-05,
      "loss": 0.1982,
      "step": 906
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32730603218078613,
      "learning_rate": 9.571578947368421e-05,
      "loss": 0.1605,
      "step": 907
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3376014828681946,
      "learning_rate": 9.570526315789475e-05,
      "loss": 0.1467,
      "step": 908
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.33412298560142517,
      "learning_rate": 9.569473684210527e-05,
      "loss": 0.2155,
      "step": 909
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32489559054374695,
      "learning_rate": 9.56842105263158e-05,
      "loss": 0.2056,
      "step": 910
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.43207183480262756,
      "learning_rate": 9.567368421052632e-05,
      "loss": 0.2218,
      "step": 911
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3488922119140625,
      "learning_rate": 9.566315789473684e-05,
      "loss": 0.2529,
      "step": 912
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28107908368110657,
      "learning_rate": 9.565263157894737e-05,
      "loss": 0.1638,
      "step": 913
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3352530300617218,
      "learning_rate": 9.56421052631579e-05,
      "loss": 0.2262,
      "step": 914
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3973303437232971,
      "learning_rate": 9.563157894736843e-05,
      "loss": 0.1718,
      "step": 915
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3355722427368164,
      "learning_rate": 9.562105263157896e-05,
      "loss": 0.1774,
      "step": 916
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3039413392543793,
      "learning_rate": 9.561052631578948e-05,
      "loss": 0.1858,
      "step": 917
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32500261068344116,
      "learning_rate": 9.56e-05,
      "loss": 0.1571,
      "step": 918
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3934527039527893,
      "learning_rate": 9.558947368421053e-05,
      "loss": 0.1767,
      "step": 919
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3376103639602661,
      "learning_rate": 9.557894736842106e-05,
      "loss": 0.1841,
      "step": 920
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32632195949554443,
      "learning_rate": 9.556842105263158e-05,
      "loss": 0.15,
      "step": 921
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.33911776542663574,
      "learning_rate": 9.555789473684212e-05,
      "loss": 0.1728,
      "step": 922
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.4071294069290161,
      "learning_rate": 9.554736842105264e-05,
      "loss": 0.1812,
      "step": 923
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.43776610493659973,
      "learning_rate": 9.553684210526315e-05,
      "loss": 0.2086,
      "step": 924
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3033351004123688,
      "learning_rate": 9.552631578947369e-05,
      "loss": 0.1891,
      "step": 925
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3044901490211487,
      "learning_rate": 9.551578947368422e-05,
      "loss": 0.1437,
      "step": 926
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3020016551017761,
      "learning_rate": 9.550526315789474e-05,
      "loss": 0.1231,
      "step": 927
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.37458544969558716,
      "learning_rate": 9.549473684210527e-05,
      "loss": 0.1426,
      "step": 928
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3398876488208771,
      "learning_rate": 9.54842105263158e-05,
      "loss": 0.1647,
      "step": 929
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28700965642929077,
      "learning_rate": 9.547368421052632e-05,
      "loss": 0.169,
      "step": 930
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3655354678630829,
      "learning_rate": 9.546315789473684e-05,
      "loss": 0.1297,
      "step": 931
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.4015871286392212,
      "learning_rate": 9.545263157894736e-05,
      "loss": 0.1844,
      "step": 932
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.34712615609169006,
      "learning_rate": 9.54421052631579e-05,
      "loss": 0.228,
      "step": 933
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.33383306860923767,
      "learning_rate": 9.543157894736843e-05,
      "loss": 0.1564,
      "step": 934
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.33436697721481323,
      "learning_rate": 9.542105263157895e-05,
      "loss": 0.146,
      "step": 935
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.385638952255249,
      "learning_rate": 9.541052631578948e-05,
      "loss": 0.2145,
      "step": 936
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.43434837460517883,
      "learning_rate": 9.54e-05,
      "loss": 0.1722,
      "step": 937
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.30322888493537903,
      "learning_rate": 9.538947368421053e-05,
      "loss": 0.1313,
      "step": 938
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2672540843486786,
      "learning_rate": 9.537894736842105e-05,
      "loss": 0.1635,
      "step": 939
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32652947306632996,
      "learning_rate": 9.536842105263159e-05,
      "loss": 0.1666,
      "step": 940
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.36083874106407166,
      "learning_rate": 9.535789473684211e-05,
      "loss": 0.164,
      "step": 941
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.28057944774627686,
      "learning_rate": 9.534736842105264e-05,
      "loss": 0.1402,
      "step": 942
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.291951984167099,
      "learning_rate": 9.533684210526316e-05,
      "loss": 0.1782,
      "step": 943
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2616128623485565,
      "learning_rate": 9.532631578947369e-05,
      "loss": 0.1346,
      "step": 944
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.31813642382621765,
      "learning_rate": 9.531578947368421e-05,
      "loss": 0.1733,
      "step": 945
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3245319724082947,
      "learning_rate": 9.530526315789474e-05,
      "loss": 0.1757,
      "step": 946
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2983855605125427,
      "learning_rate": 9.529473684210527e-05,
      "loss": 0.1794,
      "step": 947
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3085058331489563,
      "learning_rate": 9.52842105263158e-05,
      "loss": 0.1729,
      "step": 948
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3402399718761444,
      "learning_rate": 9.527368421052631e-05,
      "loss": 0.1703,
      "step": 949
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3478347063064575,
      "learning_rate": 9.526315789473685e-05,
      "loss": 0.1737,
      "step": 950
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2877001166343689,
      "learning_rate": 9.525263157894737e-05,
      "loss": 0.1592,
      "step": 951
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3021138608455658,
      "learning_rate": 9.52421052631579e-05,
      "loss": 0.1755,
      "step": 952
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3308909833431244,
      "learning_rate": 9.523157894736842e-05,
      "loss": 0.1627,
      "step": 953
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3673708438873291,
      "learning_rate": 9.522105263157896e-05,
      "loss": 0.2277,
      "step": 954
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32123565673828125,
      "learning_rate": 9.521052631578949e-05,
      "loss": 0.2157,
      "step": 955
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2863716185092926,
      "learning_rate": 9.52e-05,
      "loss": 0.1729,
      "step": 956
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3010794222354889,
      "learning_rate": 9.518947368421053e-05,
      "loss": 0.137,
      "step": 957
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3364541232585907,
      "learning_rate": 9.517894736842106e-05,
      "loss": 0.1663,
      "step": 958
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.30917033553123474,
      "learning_rate": 9.516842105263158e-05,
      "loss": 0.1549,
      "step": 959
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3311726748943329,
      "learning_rate": 9.515789473684211e-05,
      "loss": 0.1566,
      "step": 960
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32611367106437683,
      "learning_rate": 9.514736842105265e-05,
      "loss": 0.1742,
      "step": 961
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.393484890460968,
      "learning_rate": 9.513684210526316e-05,
      "loss": 0.2096,
      "step": 962
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.340353399515152,
      "learning_rate": 9.512631578947368e-05,
      "loss": 0.1551,
      "step": 963
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.29957982897758484,
      "learning_rate": 9.511578947368421e-05,
      "loss": 0.1327,
      "step": 964
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.341320663690567,
      "learning_rate": 9.510526315789475e-05,
      "loss": 0.1682,
      "step": 965
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.32220205664634705,
      "learning_rate": 9.509473684210527e-05,
      "loss": 0.1703,
      "step": 966
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.31829583644866943,
      "learning_rate": 9.50842105263158e-05,
      "loss": 0.1726,
      "step": 967
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3305317163467407,
      "learning_rate": 9.507368421052632e-05,
      "loss": 0.1566,
      "step": 968
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.33515000343322754,
      "learning_rate": 9.506315789473684e-05,
      "loss": 0.1665,
      "step": 969
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.311083048582077,
      "learning_rate": 9.505263157894737e-05,
      "loss": 0.1438,
      "step": 970
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3160390853881836,
      "learning_rate": 9.504210526315789e-05,
      "loss": 0.1988,
      "step": 971
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.317434161901474,
      "learning_rate": 9.503157894736843e-05,
      "loss": 0.1794,
      "step": 972
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34913313388824463,
      "learning_rate": 9.502105263157896e-05,
      "loss": 0.1708,
      "step": 973
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2638651430606842,
      "learning_rate": 9.501052631578948e-05,
      "loss": 0.1314,
      "step": 974
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2984559237957001,
      "learning_rate": 9.5e-05,
      "loss": 0.1521,
      "step": 975
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.29170116782188416,
      "learning_rate": 9.498947368421053e-05,
      "loss": 0.1894,
      "step": 976
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.30411258339881897,
      "learning_rate": 9.497894736842105e-05,
      "loss": 0.1267,
      "step": 977
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.29177388548851013,
      "learning_rate": 9.496842105263158e-05,
      "loss": 0.1831,
      "step": 978
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3257073760032654,
      "learning_rate": 9.495789473684212e-05,
      "loss": 0.2161,
      "step": 979
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.32586100697517395,
      "learning_rate": 9.494736842105264e-05,
      "loss": 0.1615,
      "step": 980
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3444851338863373,
      "learning_rate": 9.493684210526315e-05,
      "loss": 0.1834,
      "step": 981
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2912342846393585,
      "learning_rate": 9.492631578947369e-05,
      "loss": 0.1629,
      "step": 982
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.27002227306365967,
      "learning_rate": 9.491578947368422e-05,
      "loss": 0.1772,
      "step": 983
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.276237815618515,
      "learning_rate": 9.490526315789474e-05,
      "loss": 0.1753,
      "step": 984
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.33294808864593506,
      "learning_rate": 9.489473684210527e-05,
      "loss": 0.1517,
      "step": 985
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2990816831588745,
      "learning_rate": 9.48842105263158e-05,
      "loss": 0.1501,
      "step": 986
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3033447265625,
      "learning_rate": 9.487368421052633e-05,
      "loss": 0.1894,
      "step": 987
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.28647661209106445,
      "learning_rate": 9.486315789473684e-05,
      "loss": 0.197,
      "step": 988
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.28501442074775696,
      "learning_rate": 9.485263157894738e-05,
      "loss": 0.1382,
      "step": 989
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.28619128465652466,
      "learning_rate": 9.48421052631579e-05,
      "loss": 0.1711,
      "step": 990
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.28158169984817505,
      "learning_rate": 9.483157894736843e-05,
      "loss": 0.1623,
      "step": 991
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.4060847759246826,
      "learning_rate": 9.482105263157895e-05,
      "loss": 0.231,
      "step": 992
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2921198606491089,
      "learning_rate": 9.481052631578949e-05,
      "loss": 0.1499,
      "step": 993
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.296195924282074,
      "learning_rate": 9.48e-05,
      "loss": 0.1544,
      "step": 994
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3527877628803253,
      "learning_rate": 9.478947368421053e-05,
      "loss": 0.2209,
      "step": 995
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3097383975982666,
      "learning_rate": 9.477894736842105e-05,
      "loss": 0.1255,
      "step": 996
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3514830470085144,
      "learning_rate": 9.476842105263159e-05,
      "loss": 0.1212,
      "step": 997
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2909885346889496,
      "learning_rate": 9.475789473684211e-05,
      "loss": 0.1524,
      "step": 998
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3128538727760315,
      "learning_rate": 9.474736842105264e-05,
      "loss": 0.171,
      "step": 999
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3234279751777649,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.1444,
      "step": 1000
    },
    {
      "epoch": 3.02,
      "eval_loss": 0.16779136657714844,
      "eval_runtime": 836.5086,
      "eval_samples_per_second": 2.977,
      "eval_steps_per_second": 0.047,
      "eval_wer": 11.409317544406356,
      "step": 1000
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3496766984462738,
      "learning_rate": 9.472631578947369e-05,
      "loss": 0.1868,
      "step": 1001
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3331700563430786,
      "learning_rate": 9.471578947368421e-05,
      "loss": 0.2092,
      "step": 1002
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3161363899707794,
      "learning_rate": 9.470526315789474e-05,
      "loss": 0.1583,
      "step": 1003
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2697319984436035,
      "learning_rate": 9.469473684210527e-05,
      "loss": 0.1681,
      "step": 1004
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3276832103729248,
      "learning_rate": 9.46842105263158e-05,
      "loss": 0.1967,
      "step": 1005
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3568733036518097,
      "learning_rate": 9.467368421052632e-05,
      "loss": 0.2054,
      "step": 1006
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.29239028692245483,
      "learning_rate": 9.466315789473685e-05,
      "loss": 0.1523,
      "step": 1007
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2947255074977875,
      "learning_rate": 9.465263157894737e-05,
      "loss": 0.1413,
      "step": 1008
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34158772230148315,
      "learning_rate": 9.46421052631579e-05,
      "loss": 0.1429,
      "step": 1009
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3228147625923157,
      "learning_rate": 9.463157894736842e-05,
      "loss": 0.1648,
      "step": 1010
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2773885428905487,
      "learning_rate": 9.462105263157896e-05,
      "loss": 0.1677,
      "step": 1011
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3231247663497925,
      "learning_rate": 9.461052631578948e-05,
      "loss": 0.1887,
      "step": 1012
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.28861919045448303,
      "learning_rate": 9.46e-05,
      "loss": 0.1337,
      "step": 1013
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34553492069244385,
      "learning_rate": 9.458947368421053e-05,
      "loss": 0.1632,
      "step": 1014
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.33736297488212585,
      "learning_rate": 9.457894736842106e-05,
      "loss": 0.1629,
      "step": 1015
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3311626613140106,
      "learning_rate": 9.456842105263158e-05,
      "loss": 0.1853,
      "step": 1016
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3288063406944275,
      "learning_rate": 9.455789473684211e-05,
      "loss": 0.1308,
      "step": 1017
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3472251892089844,
      "learning_rate": 9.454736842105265e-05,
      "loss": 0.1768,
      "step": 1018
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34643951058387756,
      "learning_rate": 9.453684210526316e-05,
      "loss": 0.1247,
      "step": 1019
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2928379774093628,
      "learning_rate": 9.452631578947368e-05,
      "loss": 0.1779,
      "step": 1020
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3105769455432892,
      "learning_rate": 9.451578947368422e-05,
      "loss": 0.1463,
      "step": 1021
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.312466561794281,
      "learning_rate": 9.450526315789474e-05,
      "loss": 0.2239,
      "step": 1022
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3241925835609436,
      "learning_rate": 9.449473684210527e-05,
      "loss": 0.1499,
      "step": 1023
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3178507387638092,
      "learning_rate": 9.44842105263158e-05,
      "loss": 0.1492,
      "step": 1024
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.27611616253852844,
      "learning_rate": 9.447368421052633e-05,
      "loss": 0.1382,
      "step": 1025
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.36971914768218994,
      "learning_rate": 9.446315789473684e-05,
      "loss": 0.1564,
      "step": 1026
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2958202064037323,
      "learning_rate": 9.445263157894737e-05,
      "loss": 0.1577,
      "step": 1027
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31071969866752625,
      "learning_rate": 9.444210526315789e-05,
      "loss": 0.1592,
      "step": 1028
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31273847818374634,
      "learning_rate": 9.443157894736843e-05,
      "loss": 0.1657,
      "step": 1029
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2803255319595337,
      "learning_rate": 9.442105263157895e-05,
      "loss": 0.1584,
      "step": 1030
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2887944281101227,
      "learning_rate": 9.441052631578948e-05,
      "loss": 0.1476,
      "step": 1031
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.39042237401008606,
      "learning_rate": 9.44e-05,
      "loss": 0.1442,
      "step": 1032
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31165817379951477,
      "learning_rate": 9.438947368421053e-05,
      "loss": 0.1837,
      "step": 1033
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3179224133491516,
      "learning_rate": 9.437894736842105e-05,
      "loss": 0.1496,
      "step": 1034
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.32828107476234436,
      "learning_rate": 9.436842105263158e-05,
      "loss": 0.1628,
      "step": 1035
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3219699561595917,
      "learning_rate": 9.435789473684212e-05,
      "loss": 0.1924,
      "step": 1036
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.29634541273117065,
      "learning_rate": 9.434736842105264e-05,
      "loss": 0.1359,
      "step": 1037
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3482079803943634,
      "learning_rate": 9.433684210526317e-05,
      "loss": 0.1852,
      "step": 1038
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3787745535373688,
      "learning_rate": 9.432631578947369e-05,
      "loss": 0.1598,
      "step": 1039
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3074866235256195,
      "learning_rate": 9.431578947368421e-05,
      "loss": 0.1397,
      "step": 1040
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.32604801654815674,
      "learning_rate": 9.430526315789474e-05,
      "loss": 0.1842,
      "step": 1041
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.32884642481803894,
      "learning_rate": 9.429473684210526e-05,
      "loss": 0.178,
      "step": 1042
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3119827210903168,
      "learning_rate": 9.42842105263158e-05,
      "loss": 0.1532,
      "step": 1043
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2895874083042145,
      "learning_rate": 9.427368421052633e-05,
      "loss": 0.1402,
      "step": 1044
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34168460965156555,
      "learning_rate": 9.426315789473684e-05,
      "loss": 0.1454,
      "step": 1045
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3489924371242523,
      "learning_rate": 9.425263157894738e-05,
      "loss": 0.2546,
      "step": 1046
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.30926957726478577,
      "learning_rate": 9.42421052631579e-05,
      "loss": 0.1606,
      "step": 1047
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3315519690513611,
      "learning_rate": 9.423157894736843e-05,
      "loss": 0.196,
      "step": 1048
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3025112450122833,
      "learning_rate": 9.422105263157895e-05,
      "loss": 0.1755,
      "step": 1049
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.34529051184654236,
      "learning_rate": 9.421052631578949e-05,
      "loss": 0.1951,
      "step": 1050
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3597768247127533,
      "learning_rate": 9.42e-05,
      "loss": 0.1485,
      "step": 1051
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3067481815814972,
      "learning_rate": 9.418947368421052e-05,
      "loss": 0.151,
      "step": 1052
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2959665358066559,
      "learning_rate": 9.417894736842106e-05,
      "loss": 0.1426,
      "step": 1053
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.30347955226898193,
      "learning_rate": 9.416842105263159e-05,
      "loss": 0.1445,
      "step": 1054
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31054815649986267,
      "learning_rate": 9.415789473684211e-05,
      "loss": 0.1551,
      "step": 1055
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.36335060000419617,
      "learning_rate": 9.414736842105264e-05,
      "loss": 0.1991,
      "step": 1056
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.276957243680954,
      "learning_rate": 9.413684210526317e-05,
      "loss": 0.1195,
      "step": 1057
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.26683297753334045,
      "learning_rate": 9.412631578947369e-05,
      "loss": 0.1447,
      "step": 1058
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3222943842411041,
      "learning_rate": 9.411578947368421e-05,
      "loss": 0.1417,
      "step": 1059
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3174971044063568,
      "learning_rate": 9.410526315789473e-05,
      "loss": 0.186,
      "step": 1060
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3316501975059509,
      "learning_rate": 9.409473684210527e-05,
      "loss": 0.1554,
      "step": 1061
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31257879734039307,
      "learning_rate": 9.40842105263158e-05,
      "loss": 0.1476,
      "step": 1062
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.4136853814125061,
      "learning_rate": 9.407368421052632e-05,
      "loss": 0.211,
      "step": 1063
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3215479254722595,
      "learning_rate": 9.406315789473685e-05,
      "loss": 0.1415,
      "step": 1064
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2848297357559204,
      "learning_rate": 9.405263157894737e-05,
      "loss": 0.1471,
      "step": 1065
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.32147079706192017,
      "learning_rate": 9.40421052631579e-05,
      "loss": 0.1444,
      "step": 1066
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.31693533062934875,
      "learning_rate": 9.403157894736842e-05,
      "loss": 0.1937,
      "step": 1067
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.27921345829963684,
      "learning_rate": 9.402105263157896e-05,
      "loss": 0.1081,
      "step": 1068
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.3078185021877289,
      "learning_rate": 9.401052631578948e-05,
      "loss": 0.1435,
      "step": 1069
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2829729914665222,
      "learning_rate": 9.4e-05,
      "loss": 0.1527,
      "step": 1070
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.33727091550827026,
      "learning_rate": 9.398947368421053e-05,
      "loss": 0.19,
      "step": 1071
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2793301045894623,
      "learning_rate": 9.397894736842106e-05,
      "loss": 0.1599,
      "step": 1072
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.31071752309799194,
      "learning_rate": 9.396842105263158e-05,
      "loss": 0.166,
      "step": 1073
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.29992493987083435,
      "learning_rate": 9.39578947368421e-05,
      "loss": 0.1449,
      "step": 1074
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.30226457118988037,
      "learning_rate": 9.394736842105264e-05,
      "loss": 0.1874,
      "step": 1075
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.311938613653183,
      "learning_rate": 9.393684210526317e-05,
      "loss": 0.1695,
      "step": 1076
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.28310370445251465,
      "learning_rate": 9.392631578947368e-05,
      "loss": 0.1295,
      "step": 1077
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.3093531131744385,
      "learning_rate": 9.391578947368422e-05,
      "loss": 0.1771,
      "step": 1078
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.31576845049858093,
      "learning_rate": 9.390526315789474e-05,
      "loss": 0.1451,
      "step": 1079
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.3672589361667633,
      "learning_rate": 9.389473684210527e-05,
      "loss": 0.1623,
      "step": 1080
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.30293336510658264,
      "learning_rate": 9.388421052631579e-05,
      "loss": 0.1225,
      "step": 1081
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.33436131477355957,
      "learning_rate": 9.387368421052633e-05,
      "loss": 0.1869,
      "step": 1082
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2703050673007965,
      "learning_rate": 9.386315789473684e-05,
      "loss": 0.1489,
      "step": 1083
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2966684401035309,
      "learning_rate": 9.385263157894737e-05,
      "loss": 0.178,
      "step": 1084
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2972531318664551,
      "learning_rate": 9.384210526315789e-05,
      "loss": 0.1643,
      "step": 1085
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.36475664377212524,
      "learning_rate": 9.383157894736843e-05,
      "loss": 0.2293,
      "step": 1086
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.31190213561058044,
      "learning_rate": 9.382105263157895e-05,
      "loss": 0.1696,
      "step": 1087
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.34093233942985535,
      "learning_rate": 9.381052631578948e-05,
      "loss": 0.1301,
      "step": 1088
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.30254480242729187,
      "learning_rate": 9.38e-05,
      "loss": 0.1344,
      "step": 1089
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.28154560923576355,
      "learning_rate": 9.378947368421053e-05,
      "loss": 0.1561,
      "step": 1090
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.24387934803962708,
      "learning_rate": 9.377894736842105e-05,
      "loss": 0.1016,
      "step": 1091
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.27610886096954346,
      "learning_rate": 9.376842105263158e-05,
      "loss": 0.1284,
      "step": 1092
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2587336003780365,
      "learning_rate": 9.375789473684212e-05,
      "loss": 0.1193,
      "step": 1093
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.29137593507766724,
      "learning_rate": 9.374736842105264e-05,
      "loss": 0.1234,
      "step": 1094
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2651178538799286,
      "learning_rate": 9.373684210526316e-05,
      "loss": 0.1233,
      "step": 1095
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2859452962875366,
      "learning_rate": 9.372631578947369e-05,
      "loss": 0.142,
      "step": 1096
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.31826210021972656,
      "learning_rate": 9.371578947368421e-05,
      "loss": 0.1094,
      "step": 1097
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.29478389024734497,
      "learning_rate": 9.370526315789474e-05,
      "loss": 0.1167,
      "step": 1098
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.29735034704208374,
      "learning_rate": 9.369473684210526e-05,
      "loss": 0.1771,
      "step": 1099
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.27051636576652527,
      "learning_rate": 9.36842105263158e-05,
      "loss": 0.1157,
      "step": 1100
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.15818192064762115,
      "eval_runtime": 837.9595,
      "eval_samples_per_second": 2.972,
      "eval_steps_per_second": 0.047,
      "eval_wer": 11.576815207229666,
      "step": 1100
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.27281323075294495,
      "learning_rate": 9.367368421052633e-05,
      "loss": 0.1251,
      "step": 1101
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.29137977957725525,
      "learning_rate": 9.366315789473684e-05,
      "loss": 0.1423,
      "step": 1102
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2899647057056427,
      "learning_rate": 9.365263157894738e-05,
      "loss": 0.1092,
      "step": 1103
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2631179690361023,
      "learning_rate": 9.36421052631579e-05,
      "loss": 0.1666,
      "step": 1104
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30564993619918823,
      "learning_rate": 9.363157894736842e-05,
      "loss": 0.1507,
      "step": 1105
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2760045528411865,
      "learning_rate": 9.362105263157895e-05,
      "loss": 0.1114,
      "step": 1106
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.24201805889606476,
      "learning_rate": 9.361052631578949e-05,
      "loss": 0.1186,
      "step": 1107
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2567712366580963,
      "learning_rate": 9.360000000000001e-05,
      "loss": 0.1271,
      "step": 1108
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.26235777139663696,
      "learning_rate": 9.358947368421052e-05,
      "loss": 0.1169,
      "step": 1109
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.24698272347450256,
      "learning_rate": 9.357894736842106e-05,
      "loss": 0.118,
      "step": 1110
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.307125985622406,
      "learning_rate": 9.356842105263159e-05,
      "loss": 0.1443,
      "step": 1111
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30094650387763977,
      "learning_rate": 9.355789473684211e-05,
      "loss": 0.1542,
      "step": 1112
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2830394506454468,
      "learning_rate": 9.354736842105264e-05,
      "loss": 0.1456,
      "step": 1113
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30592140555381775,
      "learning_rate": 9.353684210526317e-05,
      "loss": 0.1129,
      "step": 1114
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.33935466408729553,
      "learning_rate": 9.352631578947368e-05,
      "loss": 0.1577,
      "step": 1115
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.31768491864204407,
      "learning_rate": 9.351578947368421e-05,
      "loss": 0.167,
      "step": 1116
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.29315781593322754,
      "learning_rate": 9.350526315789473e-05,
      "loss": 0.1733,
      "step": 1117
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30129677057266235,
      "learning_rate": 9.349473684210527e-05,
      "loss": 0.1274,
      "step": 1118
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.32383403182029724,
      "learning_rate": 9.34842105263158e-05,
      "loss": 0.1739,
      "step": 1119
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.37490910291671753,
      "learning_rate": 9.347368421052632e-05,
      "loss": 0.1366,
      "step": 1120
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.27330607175827026,
      "learning_rate": 9.346315789473685e-05,
      "loss": 0.0983,
      "step": 1121
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.4042118787765503,
      "learning_rate": 9.345263157894737e-05,
      "loss": 0.1614,
      "step": 1122
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3165052831172943,
      "learning_rate": 9.34421052631579e-05,
      "loss": 0.1478,
      "step": 1123
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2718254029750824,
      "learning_rate": 9.343157894736842e-05,
      "loss": 0.1331,
      "step": 1124
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3373945653438568,
      "learning_rate": 9.342105263157896e-05,
      "loss": 0.1354,
      "step": 1125
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30915796756744385,
      "learning_rate": 9.341052631578948e-05,
      "loss": 0.1295,
      "step": 1126
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.337517648935318,
      "learning_rate": 9.340000000000001e-05,
      "loss": 0.1212,
      "step": 1127
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2637642025947571,
      "learning_rate": 9.338947368421053e-05,
      "loss": 0.127,
      "step": 1128
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2678373157978058,
      "learning_rate": 9.337894736842106e-05,
      "loss": 0.1213,
      "step": 1129
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3133837878704071,
      "learning_rate": 9.336842105263158e-05,
      "loss": 0.1333,
      "step": 1130
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2834934592247009,
      "learning_rate": 9.33578947368421e-05,
      "loss": 0.1191,
      "step": 1131
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3150758743286133,
      "learning_rate": 9.334736842105264e-05,
      "loss": 0.2045,
      "step": 1132
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.25429853796958923,
      "learning_rate": 9.333684210526317e-05,
      "loss": 0.1016,
      "step": 1133
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.272224098443985,
      "learning_rate": 9.332631578947368e-05,
      "loss": 0.1163,
      "step": 1134
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3129008114337921,
      "learning_rate": 9.331578947368422e-05,
      "loss": 0.1221,
      "step": 1135
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.28105267882347107,
      "learning_rate": 9.330526315789474e-05,
      "loss": 0.1102,
      "step": 1136
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3100649416446686,
      "learning_rate": 9.329473684210527e-05,
      "loss": 0.123,
      "step": 1137
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2868952453136444,
      "learning_rate": 9.328421052631579e-05,
      "loss": 0.1206,
      "step": 1138
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.27827054262161255,
      "learning_rate": 9.327368421052633e-05,
      "loss": 0.1058,
      "step": 1139
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3181942105293274,
      "learning_rate": 9.326315789473684e-05,
      "loss": 0.1462,
      "step": 1140
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29487884044647217,
      "learning_rate": 9.325263157894737e-05,
      "loss": 0.1334,
      "step": 1141
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2783975303173065,
      "learning_rate": 9.32421052631579e-05,
      "loss": 0.1112,
      "step": 1142
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.30390292406082153,
      "learning_rate": 9.323157894736843e-05,
      "loss": 0.1561,
      "step": 1143
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33031773567199707,
      "learning_rate": 9.322105263157895e-05,
      "loss": 0.1338,
      "step": 1144
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2714664936065674,
      "learning_rate": 9.321052631578948e-05,
      "loss": 0.1002,
      "step": 1145
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2816724181175232,
      "learning_rate": 9.320000000000002e-05,
      "loss": 0.1283,
      "step": 1146
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33394768834114075,
      "learning_rate": 9.318947368421053e-05,
      "loss": 0.134,
      "step": 1147
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3210873305797577,
      "learning_rate": 9.317894736842105e-05,
      "loss": 0.1926,
      "step": 1148
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3321445882320404,
      "learning_rate": 9.316842105263158e-05,
      "loss": 0.1292,
      "step": 1149
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3071059584617615,
      "learning_rate": 9.315789473684211e-05,
      "loss": 0.1371,
      "step": 1150
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.277984619140625,
      "learning_rate": 9.314736842105264e-05,
      "loss": 0.1007,
      "step": 1151
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3111358880996704,
      "learning_rate": 9.313684210526316e-05,
      "loss": 0.1406,
      "step": 1152
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.30307629704475403,
      "learning_rate": 9.312631578947369e-05,
      "loss": 0.1365,
      "step": 1153
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31455326080322266,
      "learning_rate": 9.311578947368421e-05,
      "loss": 0.1366,
      "step": 1154
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3048490881919861,
      "learning_rate": 9.310526315789474e-05,
      "loss": 0.1711,
      "step": 1155
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3292595446109772,
      "learning_rate": 9.309473684210526e-05,
      "loss": 0.118,
      "step": 1156
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3290996849536896,
      "learning_rate": 9.30842105263158e-05,
      "loss": 0.1866,
      "step": 1157
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.36920973658561707,
      "learning_rate": 9.307368421052632e-05,
      "loss": 0.1662,
      "step": 1158
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.321767121553421,
      "learning_rate": 9.306315789473685e-05,
      "loss": 0.1462,
      "step": 1159
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.26574432849884033,
      "learning_rate": 9.305263157894737e-05,
      "loss": 0.1007,
      "step": 1160
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3409311771392822,
      "learning_rate": 9.30421052631579e-05,
      "loss": 0.1802,
      "step": 1161
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2943924069404602,
      "learning_rate": 9.303157894736842e-05,
      "loss": 0.1356,
      "step": 1162
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.26338669657707214,
      "learning_rate": 9.302105263157895e-05,
      "loss": 0.1114,
      "step": 1163
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29412737488746643,
      "learning_rate": 9.301052631578949e-05,
      "loss": 0.1456,
      "step": 1164
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3270605802536011,
      "learning_rate": 9.300000000000001e-05,
      "loss": 0.1585,
      "step": 1165
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33385831117630005,
      "learning_rate": 9.298947368421052e-05,
      "loss": 0.1748,
      "step": 1166
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29456034302711487,
      "learning_rate": 9.297894736842106e-05,
      "loss": 0.1444,
      "step": 1167
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31705349683761597,
      "learning_rate": 9.296842105263158e-05,
      "loss": 0.169,
      "step": 1168
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31877991557121277,
      "learning_rate": 9.295789473684211e-05,
      "loss": 0.1347,
      "step": 1169
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3748803436756134,
      "learning_rate": 9.294736842105263e-05,
      "loss": 0.1161,
      "step": 1170
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3176199197769165,
      "learning_rate": 9.293684210526317e-05,
      "loss": 0.1501,
      "step": 1171
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.28073960542678833,
      "learning_rate": 9.292631578947368e-05,
      "loss": 0.0985,
      "step": 1172
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.28522399067878723,
      "learning_rate": 9.291578947368421e-05,
      "loss": 0.1034,
      "step": 1173
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31987446546554565,
      "learning_rate": 9.290526315789475e-05,
      "loss": 0.1649,
      "step": 1174
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.317070335149765,
      "learning_rate": 9.289473684210527e-05,
      "loss": 0.1443,
      "step": 1175
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.30235201120376587,
      "learning_rate": 9.28842105263158e-05,
      "loss": 0.1282,
      "step": 1176
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2629314363002777,
      "learning_rate": 9.287368421052632e-05,
      "loss": 0.128,
      "step": 1177
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31798821687698364,
      "learning_rate": 9.286315789473686e-05,
      "loss": 0.1497,
      "step": 1178
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2669680416584015,
      "learning_rate": 9.285263157894737e-05,
      "loss": 0.1087,
      "step": 1179
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29409846663475037,
      "learning_rate": 9.28421052631579e-05,
      "loss": 0.1223,
      "step": 1180
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.299576997756958,
      "learning_rate": 9.283157894736842e-05,
      "loss": 0.129,
      "step": 1181
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2822854518890381,
      "learning_rate": 9.282105263157896e-05,
      "loss": 0.1262,
      "step": 1182
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3587186336517334,
      "learning_rate": 9.281052631578948e-05,
      "loss": 0.1298,
      "step": 1183
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3143140971660614,
      "learning_rate": 9.28e-05,
      "loss": 0.1689,
      "step": 1184
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33137306571006775,
      "learning_rate": 9.278947368421053e-05,
      "loss": 0.1486,
      "step": 1185
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3169384300708771,
      "learning_rate": 9.277894736842106e-05,
      "loss": 0.1238,
      "step": 1186
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2781605124473572,
      "learning_rate": 9.276842105263158e-05,
      "loss": 0.1394,
      "step": 1187
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29066982865333557,
      "learning_rate": 9.27578947368421e-05,
      "loss": 0.1272,
      "step": 1188
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.35879194736480713,
      "learning_rate": 9.274736842105264e-05,
      "loss": 0.1557,
      "step": 1189
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2959482669830322,
      "learning_rate": 9.273684210526317e-05,
      "loss": 0.1372,
      "step": 1190
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3041592836380005,
      "learning_rate": 9.272631578947368e-05,
      "loss": 0.1247,
      "step": 1191
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.31258782744407654,
      "learning_rate": 9.271578947368422e-05,
      "loss": 0.122,
      "step": 1192
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3256467580795288,
      "learning_rate": 9.270526315789474e-05,
      "loss": 0.1131,
      "step": 1193
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2670166790485382,
      "learning_rate": 9.269473684210527e-05,
      "loss": 0.1075,
      "step": 1194
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3188815116882324,
      "learning_rate": 9.268421052631579e-05,
      "loss": 0.1596,
      "step": 1195
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3224007785320282,
      "learning_rate": 9.267368421052633e-05,
      "loss": 0.1215,
      "step": 1196
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.34162235260009766,
      "learning_rate": 9.266315789473685e-05,
      "loss": 0.1961,
      "step": 1197
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29858386516571045,
      "learning_rate": 9.265263157894736e-05,
      "loss": 0.1659,
      "step": 1198
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.37678125500679016,
      "learning_rate": 9.26421052631579e-05,
      "loss": 0.1908,
      "step": 1199
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3289935886859894,
      "learning_rate": 9.263157894736843e-05,
      "loss": 0.1928,
      "step": 1200
    },
    {
      "epoch": 4.01,
      "eval_loss": 0.15210911631584167,
      "eval_runtime": 825.3632,
      "eval_samples_per_second": 3.017,
      "eval_steps_per_second": 0.047,
      "eval_wer": 10.490028046120287,
      "step": 1200
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.32849830389022827,
      "learning_rate": 9.262105263157895e-05,
      "loss": 0.1439,
      "step": 1201
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2839365005493164,
      "learning_rate": 9.261052631578948e-05,
      "loss": 0.1622,
      "step": 1202
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3495636284351349,
      "learning_rate": 9.260000000000001e-05,
      "loss": 0.1688,
      "step": 1203
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3017489016056061,
      "learning_rate": 9.258947368421053e-05,
      "loss": 0.147,
      "step": 1204
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.311389297246933,
      "learning_rate": 9.257894736842105e-05,
      "loss": 0.1318,
      "step": 1205
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3581089377403259,
      "learning_rate": 9.256842105263159e-05,
      "loss": 0.1092,
      "step": 1206
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.28190240263938904,
      "learning_rate": 9.255789473684211e-05,
      "loss": 0.1218,
      "step": 1207
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.29675036668777466,
      "learning_rate": 9.254736842105264e-05,
      "loss": 0.1377,
      "step": 1208
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.340788871049881,
      "learning_rate": 9.253684210526316e-05,
      "loss": 0.1618,
      "step": 1209
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3432002365589142,
      "learning_rate": 9.252631578947369e-05,
      "loss": 0.1589,
      "step": 1210
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.27928265929222107,
      "learning_rate": 9.251578947368421e-05,
      "loss": 0.1209,
      "step": 1211
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2947549521923065,
      "learning_rate": 9.250526315789474e-05,
      "loss": 0.1282,
      "step": 1212
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.32209667563438416,
      "learning_rate": 9.249473684210526e-05,
      "loss": 0.1058,
      "step": 1213
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2557746469974518,
      "learning_rate": 9.24842105263158e-05,
      "loss": 0.1412,
      "step": 1214
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3124372065067291,
      "learning_rate": 9.247368421052632e-05,
      "loss": 0.1416,
      "step": 1215
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3233640491962433,
      "learning_rate": 9.246315789473685e-05,
      "loss": 0.1391,
      "step": 1216
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.26487722992897034,
      "learning_rate": 9.245263157894737e-05,
      "loss": 0.1195,
      "step": 1217
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2794281244277954,
      "learning_rate": 9.24421052631579e-05,
      "loss": 0.1224,
      "step": 1218
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.32723429799079895,
      "learning_rate": 9.243157894736842e-05,
      "loss": 0.152,
      "step": 1219
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3082689344882965,
      "learning_rate": 9.242105263157895e-05,
      "loss": 0.1505,
      "step": 1220
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.28618451952934265,
      "learning_rate": 9.241052631578949e-05,
      "loss": 0.1036,
      "step": 1221
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3901100754737854,
      "learning_rate": 9.240000000000001e-05,
      "loss": 0.2165,
      "step": 1222
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33860522508621216,
      "learning_rate": 9.238947368421052e-05,
      "loss": 0.12,
      "step": 1223
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33012187480926514,
      "learning_rate": 9.237894736842106e-05,
      "loss": 0.1987,
      "step": 1224
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3312113881111145,
      "learning_rate": 9.236842105263158e-05,
      "loss": 0.1849,
      "step": 1225
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33824267983436584,
      "learning_rate": 9.235789473684211e-05,
      "loss": 0.1355,
      "step": 1226
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3117407262325287,
      "learning_rate": 9.234736842105263e-05,
      "loss": 0.1644,
      "step": 1227
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.336176335811615,
      "learning_rate": 9.233684210526317e-05,
      "loss": 0.1717,
      "step": 1228
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.35758915543556213,
      "learning_rate": 9.23263157894737e-05,
      "loss": 0.1737,
      "step": 1229
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3095785081386566,
      "learning_rate": 9.231578947368421e-05,
      "loss": 0.1489,
      "step": 1230
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3111904561519623,
      "learning_rate": 9.230526315789475e-05,
      "loss": 0.1275,
      "step": 1231
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3114386200904846,
      "learning_rate": 9.229473684210527e-05,
      "loss": 0.1259,
      "step": 1232
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33871930837631226,
      "learning_rate": 9.22842105263158e-05,
      "loss": 0.1438,
      "step": 1233
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3129398226737976,
      "learning_rate": 9.227368421052632e-05,
      "loss": 0.1357,
      "step": 1234
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3132077753543854,
      "learning_rate": 9.226315789473686e-05,
      "loss": 0.1105,
      "step": 1235
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3536801338195801,
      "learning_rate": 9.225263157894737e-05,
      "loss": 0.1718,
      "step": 1236
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2819061875343323,
      "learning_rate": 9.224210526315789e-05,
      "loss": 0.0983,
      "step": 1237
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.27910178899765015,
      "learning_rate": 9.223157894736843e-05,
      "loss": 0.1211,
      "step": 1238
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.33018797636032104,
      "learning_rate": 9.222105263157896e-05,
      "loss": 0.1307,
      "step": 1239
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3362630009651184,
      "learning_rate": 9.221052631578948e-05,
      "loss": 0.1223,
      "step": 1240
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3353944718837738,
      "learning_rate": 9.22e-05,
      "loss": 0.1174,
      "step": 1241
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.26815497875213623,
      "learning_rate": 9.218947368421053e-05,
      "loss": 0.1024,
      "step": 1242
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3473142683506012,
      "learning_rate": 9.217894736842105e-05,
      "loss": 0.1276,
      "step": 1243
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.33140090107917786,
      "learning_rate": 9.216842105263158e-05,
      "loss": 0.1352,
      "step": 1244
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3453676104545593,
      "learning_rate": 9.21578947368421e-05,
      "loss": 0.1645,
      "step": 1245
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3130527138710022,
      "learning_rate": 9.214736842105264e-05,
      "loss": 0.1599,
      "step": 1246
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3702315390110016,
      "learning_rate": 9.213684210526317e-05,
      "loss": 0.1628,
      "step": 1247
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.4929618537425995,
      "learning_rate": 9.212631578947369e-05,
      "loss": 0.1589,
      "step": 1248
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3302730619907379,
      "learning_rate": 9.211578947368422e-05,
      "loss": 0.1443,
      "step": 1249
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3375897705554962,
      "learning_rate": 9.210526315789474e-05,
      "loss": 0.1845,
      "step": 1250
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.28753387928009033,
      "learning_rate": 9.209473684210526e-05,
      "loss": 0.1102,
      "step": 1251
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.38832756876945496,
      "learning_rate": 9.208421052631579e-05,
      "loss": 0.1946,
      "step": 1252
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3156644403934479,
      "learning_rate": 9.207368421052633e-05,
      "loss": 0.1512,
      "step": 1253
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3179839551448822,
      "learning_rate": 9.206315789473685e-05,
      "loss": 0.163,
      "step": 1254
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3443009555339813,
      "learning_rate": 9.205263157894736e-05,
      "loss": 0.1201,
      "step": 1255
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.28216424584388733,
      "learning_rate": 9.20421052631579e-05,
      "loss": 0.1692,
      "step": 1256
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3317772150039673,
      "learning_rate": 9.203157894736843e-05,
      "loss": 0.1438,
      "step": 1257
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3219209909439087,
      "learning_rate": 9.202105263157895e-05,
      "loss": 0.1152,
      "step": 1258
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.27567920088768005,
      "learning_rate": 9.201052631578948e-05,
      "loss": 0.1221,
      "step": 1259
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3387419283390045,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.1377,
      "step": 1260
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3310457170009613,
      "learning_rate": 9.198947368421052e-05,
      "loss": 0.1496,
      "step": 1261
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.33209744095802307,
      "learning_rate": 9.197894736842105e-05,
      "loss": 0.1372,
      "step": 1262
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.34581854939460754,
      "learning_rate": 9.196842105263159e-05,
      "loss": 0.1308,
      "step": 1263
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2903204560279846,
      "learning_rate": 9.195789473684211e-05,
      "loss": 0.1387,
      "step": 1264
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2826070487499237,
      "learning_rate": 9.194736842105264e-05,
      "loss": 0.1291,
      "step": 1265
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3305836617946625,
      "learning_rate": 9.193684210526316e-05,
      "loss": 0.1705,
      "step": 1266
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.30284231901168823,
      "learning_rate": 9.19263157894737e-05,
      "loss": 0.1367,
      "step": 1267
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29028329253196716,
      "learning_rate": 9.191578947368421e-05,
      "loss": 0.1189,
      "step": 1268
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.30031660199165344,
      "learning_rate": 9.190526315789474e-05,
      "loss": 0.17,
      "step": 1269
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3022526502609253,
      "learning_rate": 9.189473684210527e-05,
      "loss": 0.103,
      "step": 1270
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3031778931617737,
      "learning_rate": 9.18842105263158e-05,
      "loss": 0.1232,
      "step": 1271
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.36658623814582825,
      "learning_rate": 9.187368421052632e-05,
      "loss": 0.1484,
      "step": 1272
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2994888722896576,
      "learning_rate": 9.186315789473685e-05,
      "loss": 0.1584,
      "step": 1273
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3234303891658783,
      "learning_rate": 9.185263157894737e-05,
      "loss": 0.1457,
      "step": 1274
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3193478286266327,
      "learning_rate": 9.18421052631579e-05,
      "loss": 0.146,
      "step": 1275
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.30424368381500244,
      "learning_rate": 9.183157894736842e-05,
      "loss": 0.1129,
      "step": 1276
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2776236832141876,
      "learning_rate": 9.182105263157895e-05,
      "loss": 0.1383,
      "step": 1277
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29997509717941284,
      "learning_rate": 9.181052631578948e-05,
      "loss": 0.1419,
      "step": 1278
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29008015990257263,
      "learning_rate": 9.180000000000001e-05,
      "loss": 0.1254,
      "step": 1279
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2597549855709076,
      "learning_rate": 9.178947368421052e-05,
      "loss": 0.1167,
      "step": 1280
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3251309096813202,
      "learning_rate": 9.177894736842106e-05,
      "loss": 0.117,
      "step": 1281
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3046940565109253,
      "learning_rate": 9.176842105263158e-05,
      "loss": 0.1245,
      "step": 1282
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.34654751420021057,
      "learning_rate": 9.175789473684211e-05,
      "loss": 0.1492,
      "step": 1283
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.333126038312912,
      "learning_rate": 9.174736842105263e-05,
      "loss": 0.1548,
      "step": 1284
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.33906254172325134,
      "learning_rate": 9.173684210526317e-05,
      "loss": 0.1445,
      "step": 1285
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2860410213470459,
      "learning_rate": 9.17263157894737e-05,
      "loss": 0.1201,
      "step": 1286
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3375656306743622,
      "learning_rate": 9.17157894736842e-05,
      "loss": 0.1521,
      "step": 1287
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3482202887535095,
      "learning_rate": 9.170526315789474e-05,
      "loss": 0.1137,
      "step": 1288
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3109058737754822,
      "learning_rate": 9.169473684210527e-05,
      "loss": 0.1064,
      "step": 1289
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3736148774623871,
      "learning_rate": 9.16842105263158e-05,
      "loss": 0.1672,
      "step": 1290
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2991800308227539,
      "learning_rate": 9.167368421052632e-05,
      "loss": 0.1468,
      "step": 1291
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3229887783527374,
      "learning_rate": 9.166315789473686e-05,
      "loss": 0.138,
      "step": 1292
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29354128241539,
      "learning_rate": 9.165263157894737e-05,
      "loss": 0.1193,
      "step": 1293
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.34013786911964417,
      "learning_rate": 9.164210526315789e-05,
      "loss": 0.1266,
      "step": 1294
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3230743706226349,
      "learning_rate": 9.163157894736843e-05,
      "loss": 0.1335,
      "step": 1295
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3063926696777344,
      "learning_rate": 9.162105263157895e-05,
      "loss": 0.1606,
      "step": 1296
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3235507309436798,
      "learning_rate": 9.161052631578948e-05,
      "loss": 0.1521,
      "step": 1297
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.30955269932746887,
      "learning_rate": 9.16e-05,
      "loss": 0.147,
      "step": 1298
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3297909200191498,
      "learning_rate": 9.158947368421054e-05,
      "loss": 0.1808,
      "step": 1299
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.36704665422439575,
      "learning_rate": 9.157894736842105e-05,
      "loss": 0.1705,
      "step": 1300
    },
    {
      "epoch": 4.02,
      "eval_loss": 0.1456858068704605,
      "eval_runtime": 840.1636,
      "eval_samples_per_second": 2.964,
      "eval_steps_per_second": 0.046,
      "eval_wer": 10.715955126207541,
      "step": 1300
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3261963427066803,
      "learning_rate": 9.156842105263158e-05,
      "loss": 0.1359,
      "step": 1301
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29652372002601624,
      "learning_rate": 9.15578947368421e-05,
      "loss": 0.1155,
      "step": 1302
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2946082353591919,
      "learning_rate": 9.154736842105264e-05,
      "loss": 0.1416,
      "step": 1303
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.31531599164009094,
      "learning_rate": 9.153684210526317e-05,
      "loss": 0.1299,
      "step": 1304
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3366524279117584,
      "learning_rate": 9.152631578947369e-05,
      "loss": 0.119,
      "step": 1305
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3690539300441742,
      "learning_rate": 9.151578947368421e-05,
      "loss": 0.1432,
      "step": 1306
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3587457835674286,
      "learning_rate": 9.150526315789474e-05,
      "loss": 0.1208,
      "step": 1307
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.30573946237564087,
      "learning_rate": 9.149473684210526e-05,
      "loss": 0.1401,
      "step": 1308
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3427223265171051,
      "learning_rate": 9.148421052631579e-05,
      "loss": 0.1525,
      "step": 1309
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32678481936454773,
      "learning_rate": 9.147368421052633e-05,
      "loss": 0.1144,
      "step": 1310
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3370647728443146,
      "learning_rate": 9.146315789473685e-05,
      "loss": 0.1682,
      "step": 1311
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.26627954840660095,
      "learning_rate": 9.145263157894736e-05,
      "loss": 0.1142,
      "step": 1312
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3215041160583496,
      "learning_rate": 9.14421052631579e-05,
      "loss": 0.1448,
      "step": 1313
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29423654079437256,
      "learning_rate": 9.143157894736843e-05,
      "loss": 0.1508,
      "step": 1314
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3498200476169586,
      "learning_rate": 9.142105263157895e-05,
      "loss": 0.1986,
      "step": 1315
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.27885812520980835,
      "learning_rate": 9.141052631578947e-05,
      "loss": 0.114,
      "step": 1316
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.25774869322776794,
      "learning_rate": 9.140000000000001e-05,
      "loss": 0.113,
      "step": 1317
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2834896147251129,
      "learning_rate": 9.138947368421054e-05,
      "loss": 0.13,
      "step": 1318
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3209378123283386,
      "learning_rate": 9.137894736842105e-05,
      "loss": 0.1465,
      "step": 1319
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.26962757110595703,
      "learning_rate": 9.136842105263159e-05,
      "loss": 0.1268,
      "step": 1320
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32244449853897095,
      "learning_rate": 9.135789473684211e-05,
      "loss": 0.1878,
      "step": 1321
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32036951184272766,
      "learning_rate": 9.134736842105264e-05,
      "loss": 0.147,
      "step": 1322
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.29068833589553833,
      "learning_rate": 9.133684210526316e-05,
      "loss": 0.1411,
      "step": 1323
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.31431254744529724,
      "learning_rate": 9.13263157894737e-05,
      "loss": 0.1353,
      "step": 1324
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3985939919948578,
      "learning_rate": 9.131578947368421e-05,
      "loss": 0.1863,
      "step": 1325
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.31712231040000916,
      "learning_rate": 9.130526315789473e-05,
      "loss": 0.1835,
      "step": 1326
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2744028866291046,
      "learning_rate": 9.129473684210527e-05,
      "loss": 0.1222,
      "step": 1327
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.28910839557647705,
      "learning_rate": 9.12842105263158e-05,
      "loss": 0.1344,
      "step": 1328
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2792150676250458,
      "learning_rate": 9.127368421052632e-05,
      "loss": 0.1271,
      "step": 1329
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3133839964866638,
      "learning_rate": 9.126315789473685e-05,
      "loss": 0.1385,
      "step": 1330
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.27157318592071533,
      "learning_rate": 9.125263157894737e-05,
      "loss": 0.1206,
      "step": 1331
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3348497450351715,
      "learning_rate": 9.12421052631579e-05,
      "loss": 0.1363,
      "step": 1332
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.2939162850379944,
      "learning_rate": 9.123157894736842e-05,
      "loss": 0.1265,
      "step": 1333
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.28262701630592346,
      "learning_rate": 9.122105263157894e-05,
      "loss": 0.1017,
      "step": 1334
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.304385244846344,
      "learning_rate": 9.121052631578948e-05,
      "loss": 0.1298,
      "step": 1335
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32607129216194153,
      "learning_rate": 9.120000000000001e-05,
      "loss": 0.1516,
      "step": 1336
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32489079236984253,
      "learning_rate": 9.118947368421053e-05,
      "loss": 0.1134,
      "step": 1337
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.32540133595466614,
      "learning_rate": 9.117894736842106e-05,
      "loss": 0.1329,
      "step": 1338
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.31728553771972656,
      "learning_rate": 9.116842105263158e-05,
      "loss": 0.1297,
      "step": 1339
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3323877453804016,
      "learning_rate": 9.11578947368421e-05,
      "loss": 0.2205,
      "step": 1340
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.296163946390152,
      "learning_rate": 9.114736842105263e-05,
      "loss": 0.1081,
      "step": 1341
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3574770987033844,
      "learning_rate": 9.113684210526317e-05,
      "loss": 0.1242,
      "step": 1342
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.302360862493515,
      "learning_rate": 9.11263157894737e-05,
      "loss": 0.0927,
      "step": 1343
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.2866576015949249,
      "learning_rate": 9.11157894736842e-05,
      "loss": 0.109,
      "step": 1344
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.29086244106292725,
      "learning_rate": 9.110526315789474e-05,
      "loss": 0.1529,
      "step": 1345
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.33601757884025574,
      "learning_rate": 9.109473684210527e-05,
      "loss": 0.1176,
      "step": 1346
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3208904266357422,
      "learning_rate": 9.108421052631579e-05,
      "loss": 0.1439,
      "step": 1347
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.32217633724212646,
      "learning_rate": 9.107368421052632e-05,
      "loss": 0.1503,
      "step": 1348
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.30618953704833984,
      "learning_rate": 9.106315789473686e-05,
      "loss": 0.1423,
      "step": 1349
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3152991831302643,
      "learning_rate": 9.105263157894738e-05,
      "loss": 0.1295,
      "step": 1350
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3682608902454376,
      "learning_rate": 9.104210526315789e-05,
      "loss": 0.1835,
      "step": 1351
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3314198851585388,
      "learning_rate": 9.103157894736843e-05,
      "loss": 0.1258,
      "step": 1352
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.38190215826034546,
      "learning_rate": 9.102105263157895e-05,
      "loss": 0.1585,
      "step": 1353
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.29068413376808167,
      "learning_rate": 9.101052631578948e-05,
      "loss": 0.1551,
      "step": 1354
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.2894086539745331,
      "learning_rate": 9.1e-05,
      "loss": 0.1184,
      "step": 1355
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3222014307975769,
      "learning_rate": 9.098947368421054e-05,
      "loss": 0.1171,
      "step": 1356
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.34073567390441895,
      "learning_rate": 9.097894736842105e-05,
      "loss": 0.1568,
      "step": 1357
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3053831458091736,
      "learning_rate": 9.096842105263158e-05,
      "loss": 0.1235,
      "step": 1358
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.29972347617149353,
      "learning_rate": 9.095789473684211e-05,
      "loss": 0.1106,
      "step": 1359
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.4041392207145691,
      "learning_rate": 9.094736842105264e-05,
      "loss": 0.1413,
      "step": 1360
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3413773477077484,
      "learning_rate": 9.093684210526316e-05,
      "loss": 0.1618,
      "step": 1361
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3466857671737671,
      "learning_rate": 9.092631578947369e-05,
      "loss": 0.123,
      "step": 1362
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.35225069522857666,
      "learning_rate": 9.091578947368421e-05,
      "loss": 0.1177,
      "step": 1363
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2830895483493805,
      "learning_rate": 9.090526315789474e-05,
      "loss": 0.1052,
      "step": 1364
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.23256009817123413,
      "learning_rate": 9.089473684210526e-05,
      "loss": 0.0759,
      "step": 1365
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.29999831318855286,
      "learning_rate": 9.088421052631579e-05,
      "loss": 0.1419,
      "step": 1366
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2939033806324005,
      "learning_rate": 9.087368421052633e-05,
      "loss": 0.0765,
      "step": 1367
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2506541907787323,
      "learning_rate": 9.086315789473685e-05,
      "loss": 0.0761,
      "step": 1368
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2419762909412384,
      "learning_rate": 9.085263157894737e-05,
      "loss": 0.0863,
      "step": 1369
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2965850532054901,
      "learning_rate": 9.08421052631579e-05,
      "loss": 0.1486,
      "step": 1370
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2866864800453186,
      "learning_rate": 9.083157894736842e-05,
      "loss": 0.1509,
      "step": 1371
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.27670279145240784,
      "learning_rate": 9.082105263157895e-05,
      "loss": 0.1098,
      "step": 1372
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2833627164363861,
      "learning_rate": 9.081052631578947e-05,
      "loss": 0.0804,
      "step": 1373
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2989562153816223,
      "learning_rate": 9.080000000000001e-05,
      "loss": 0.1506,
      "step": 1374
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.291618287563324,
      "learning_rate": 9.078947368421054e-05,
      "loss": 0.1086,
      "step": 1375
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.30379655957221985,
      "learning_rate": 9.077894736842105e-05,
      "loss": 0.1092,
      "step": 1376
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.26233428716659546,
      "learning_rate": 9.076842105263159e-05,
      "loss": 0.1021,
      "step": 1377
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2632905840873718,
      "learning_rate": 9.075789473684211e-05,
      "loss": 0.1278,
      "step": 1378
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2608671486377716,
      "learning_rate": 9.074736842105263e-05,
      "loss": 0.114,
      "step": 1379
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2712617814540863,
      "learning_rate": 9.073684210526316e-05,
      "loss": 0.0759,
      "step": 1380
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.27533167600631714,
      "learning_rate": 9.07263157894737e-05,
      "loss": 0.0969,
      "step": 1381
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2654111087322235,
      "learning_rate": 9.071578947368421e-05,
      "loss": 0.098,
      "step": 1382
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.27569594979286194,
      "learning_rate": 9.070526315789473e-05,
      "loss": 0.1359,
      "step": 1383
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.28849899768829346,
      "learning_rate": 9.069473684210527e-05,
      "loss": 0.1371,
      "step": 1384
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.28861042857170105,
      "learning_rate": 9.06842105263158e-05,
      "loss": 0.0991,
      "step": 1385
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.24970395863056183,
      "learning_rate": 9.067368421052632e-05,
      "loss": 0.1159,
      "step": 1386
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2856176197528839,
      "learning_rate": 9.066315789473685e-05,
      "loss": 0.1235,
      "step": 1387
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.35859590768814087,
      "learning_rate": 9.065263157894738e-05,
      "loss": 0.1616,
      "step": 1388
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2701703608036041,
      "learning_rate": 9.06421052631579e-05,
      "loss": 0.0803,
      "step": 1389
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.29029518365859985,
      "learning_rate": 9.063157894736842e-05,
      "loss": 0.1411,
      "step": 1390
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3073064088821411,
      "learning_rate": 9.062105263157896e-05,
      "loss": 0.1537,
      "step": 1391
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.30135461688041687,
      "learning_rate": 9.061052631578948e-05,
      "loss": 0.1347,
      "step": 1392
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.289956659078598,
      "learning_rate": 9.06e-05,
      "loss": 0.1138,
      "step": 1393
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2525760531425476,
      "learning_rate": 9.058947368421053e-05,
      "loss": 0.1012,
      "step": 1394
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2760566771030426,
      "learning_rate": 9.057894736842106e-05,
      "loss": 0.0973,
      "step": 1395
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.28076785802841187,
      "learning_rate": 9.056842105263158e-05,
      "loss": 0.084,
      "step": 1396
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.28749018907546997,
      "learning_rate": 9.05578947368421e-05,
      "loss": 0.1088,
      "step": 1397
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.26965317130088806,
      "learning_rate": 9.054736842105263e-05,
      "loss": 0.0913,
      "step": 1398
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.25823795795440674,
      "learning_rate": 9.053684210526317e-05,
      "loss": 0.066,
      "step": 1399
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.27160465717315674,
      "learning_rate": 9.052631578947369e-05,
      "loss": 0.1099,
      "step": 1400
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.1410556435585022,
      "eval_runtime": 839.4248,
      "eval_samples_per_second": 2.966,
      "eval_steps_per_second": 0.046,
      "eval_wer": 10.388750389529449,
      "step": 1400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2986997365951538,
      "learning_rate": 9.05157894736842e-05,
      "loss": 0.1106,
      "step": 1401
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2887459397315979,
      "learning_rate": 9.050526315789474e-05,
      "loss": 0.1499,
      "step": 1402
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2614649534225464,
      "learning_rate": 9.049473684210527e-05,
      "loss": 0.0934,
      "step": 1403
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2499931901693344,
      "learning_rate": 9.048421052631579e-05,
      "loss": 0.0984,
      "step": 1404
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.25643810629844666,
      "learning_rate": 9.047368421052632e-05,
      "loss": 0.085,
      "step": 1405
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3226464092731476,
      "learning_rate": 9.046315789473685e-05,
      "loss": 0.0943,
      "step": 1406
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.30293282866477966,
      "learning_rate": 9.045263157894738e-05,
      "loss": 0.0875,
      "step": 1407
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.26348012685775757,
      "learning_rate": 9.044210526315789e-05,
      "loss": 0.1039,
      "step": 1408
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.33673587441444397,
      "learning_rate": 9.043157894736843e-05,
      "loss": 0.1298,
      "step": 1409
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2653563916683197,
      "learning_rate": 9.042105263157895e-05,
      "loss": 0.0989,
      "step": 1410
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2846710979938507,
      "learning_rate": 9.041052631578948e-05,
      "loss": 0.1005,
      "step": 1411
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2619054317474365,
      "learning_rate": 9.04e-05,
      "loss": 0.1159,
      "step": 1412
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2940821051597595,
      "learning_rate": 9.038947368421054e-05,
      "loss": 0.1009,
      "step": 1413
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2773212492465973,
      "learning_rate": 9.037894736842105e-05,
      "loss": 0.1115,
      "step": 1414
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3117474317550659,
      "learning_rate": 9.036842105263158e-05,
      "loss": 0.0888,
      "step": 1415
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2533780038356781,
      "learning_rate": 9.035789473684211e-05,
      "loss": 0.095,
      "step": 1416
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.26137736439704895,
      "learning_rate": 9.034736842105264e-05,
      "loss": 0.1181,
      "step": 1417
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30225205421447754,
      "learning_rate": 9.033684210526316e-05,
      "loss": 0.1035,
      "step": 1418
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3032311797142029,
      "learning_rate": 9.032631578947369e-05,
      "loss": 0.1284,
      "step": 1419
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.24657922983169556,
      "learning_rate": 9.031578947368423e-05,
      "loss": 0.0816,
      "step": 1420
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.27153173089027405,
      "learning_rate": 9.030526315789474e-05,
      "loss": 0.1119,
      "step": 1421
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3237723112106323,
      "learning_rate": 9.029473684210526e-05,
      "loss": 0.1531,
      "step": 1422
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2701709270477295,
      "learning_rate": 9.02842105263158e-05,
      "loss": 0.0945,
      "step": 1423
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29795390367507935,
      "learning_rate": 9.027368421052632e-05,
      "loss": 0.1334,
      "step": 1424
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2616082429885864,
      "learning_rate": 9.026315789473685e-05,
      "loss": 0.1033,
      "step": 1425
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31029748916625977,
      "learning_rate": 9.025263157894737e-05,
      "loss": 0.1334,
      "step": 1426
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2496607005596161,
      "learning_rate": 9.02421052631579e-05,
      "loss": 0.1042,
      "step": 1427
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2587779760360718,
      "learning_rate": 9.023157894736842e-05,
      "loss": 0.0796,
      "step": 1428
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3206508159637451,
      "learning_rate": 9.022105263157895e-05,
      "loss": 0.1257,
      "step": 1429
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29503241181373596,
      "learning_rate": 9.021052631578947e-05,
      "loss": 0.0951,
      "step": 1430
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30635055899620056,
      "learning_rate": 9.020000000000001e-05,
      "loss": 0.122,
      "step": 1431
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2914925813674927,
      "learning_rate": 9.018947368421054e-05,
      "loss": 0.1047,
      "step": 1432
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2746652066707611,
      "learning_rate": 9.017894736842105e-05,
      "loss": 0.1052,
      "step": 1433
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2705906629562378,
      "learning_rate": 9.016842105263158e-05,
      "loss": 0.1068,
      "step": 1434
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3036545217037201,
      "learning_rate": 9.015789473684211e-05,
      "loss": 0.1084,
      "step": 1435
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3202075958251953,
      "learning_rate": 9.014736842105263e-05,
      "loss": 0.1068,
      "step": 1436
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.32140758633613586,
      "learning_rate": 9.013684210526316e-05,
      "loss": 0.1575,
      "step": 1437
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.27415093779563904,
      "learning_rate": 9.01263157894737e-05,
      "loss": 0.0942,
      "step": 1438
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3297683596611023,
      "learning_rate": 9.011578947368422e-05,
      "loss": 0.1644,
      "step": 1439
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.28071513772010803,
      "learning_rate": 9.010526315789473e-05,
      "loss": 0.1242,
      "step": 1440
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30343493819236755,
      "learning_rate": 9.009473684210527e-05,
      "loss": 0.1328,
      "step": 1441
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.25964170694351196,
      "learning_rate": 9.00842105263158e-05,
      "loss": 0.1163,
      "step": 1442
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.33722537755966187,
      "learning_rate": 9.007368421052632e-05,
      "loss": 0.1974,
      "step": 1443
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30776724219322205,
      "learning_rate": 9.006315789473684e-05,
      "loss": 0.1053,
      "step": 1444
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.34086132049560547,
      "learning_rate": 9.005263157894738e-05,
      "loss": 0.1173,
      "step": 1445
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.302844762802124,
      "learning_rate": 9.00421052631579e-05,
      "loss": 0.0922,
      "step": 1446
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3493708372116089,
      "learning_rate": 9.003157894736842e-05,
      "loss": 0.1313,
      "step": 1447
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3565736413002014,
      "learning_rate": 9.002105263157896e-05,
      "loss": 0.1328,
      "step": 1448
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3589555025100708,
      "learning_rate": 9.001052631578948e-05,
      "loss": 0.1232,
      "step": 1449
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3122302293777466,
      "learning_rate": 9e-05,
      "loss": 0.1422,
      "step": 1450
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29397496581077576,
      "learning_rate": 8.998947368421053e-05,
      "loss": 0.1338,
      "step": 1451
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3250844180583954,
      "learning_rate": 8.997894736842105e-05,
      "loss": 0.1432,
      "step": 1452
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3048170208930969,
      "learning_rate": 8.996842105263158e-05,
      "loss": 0.1451,
      "step": 1453
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2926752269268036,
      "learning_rate": 8.99578947368421e-05,
      "loss": 0.1198,
      "step": 1454
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3124828040599823,
      "learning_rate": 8.994736842105264e-05,
      "loss": 0.1263,
      "step": 1455
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29546499252319336,
      "learning_rate": 8.993684210526317e-05,
      "loss": 0.1223,
      "step": 1456
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.33258166909217834,
      "learning_rate": 8.992631578947369e-05,
      "loss": 0.1808,
      "step": 1457
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2912239730358124,
      "learning_rate": 8.991578947368422e-05,
      "loss": 0.1086,
      "step": 1458
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3229469060897827,
      "learning_rate": 8.990526315789474e-05,
      "loss": 0.1522,
      "step": 1459
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3339352607727051,
      "learning_rate": 8.989473684210527e-05,
      "loss": 0.1217,
      "step": 1460
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3654198944568634,
      "learning_rate": 8.988421052631579e-05,
      "loss": 0.1996,
      "step": 1461
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.293388307094574,
      "learning_rate": 8.987368421052631e-05,
      "loss": 0.101,
      "step": 1462
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31304115056991577,
      "learning_rate": 8.986315789473685e-05,
      "loss": 0.1115,
      "step": 1463
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3403548002243042,
      "learning_rate": 8.985263157894738e-05,
      "loss": 0.1339,
      "step": 1464
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.35530582070350647,
      "learning_rate": 8.984210526315789e-05,
      "loss": 0.1616,
      "step": 1465
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2726908326148987,
      "learning_rate": 8.983157894736843e-05,
      "loss": 0.1,
      "step": 1466
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31820279359817505,
      "learning_rate": 8.982105263157895e-05,
      "loss": 0.1189,
      "step": 1467
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3184744417667389,
      "learning_rate": 8.981052631578948e-05,
      "loss": 0.1548,
      "step": 1468
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.33839452266693115,
      "learning_rate": 8.98e-05,
      "loss": 0.1365,
      "step": 1469
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31875482201576233,
      "learning_rate": 8.978947368421054e-05,
      "loss": 0.1553,
      "step": 1470
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.330998033285141,
      "learning_rate": 8.977894736842106e-05,
      "loss": 0.1308,
      "step": 1471
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3286735713481903,
      "learning_rate": 8.976842105263157e-05,
      "loss": 0.1394,
      "step": 1472
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29405495524406433,
      "learning_rate": 8.975789473684211e-05,
      "loss": 0.1514,
      "step": 1473
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3101303279399872,
      "learning_rate": 8.974736842105264e-05,
      "loss": 0.141,
      "step": 1474
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29580751061439514,
      "learning_rate": 8.973684210526316e-05,
      "loss": 0.131,
      "step": 1475
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3036847710609436,
      "learning_rate": 8.972631578947369e-05,
      "loss": 0.0811,
      "step": 1476
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3185198903083801,
      "learning_rate": 8.971578947368422e-05,
      "loss": 0.1162,
      "step": 1477
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3165406584739685,
      "learning_rate": 8.970526315789474e-05,
      "loss": 0.1251,
      "step": 1478
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3419879078865051,
      "learning_rate": 8.969473684210526e-05,
      "loss": 0.1235,
      "step": 1479
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.27022188901901245,
      "learning_rate": 8.96842105263158e-05,
      "loss": 0.1123,
      "step": 1480
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31469252705574036,
      "learning_rate": 8.967368421052632e-05,
      "loss": 0.1311,
      "step": 1481
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2587417960166931,
      "learning_rate": 8.966315789473685e-05,
      "loss": 0.0938,
      "step": 1482
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2542221248149872,
      "learning_rate": 8.965263157894737e-05,
      "loss": 0.0646,
      "step": 1483
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2844136357307434,
      "learning_rate": 8.96421052631579e-05,
      "loss": 0.1002,
      "step": 1484
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30043885111808777,
      "learning_rate": 8.963157894736842e-05,
      "loss": 0.0975,
      "step": 1485
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.37607359886169434,
      "learning_rate": 8.962105263157895e-05,
      "loss": 0.2009,
      "step": 1486
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.288800448179245,
      "learning_rate": 8.961052631578948e-05,
      "loss": 0.0858,
      "step": 1487
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29429739713668823,
      "learning_rate": 8.960000000000001e-05,
      "loss": 0.1086,
      "step": 1488
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.33926117420196533,
      "learning_rate": 8.958947368421053e-05,
      "loss": 0.1251,
      "step": 1489
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3131583631038666,
      "learning_rate": 8.957894736842106e-05,
      "loss": 0.1189,
      "step": 1490
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.34868359565734863,
      "learning_rate": 8.956842105263158e-05,
      "loss": 0.1542,
      "step": 1491
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3175378739833832,
      "learning_rate": 8.955789473684211e-05,
      "loss": 0.1419,
      "step": 1492
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3373911678791046,
      "learning_rate": 8.954736842105263e-05,
      "loss": 0.1357,
      "step": 1493
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.29325804114341736,
      "learning_rate": 8.953684210526316e-05,
      "loss": 0.1357,
      "step": 1494
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.32425928115844727,
      "learning_rate": 8.95263157894737e-05,
      "loss": 0.1385,
      "step": 1495
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3094804584980011,
      "learning_rate": 8.951578947368422e-05,
      "loss": 0.1367,
      "step": 1496
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3531034290790558,
      "learning_rate": 8.950526315789473e-05,
      "loss": 0.1648,
      "step": 1497
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.279147207736969,
      "learning_rate": 8.949473684210527e-05,
      "loss": 0.1239,
      "step": 1498
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.32928118109703064,
      "learning_rate": 8.94842105263158e-05,
      "loss": 0.1168,
      "step": 1499
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.37974271178245544,
      "learning_rate": 8.947368421052632e-05,
      "loss": 0.1138,
      "step": 1500
    },
    {
      "epoch": 5.01,
      "eval_loss": 0.13695290684700012,
      "eval_runtime": 836.7478,
      "eval_samples_per_second": 2.976,
      "eval_steps_per_second": 0.047,
      "eval_wer": 9.598005609224057,
      "step": 1500
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3028099834918976,
      "learning_rate": 8.946315789473684e-05,
      "loss": 0.107,
      "step": 1501
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2767654061317444,
      "learning_rate": 8.945263157894738e-05,
      "loss": 0.1114,
      "step": 1502
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31433162093162537,
      "learning_rate": 8.944210526315789e-05,
      "loss": 0.097,
      "step": 1503
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.31465649604797363,
      "learning_rate": 8.943157894736842e-05,
      "loss": 0.1028,
      "step": 1504
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2966177761554718,
      "learning_rate": 8.942105263157896e-05,
      "loss": 0.1093,
      "step": 1505
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3009296655654907,
      "learning_rate": 8.941052631578948e-05,
      "loss": 0.1366,
      "step": 1506
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30078044533729553,
      "learning_rate": 8.94e-05,
      "loss": 0.1281,
      "step": 1507
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3554558753967285,
      "learning_rate": 8.938947368421053e-05,
      "loss": 0.1277,
      "step": 1508
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.28579285740852356,
      "learning_rate": 8.937894736842107e-05,
      "loss": 0.1217,
      "step": 1509
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.30753880739212036,
      "learning_rate": 8.936842105263158e-05,
      "loss": 0.1287,
      "step": 1510
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3005974292755127,
      "learning_rate": 8.93578947368421e-05,
      "loss": 0.1172,
      "step": 1511
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2778557538986206,
      "learning_rate": 8.934736842105264e-05,
      "loss": 0.101,
      "step": 1512
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.30632105469703674,
      "learning_rate": 8.933684210526317e-05,
      "loss": 0.1254,
      "step": 1513
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3094063699245453,
      "learning_rate": 8.932631578947369e-05,
      "loss": 0.1289,
      "step": 1514
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2851927876472473,
      "learning_rate": 8.931578947368422e-05,
      "loss": 0.1136,
      "step": 1515
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3254610300064087,
      "learning_rate": 8.930526315789474e-05,
      "loss": 0.1394,
      "step": 1516
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3062467575073242,
      "learning_rate": 8.929473684210526e-05,
      "loss": 0.1462,
      "step": 1517
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.30993446707725525,
      "learning_rate": 8.928421052631579e-05,
      "loss": 0.1045,
      "step": 1518
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3162308633327484,
      "learning_rate": 8.927368421052631e-05,
      "loss": 0.1326,
      "step": 1519
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33730071783065796,
      "learning_rate": 8.926315789473685e-05,
      "loss": 0.1465,
      "step": 1520
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.25235846638679504,
      "learning_rate": 8.925263157894738e-05,
      "loss": 0.0994,
      "step": 1521
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.35366302728652954,
      "learning_rate": 8.924210526315789e-05,
      "loss": 0.1192,
      "step": 1522
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.28416261076927185,
      "learning_rate": 8.923157894736843e-05,
      "loss": 0.0825,
      "step": 1523
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3460920453071594,
      "learning_rate": 8.922105263157895e-05,
      "loss": 0.114,
      "step": 1524
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33069920539855957,
      "learning_rate": 8.921052631578948e-05,
      "loss": 0.1454,
      "step": 1525
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.275068998336792,
      "learning_rate": 8.92e-05,
      "loss": 0.1119,
      "step": 1526
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.30358120799064636,
      "learning_rate": 8.918947368421054e-05,
      "loss": 0.1174,
      "step": 1527
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3293270766735077,
      "learning_rate": 8.917894736842106e-05,
      "loss": 0.1382,
      "step": 1528
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3046671450138092,
      "learning_rate": 8.916842105263157e-05,
      "loss": 0.1117,
      "step": 1529
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2949889898300171,
      "learning_rate": 8.915789473684211e-05,
      "loss": 0.1244,
      "step": 1530
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27971094846725464,
      "learning_rate": 8.914736842105264e-05,
      "loss": 0.0904,
      "step": 1531
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3295885920524597,
      "learning_rate": 8.913684210526316e-05,
      "loss": 0.1427,
      "step": 1532
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.31829285621643066,
      "learning_rate": 8.912631578947369e-05,
      "loss": 0.1076,
      "step": 1533
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3537403643131256,
      "learning_rate": 8.911578947368422e-05,
      "loss": 0.1916,
      "step": 1534
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.25728127360343933,
      "learning_rate": 8.910526315789474e-05,
      "loss": 0.0833,
      "step": 1535
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.29094812273979187,
      "learning_rate": 8.909473684210526e-05,
      "loss": 0.0876,
      "step": 1536
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3159594237804413,
      "learning_rate": 8.90842105263158e-05,
      "loss": 0.1533,
      "step": 1537
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.29095736145973206,
      "learning_rate": 8.907368421052632e-05,
      "loss": 0.1108,
      "step": 1538
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3408423066139221,
      "learning_rate": 8.906315789473685e-05,
      "loss": 0.135,
      "step": 1539
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.35795313119888306,
      "learning_rate": 8.905263157894737e-05,
      "loss": 0.1819,
      "step": 1540
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33560800552368164,
      "learning_rate": 8.904210526315791e-05,
      "loss": 0.1178,
      "step": 1541
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.31264275312423706,
      "learning_rate": 8.903157894736842e-05,
      "loss": 0.117,
      "step": 1542
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3143273890018463,
      "learning_rate": 8.902105263157895e-05,
      "loss": 0.129,
      "step": 1543
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2582772672176361,
      "learning_rate": 8.901052631578948e-05,
      "loss": 0.088,
      "step": 1544
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33367210626602173,
      "learning_rate": 8.900000000000001e-05,
      "loss": 0.1498,
      "step": 1545
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.30006736516952515,
      "learning_rate": 8.898947368421053e-05,
      "loss": 0.1088,
      "step": 1546
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.32869601249694824,
      "learning_rate": 8.897894736842106e-05,
      "loss": 0.1104,
      "step": 1547
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.32525211572647095,
      "learning_rate": 8.896842105263158e-05,
      "loss": 0.1201,
      "step": 1548
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.26361605525016785,
      "learning_rate": 8.895789473684211e-05,
      "loss": 0.1004,
      "step": 1549
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.30863168835639954,
      "learning_rate": 8.894736842105263e-05,
      "loss": 0.1424,
      "step": 1550
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2531597912311554,
      "learning_rate": 8.893684210526316e-05,
      "loss": 0.0885,
      "step": 1551
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3068774938583374,
      "learning_rate": 8.89263157894737e-05,
      "loss": 0.1127,
      "step": 1552
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27886536717414856,
      "learning_rate": 8.891578947368422e-05,
      "loss": 0.1187,
      "step": 1553
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.31902769207954407,
      "learning_rate": 8.890526315789473e-05,
      "loss": 0.1454,
      "step": 1554
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33873698115348816,
      "learning_rate": 8.889473684210527e-05,
      "loss": 0.1237,
      "step": 1555
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3168899416923523,
      "learning_rate": 8.888421052631579e-05,
      "loss": 0.1354,
      "step": 1556
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.29290249943733215,
      "learning_rate": 8.887368421052632e-05,
      "loss": 0.15,
      "step": 1557
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.32105356454849243,
      "learning_rate": 8.886315789473684e-05,
      "loss": 0.1376,
      "step": 1558
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3074861764907837,
      "learning_rate": 8.885263157894738e-05,
      "loss": 0.1123,
      "step": 1559
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2781457304954529,
      "learning_rate": 8.88421052631579e-05,
      "loss": 0.0891,
      "step": 1560
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.32551631331443787,
      "learning_rate": 8.883157894736842e-05,
      "loss": 0.1257,
      "step": 1561
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3771130442619324,
      "learning_rate": 8.882105263157895e-05,
      "loss": 0.0984,
      "step": 1562
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.31602245569229126,
      "learning_rate": 8.881052631578948e-05,
      "loss": 0.1087,
      "step": 1563
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33930858969688416,
      "learning_rate": 8.88e-05,
      "loss": 0.1349,
      "step": 1564
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.29604777693748474,
      "learning_rate": 8.878947368421053e-05,
      "loss": 0.1475,
      "step": 1565
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2958452105522156,
      "learning_rate": 8.877894736842107e-05,
      "loss": 0.0991,
      "step": 1566
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33620917797088623,
      "learning_rate": 8.876842105263158e-05,
      "loss": 0.1257,
      "step": 1567
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2641739249229431,
      "learning_rate": 8.87578947368421e-05,
      "loss": 0.0748,
      "step": 1568
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2685185968875885,
      "learning_rate": 8.874736842105264e-05,
      "loss": 0.0884,
      "step": 1569
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3666563928127289,
      "learning_rate": 8.873684210526316e-05,
      "loss": 0.1512,
      "step": 1570
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2916111350059509,
      "learning_rate": 8.872631578947369e-05,
      "loss": 0.0824,
      "step": 1571
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.28780630230903625,
      "learning_rate": 8.871578947368421e-05,
      "loss": 0.1091,
      "step": 1572
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3122166693210602,
      "learning_rate": 8.870526315789474e-05,
      "loss": 0.1081,
      "step": 1573
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3145657777786255,
      "learning_rate": 8.869473684210526e-05,
      "loss": 0.1023,
      "step": 1574
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27754542231559753,
      "learning_rate": 8.868421052631579e-05,
      "loss": 0.1072,
      "step": 1575
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.320715069770813,
      "learning_rate": 8.867368421052633e-05,
      "loss": 0.1596,
      "step": 1576
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3041938841342926,
      "learning_rate": 8.866315789473685e-05,
      "loss": 0.0883,
      "step": 1577
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.29564130306243896,
      "learning_rate": 8.865263157894738e-05,
      "loss": 0.1109,
      "step": 1578
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.36406826972961426,
      "learning_rate": 8.86421052631579e-05,
      "loss": 0.1303,
      "step": 1579
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3228398859500885,
      "learning_rate": 8.863157894736842e-05,
      "loss": 0.0976,
      "step": 1580
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2551189064979553,
      "learning_rate": 8.862105263157895e-05,
      "loss": 0.1251,
      "step": 1581
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.35311591625213623,
      "learning_rate": 8.861052631578947e-05,
      "loss": 0.1098,
      "step": 1582
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3246239721775055,
      "learning_rate": 8.86e-05,
      "loss": 0.1228,
      "step": 1583
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3169938027858734,
      "learning_rate": 8.858947368421054e-05,
      "loss": 0.1318,
      "step": 1584
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3315754234790802,
      "learning_rate": 8.857894736842106e-05,
      "loss": 0.1548,
      "step": 1585
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.35415592789649963,
      "learning_rate": 8.856842105263157e-05,
      "loss": 0.1336,
      "step": 1586
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.34963515400886536,
      "learning_rate": 8.855789473684211e-05,
      "loss": 0.0936,
      "step": 1587
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33793768286705017,
      "learning_rate": 8.854736842105264e-05,
      "loss": 0.1667,
      "step": 1588
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2887902557849884,
      "learning_rate": 8.853684210526316e-05,
      "loss": 0.1331,
      "step": 1589
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33884379267692566,
      "learning_rate": 8.852631578947368e-05,
      "loss": 0.1281,
      "step": 1590
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2941902279853821,
      "learning_rate": 8.851578947368422e-05,
      "loss": 0.0919,
      "step": 1591
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.33237579464912415,
      "learning_rate": 8.850526315789473e-05,
      "loss": 0.1427,
      "step": 1592
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.35646337270736694,
      "learning_rate": 8.849473684210526e-05,
      "loss": 0.1518,
      "step": 1593
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3219118118286133,
      "learning_rate": 8.84842105263158e-05,
      "loss": 0.1119,
      "step": 1594
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3041495084762573,
      "learning_rate": 8.847368421052632e-05,
      "loss": 0.1011,
      "step": 1595
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.25083521008491516,
      "learning_rate": 8.846315789473685e-05,
      "loss": 0.0923,
      "step": 1596
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27880212664604187,
      "learning_rate": 8.845263157894737e-05,
      "loss": 0.0956,
      "step": 1597
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3109883964061737,
      "learning_rate": 8.844210526315791e-05,
      "loss": 0.1063,
      "step": 1598
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3265978991985321,
      "learning_rate": 8.843157894736842e-05,
      "loss": 0.1597,
      "step": 1599
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.26440107822418213,
      "learning_rate": 8.842105263157894e-05,
      "loss": 0.1198,
      "step": 1600
    },
    {
      "epoch": 5.02,
      "eval_loss": 0.1328059583902359,
      "eval_runtime": 871.0594,
      "eval_samples_per_second": 2.859,
      "eval_steps_per_second": 0.045,
      "eval_wer": 10.731536304144592,
      "step": 1600
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3088158071041107,
      "learning_rate": 8.841052631578948e-05,
      "loss": 0.1307,
      "step": 1601
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.31521424651145935,
      "learning_rate": 8.840000000000001e-05,
      "loss": 0.1237,
      "step": 1602
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.25768762826919556,
      "learning_rate": 8.838947368421053e-05,
      "loss": 0.103,
      "step": 1603
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27269917726516724,
      "learning_rate": 8.837894736842106e-05,
      "loss": 0.0891,
      "step": 1604
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.288367360830307,
      "learning_rate": 8.836842105263158e-05,
      "loss": 0.1048,
      "step": 1605
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27782875299453735,
      "learning_rate": 8.83578947368421e-05,
      "loss": 0.0869,
      "step": 1606
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3303481638431549,
      "learning_rate": 8.834736842105263e-05,
      "loss": 0.1422,
      "step": 1607
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3032921552658081,
      "learning_rate": 8.833684210526317e-05,
      "loss": 0.1009,
      "step": 1608
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3085913062095642,
      "learning_rate": 8.83263157894737e-05,
      "loss": 0.1139,
      "step": 1609
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.27901285886764526,
      "learning_rate": 8.831578947368422e-05,
      "loss": 0.091,
      "step": 1610
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.24493612349033356,
      "learning_rate": 8.830526315789474e-05,
      "loss": 0.0831,
      "step": 1611
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3565715551376343,
      "learning_rate": 8.829473684210527e-05,
      "loss": 0.1547,
      "step": 1612
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.332765132188797,
      "learning_rate": 8.828421052631579e-05,
      "loss": 0.1201,
      "step": 1613
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3566965162754059,
      "learning_rate": 8.827368421052632e-05,
      "loss": 0.1322,
      "step": 1614
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.31028297543525696,
      "learning_rate": 8.826315789473684e-05,
      "loss": 0.1461,
      "step": 1615
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.26259806752204895,
      "learning_rate": 8.825263157894738e-05,
      "loss": 0.0799,
      "step": 1616
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3393433392047882,
      "learning_rate": 8.82421052631579e-05,
      "loss": 0.0917,
      "step": 1617
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3012864291667938,
      "learning_rate": 8.823157894736842e-05,
      "loss": 0.1246,
      "step": 1618
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.34292247891426086,
      "learning_rate": 8.822105263157895e-05,
      "loss": 0.1176,
      "step": 1619
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.2904616594314575,
      "learning_rate": 8.821052631578948e-05,
      "loss": 0.1185,
      "step": 1620
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.2935400903224945,
      "learning_rate": 8.82e-05,
      "loss": 0.0828,
      "step": 1621
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.37479326128959656,
      "learning_rate": 8.818947368421053e-05,
      "loss": 0.133,
      "step": 1622
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.37118834257125854,
      "learning_rate": 8.817894736842107e-05,
      "loss": 0.1363,
      "step": 1623
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.30176016688346863,
      "learning_rate": 8.816842105263158e-05,
      "loss": 0.114,
      "step": 1624
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3048771023750305,
      "learning_rate": 8.81578947368421e-05,
      "loss": 0.1349,
      "step": 1625
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.45669418573379517,
      "learning_rate": 8.814736842105264e-05,
      "loss": 0.1457,
      "step": 1626
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.33626383543014526,
      "learning_rate": 8.813684210526316e-05,
      "loss": 0.0893,
      "step": 1627
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.31584009528160095,
      "learning_rate": 8.812631578947369e-05,
      "loss": 0.131,
      "step": 1628
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.30265945196151733,
      "learning_rate": 8.811578947368421e-05,
      "loss": 0.1179,
      "step": 1629
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.33053380250930786,
      "learning_rate": 8.810526315789475e-05,
      "loss": 0.1589,
      "step": 1630
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3482980728149414,
      "learning_rate": 8.809473684210526e-05,
      "loss": 0.0834,
      "step": 1631
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3114079236984253,
      "learning_rate": 8.808421052631579e-05,
      "loss": 0.1059,
      "step": 1632
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.30254775285720825,
      "learning_rate": 8.807368421052633e-05,
      "loss": 0.1192,
      "step": 1633
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.25371989607810974,
      "learning_rate": 8.806315789473685e-05,
      "loss": 0.0953,
      "step": 1634
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.37677237391471863,
      "learning_rate": 8.805263157894737e-05,
      "loss": 0.138,
      "step": 1635
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2722610533237457,
      "learning_rate": 8.80421052631579e-05,
      "loss": 0.0827,
      "step": 1636
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.27480602264404297,
      "learning_rate": 8.803157894736842e-05,
      "loss": 0.0943,
      "step": 1637
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2765795588493347,
      "learning_rate": 8.802105263157895e-05,
      "loss": 0.0993,
      "step": 1638
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30477669835090637,
      "learning_rate": 8.801052631578947e-05,
      "loss": 0.1516,
      "step": 1639
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30413031578063965,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.1463,
      "step": 1640
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2259710282087326,
      "learning_rate": 8.798947368421054e-05,
      "loss": 0.0786,
      "step": 1641
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2977251708507538,
      "learning_rate": 8.797894736842106e-05,
      "loss": 0.1107,
      "step": 1642
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3001366853713989,
      "learning_rate": 8.796842105263157e-05,
      "loss": 0.1077,
      "step": 1643
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2549917697906494,
      "learning_rate": 8.795789473684211e-05,
      "loss": 0.0739,
      "step": 1644
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30086490511894226,
      "learning_rate": 8.794736842105263e-05,
      "loss": 0.0927,
      "step": 1645
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2929764688014984,
      "learning_rate": 8.793684210526316e-05,
      "loss": 0.0766,
      "step": 1646
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2910817861557007,
      "learning_rate": 8.792631578947368e-05,
      "loss": 0.0752,
      "step": 1647
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3280077576637268,
      "learning_rate": 8.791578947368422e-05,
      "loss": 0.124,
      "step": 1648
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.4076669216156006,
      "learning_rate": 8.790526315789475e-05,
      "loss": 0.1134,
      "step": 1649
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3029272258281708,
      "learning_rate": 8.789473684210526e-05,
      "loss": 0.1202,
      "step": 1650
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.25764670968055725,
      "learning_rate": 8.78842105263158e-05,
      "loss": 0.0768,
      "step": 1651
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30908283591270447,
      "learning_rate": 8.787368421052632e-05,
      "loss": 0.1318,
      "step": 1652
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.29874345660209656,
      "learning_rate": 8.786315789473685e-05,
      "loss": 0.0945,
      "step": 1653
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.29298120737075806,
      "learning_rate": 8.785263157894737e-05,
      "loss": 0.1211,
      "step": 1654
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.25515592098236084,
      "learning_rate": 8.784210526315791e-05,
      "loss": 0.1072,
      "step": 1655
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3033720850944519,
      "learning_rate": 8.783157894736842e-05,
      "loss": 0.1417,
      "step": 1656
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2738228738307953,
      "learning_rate": 8.782105263157894e-05,
      "loss": 0.0884,
      "step": 1657
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2306355983018875,
      "learning_rate": 8.781052631578948e-05,
      "loss": 0.0839,
      "step": 1658
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.319142609834671,
      "learning_rate": 8.78e-05,
      "loss": 0.1239,
      "step": 1659
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30149760842323303,
      "learning_rate": 8.778947368421053e-05,
      "loss": 0.1365,
      "step": 1660
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3096027076244354,
      "learning_rate": 8.777894736842106e-05,
      "loss": 0.0942,
      "step": 1661
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2634664475917816,
      "learning_rate": 8.77684210526316e-05,
      "loss": 0.0799,
      "step": 1662
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.29756906628608704,
      "learning_rate": 8.77578947368421e-05,
      "loss": 0.1092,
      "step": 1663
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.27436453104019165,
      "learning_rate": 8.774736842105263e-05,
      "loss": 0.0967,
      "step": 1664
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2390379011631012,
      "learning_rate": 8.773684210526317e-05,
      "loss": 0.07,
      "step": 1665
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3528910279273987,
      "learning_rate": 8.772631578947369e-05,
      "loss": 0.1572,
      "step": 1666
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.23158830404281616,
      "learning_rate": 8.771578947368422e-05,
      "loss": 0.1065,
      "step": 1667
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30428245663642883,
      "learning_rate": 8.770526315789474e-05,
      "loss": 0.1195,
      "step": 1668
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.30264395475387573,
      "learning_rate": 8.769473684210527e-05,
      "loss": 0.1406,
      "step": 1669
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.28607070446014404,
      "learning_rate": 8.768421052631579e-05,
      "loss": 0.1166,
      "step": 1670
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3221198320388794,
      "learning_rate": 8.767368421052632e-05,
      "loss": 0.104,
      "step": 1671
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.314593106508255,
      "learning_rate": 8.766315789473685e-05,
      "loss": 0.0737,
      "step": 1672
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.32463547587394714,
      "learning_rate": 8.765263157894738e-05,
      "loss": 0.1124,
      "step": 1673
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2795485556125641,
      "learning_rate": 8.76421052631579e-05,
      "loss": 0.0957,
      "step": 1674
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2903217375278473,
      "learning_rate": 8.763157894736841e-05,
      "loss": 0.1198,
      "step": 1675
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2872813045978546,
      "learning_rate": 8.762105263157895e-05,
      "loss": 0.1044,
      "step": 1676
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.28222134709358215,
      "learning_rate": 8.761052631578948e-05,
      "loss": 0.1043,
      "step": 1677
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3117155134677887,
      "learning_rate": 8.76e-05,
      "loss": 0.1066,
      "step": 1678
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.34843578934669495,
      "learning_rate": 8.758947368421053e-05,
      "loss": 0.1293,
      "step": 1679
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3074096143245697,
      "learning_rate": 8.757894736842106e-05,
      "loss": 0.1064,
      "step": 1680
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3724728226661682,
      "learning_rate": 8.756842105263159e-05,
      "loss": 0.1431,
      "step": 1681
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2853005528450012,
      "learning_rate": 8.75578947368421e-05,
      "loss": 0.0807,
      "step": 1682
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3335856795310974,
      "learning_rate": 8.754736842105264e-05,
      "loss": 0.1437,
      "step": 1683
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3046063780784607,
      "learning_rate": 8.753684210526316e-05,
      "loss": 0.0688,
      "step": 1684
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.27372634410858154,
      "learning_rate": 8.752631578947369e-05,
      "loss": 0.0773,
      "step": 1685
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31321269273757935,
      "learning_rate": 8.751578947368421e-05,
      "loss": 0.0935,
      "step": 1686
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.28894877433776855,
      "learning_rate": 8.750526315789475e-05,
      "loss": 0.1115,
      "step": 1687
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30395621061325073,
      "learning_rate": 8.749473684210526e-05,
      "loss": 0.1207,
      "step": 1688
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2585330009460449,
      "learning_rate": 8.748421052631579e-05,
      "loss": 0.0793,
      "step": 1689
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3273872435092926,
      "learning_rate": 8.747368421052632e-05,
      "loss": 0.135,
      "step": 1690
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2772502899169922,
      "learning_rate": 8.746315789473685e-05,
      "loss": 0.08,
      "step": 1691
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31316810846328735,
      "learning_rate": 8.745263157894737e-05,
      "loss": 0.1065,
      "step": 1692
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.32454556226730347,
      "learning_rate": 8.74421052631579e-05,
      "loss": 0.1243,
      "step": 1693
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31407955288887024,
      "learning_rate": 8.743157894736842e-05,
      "loss": 0.123,
      "step": 1694
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29517269134521484,
      "learning_rate": 8.742105263157895e-05,
      "loss": 0.0733,
      "step": 1695
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2841949462890625,
      "learning_rate": 8.741052631578947e-05,
      "loss": 0.0961,
      "step": 1696
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2809704542160034,
      "learning_rate": 8.740000000000001e-05,
      "loss": 0.0996,
      "step": 1697
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2685438394546509,
      "learning_rate": 8.738947368421053e-05,
      "loss": 0.101,
      "step": 1698
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30841168761253357,
      "learning_rate": 8.737894736842106e-05,
      "loss": 0.1074,
      "step": 1699
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3013727366924286,
      "learning_rate": 8.736842105263158e-05,
      "loss": 0.1143,
      "step": 1700
    },
    {
      "epoch": 6.01,
      "eval_loss": 0.12936098873615265,
      "eval_runtime": 884.8037,
      "eval_samples_per_second": 2.814,
      "eval_steps_per_second": 0.044,
      "eval_wer": 11.06263633530695,
      "step": 1700
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.33023932576179504,
      "learning_rate": 8.735789473684211e-05,
      "loss": 0.1549,
      "step": 1701
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.32618385553359985,
      "learning_rate": 8.734736842105263e-05,
      "loss": 0.1174,
      "step": 1702
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3346790373325348,
      "learning_rate": 8.733684210526316e-05,
      "loss": 0.091,
      "step": 1703
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3508725166320801,
      "learning_rate": 8.732631578947368e-05,
      "loss": 0.1666,
      "step": 1704
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.32044363021850586,
      "learning_rate": 8.731578947368422e-05,
      "loss": 0.1341,
      "step": 1705
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3435184359550476,
      "learning_rate": 8.730526315789475e-05,
      "loss": 0.1189,
      "step": 1706
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2569519579410553,
      "learning_rate": 8.729473684210526e-05,
      "loss": 0.0831,
      "step": 1707
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2810022830963135,
      "learning_rate": 8.72842105263158e-05,
      "loss": 0.1026,
      "step": 1708
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29610174894332886,
      "learning_rate": 8.727368421052632e-05,
      "loss": 0.1108,
      "step": 1709
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.27415141463279724,
      "learning_rate": 8.726315789473684e-05,
      "loss": 0.108,
      "step": 1710
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2655920386314392,
      "learning_rate": 8.725263157894737e-05,
      "loss": 0.1059,
      "step": 1711
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2678215503692627,
      "learning_rate": 8.724210526315791e-05,
      "loss": 0.0896,
      "step": 1712
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2849636673927307,
      "learning_rate": 8.723157894736842e-05,
      "loss": 0.1305,
      "step": 1713
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.34565219283103943,
      "learning_rate": 8.722105263157894e-05,
      "loss": 0.1281,
      "step": 1714
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30377885699272156,
      "learning_rate": 8.721052631578948e-05,
      "loss": 0.1238,
      "step": 1715
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3212517499923706,
      "learning_rate": 8.72e-05,
      "loss": 0.1136,
      "step": 1716
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.24546107649803162,
      "learning_rate": 8.718947368421053e-05,
      "loss": 0.0865,
      "step": 1717
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2656242251396179,
      "learning_rate": 8.717894736842105e-05,
      "loss": 0.0733,
      "step": 1718
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.33616116642951965,
      "learning_rate": 8.716842105263159e-05,
      "loss": 0.1137,
      "step": 1719
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.28400295972824097,
      "learning_rate": 8.71578947368421e-05,
      "loss": 0.1165,
      "step": 1720
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29290875792503357,
      "learning_rate": 8.714736842105263e-05,
      "loss": 0.0999,
      "step": 1721
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30709901452064514,
      "learning_rate": 8.713684210526317e-05,
      "loss": 0.1466,
      "step": 1722
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2796162962913513,
      "learning_rate": 8.712631578947369e-05,
      "loss": 0.0897,
      "step": 1723
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3044341504573822,
      "learning_rate": 8.711578947368422e-05,
      "loss": 0.09,
      "step": 1724
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3178410530090332,
      "learning_rate": 8.710526315789474e-05,
      "loss": 0.1194,
      "step": 1725
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30667561292648315,
      "learning_rate": 8.709473684210527e-05,
      "loss": 0.1252,
      "step": 1726
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.342409610748291,
      "learning_rate": 8.708421052631579e-05,
      "loss": 0.0859,
      "step": 1727
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.35674822330474854,
      "learning_rate": 8.707368421052631e-05,
      "loss": 0.1222,
      "step": 1728
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2733057737350464,
      "learning_rate": 8.706315789473685e-05,
      "loss": 0.0776,
      "step": 1729
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.307438462972641,
      "learning_rate": 8.705263157894738e-05,
      "loss": 0.1223,
      "step": 1730
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.36204272508621216,
      "learning_rate": 8.70421052631579e-05,
      "loss": 0.1196,
      "step": 1731
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2981472313404083,
      "learning_rate": 8.703157894736843e-05,
      "loss": 0.0898,
      "step": 1732
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31648194789886475,
      "learning_rate": 8.702105263157895e-05,
      "loss": 0.0964,
      "step": 1733
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.25963038206100464,
      "learning_rate": 8.701052631578948e-05,
      "loss": 0.0859,
      "step": 1734
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30619630217552185,
      "learning_rate": 8.7e-05,
      "loss": 0.1138,
      "step": 1735
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3180334270000458,
      "learning_rate": 8.698947368421053e-05,
      "loss": 0.0957,
      "step": 1736
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2934059798717499,
      "learning_rate": 8.697894736842106e-05,
      "loss": 0.0879,
      "step": 1737
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2757038176059723,
      "learning_rate": 8.696842105263159e-05,
      "loss": 0.1078,
      "step": 1738
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.30645042657852173,
      "learning_rate": 8.69578947368421e-05,
      "loss": 0.1125,
      "step": 1739
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29706645011901855,
      "learning_rate": 8.694736842105264e-05,
      "loss": 0.1066,
      "step": 1740
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3041061460971832,
      "learning_rate": 8.693684210526316e-05,
      "loss": 0.1379,
      "step": 1741
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2756405174732208,
      "learning_rate": 8.692631578947369e-05,
      "loss": 0.0823,
      "step": 1742
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.27446499466896057,
      "learning_rate": 8.691578947368421e-05,
      "loss": 0.0963,
      "step": 1743
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2983149588108063,
      "learning_rate": 8.690526315789475e-05,
      "loss": 0.0723,
      "step": 1744
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2750202417373657,
      "learning_rate": 8.689473684210526e-05,
      "loss": 0.0875,
      "step": 1745
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2997509837150574,
      "learning_rate": 8.688421052631579e-05,
      "loss": 0.098,
      "step": 1746
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3128538727760315,
      "learning_rate": 8.687368421052632e-05,
      "loss": 0.0952,
      "step": 1747
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3057074546813965,
      "learning_rate": 8.686315789473685e-05,
      "loss": 0.0886,
      "step": 1748
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3519934415817261,
      "learning_rate": 8.685263157894737e-05,
      "loss": 0.1076,
      "step": 1749
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3158583343029022,
      "learning_rate": 8.68421052631579e-05,
      "loss": 0.1325,
      "step": 1750
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2903476357460022,
      "learning_rate": 8.683157894736844e-05,
      "loss": 0.1208,
      "step": 1751
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.25478747487068176,
      "learning_rate": 8.682105263157895e-05,
      "loss": 0.1074,
      "step": 1752
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31655004620552063,
      "learning_rate": 8.681052631578947e-05,
      "loss": 0.0944,
      "step": 1753
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.25828468799591064,
      "learning_rate": 8.680000000000001e-05,
      "loss": 0.0762,
      "step": 1754
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2652490735054016,
      "learning_rate": 8.678947368421053e-05,
      "loss": 0.084,
      "step": 1755
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2746853530406952,
      "learning_rate": 8.677894736842106e-05,
      "loss": 0.0876,
      "step": 1756
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2879902422428131,
      "learning_rate": 8.676842105263158e-05,
      "loss": 0.107,
      "step": 1757
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.39727145433425903,
      "learning_rate": 8.675789473684211e-05,
      "loss": 0.0938,
      "step": 1758
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2814972698688507,
      "learning_rate": 8.674736842105263e-05,
      "loss": 0.0906,
      "step": 1759
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.27036988735198975,
      "learning_rate": 8.673684210526316e-05,
      "loss": 0.0842,
      "step": 1760
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.26938703656196594,
      "learning_rate": 8.67263157894737e-05,
      "loss": 0.0761,
      "step": 1761
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.23890060186386108,
      "learning_rate": 8.671578947368422e-05,
      "loss": 0.0758,
      "step": 1762
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.31084761023521423,
      "learning_rate": 8.670526315789474e-05,
      "loss": 0.1131,
      "step": 1763
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.300660640001297,
      "learning_rate": 8.669473684210526e-05,
      "loss": 0.1017,
      "step": 1764
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29230278730392456,
      "learning_rate": 8.66842105263158e-05,
      "loss": 0.1117,
      "step": 1765
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2625347673892975,
      "learning_rate": 8.667368421052632e-05,
      "loss": 0.0912,
      "step": 1766
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.27216672897338867,
      "learning_rate": 8.666315789473684e-05,
      "loss": 0.0948,
      "step": 1767
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.28686821460723877,
      "learning_rate": 8.665263157894737e-05,
      "loss": 0.1085,
      "step": 1768
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.29341670870780945,
      "learning_rate": 8.66421052631579e-05,
      "loss": 0.1273,
      "step": 1769
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.322045236825943,
      "learning_rate": 8.663157894736843e-05,
      "loss": 0.1123,
      "step": 1770
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.291995108127594,
      "learning_rate": 8.662105263157894e-05,
      "loss": 0.1353,
      "step": 1771
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2997298836708069,
      "learning_rate": 8.661052631578948e-05,
      "loss": 0.0807,
      "step": 1772
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3330742120742798,
      "learning_rate": 8.66e-05,
      "loss": 0.1349,
      "step": 1773
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2754085659980774,
      "learning_rate": 8.658947368421053e-05,
      "loss": 0.09,
      "step": 1774
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.25561851263046265,
      "learning_rate": 8.657894736842105e-05,
      "loss": 0.1065,
      "step": 1775
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.23572830855846405,
      "learning_rate": 8.656842105263159e-05,
      "loss": 0.0621,
      "step": 1776
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.28691697120666504,
      "learning_rate": 8.65578947368421e-05,
      "loss": 0.078,
      "step": 1777
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2963021993637085,
      "learning_rate": 8.654736842105263e-05,
      "loss": 0.1367,
      "step": 1778
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2789264917373657,
      "learning_rate": 8.653684210526317e-05,
      "loss": 0.0992,
      "step": 1779
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3191327154636383,
      "learning_rate": 8.652631578947369e-05,
      "loss": 0.1071,
      "step": 1780
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.34334975481033325,
      "learning_rate": 8.651578947368421e-05,
      "loss": 0.1021,
      "step": 1781
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.3212207555770874,
      "learning_rate": 8.650526315789474e-05,
      "loss": 0.0973,
      "step": 1782
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2772464156150818,
      "learning_rate": 8.649473684210528e-05,
      "loss": 0.0916,
      "step": 1783
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.36031481623649597,
      "learning_rate": 8.648421052631579e-05,
      "loss": 0.0828,
      "step": 1784
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.37223511934280396,
      "learning_rate": 8.647368421052631e-05,
      "loss": 0.1364,
      "step": 1785
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.32417982816696167,
      "learning_rate": 8.646315789473685e-05,
      "loss": 0.1194,
      "step": 1786
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3079489767551422,
      "learning_rate": 8.645263157894738e-05,
      "loss": 0.1333,
      "step": 1787
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.34758034348487854,
      "learning_rate": 8.64421052631579e-05,
      "loss": 0.1067,
      "step": 1788
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.28217771649360657,
      "learning_rate": 8.643157894736843e-05,
      "loss": 0.1053,
      "step": 1789
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27467724680900574,
      "learning_rate": 8.642105263157895e-05,
      "loss": 0.1347,
      "step": 1790
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.4151366651058197,
      "learning_rate": 8.641052631578947e-05,
      "loss": 0.1423,
      "step": 1791
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.34875911474227905,
      "learning_rate": 8.64e-05,
      "loss": 0.1061,
      "step": 1792
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26533350348472595,
      "learning_rate": 8.638947368421054e-05,
      "loss": 0.0927,
      "step": 1793
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.28697147965431213,
      "learning_rate": 8.637894736842106e-05,
      "loss": 0.1062,
      "step": 1794
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31298795342445374,
      "learning_rate": 8.636842105263159e-05,
      "loss": 0.1032,
      "step": 1795
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.33344659209251404,
      "learning_rate": 8.63578947368421e-05,
      "loss": 0.1185,
      "step": 1796
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26729726791381836,
      "learning_rate": 8.634736842105264e-05,
      "loss": 0.0792,
      "step": 1797
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2743454575538635,
      "learning_rate": 8.633684210526316e-05,
      "loss": 0.1004,
      "step": 1798
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2747916579246521,
      "learning_rate": 8.632631578947369e-05,
      "loss": 0.0707,
      "step": 1799
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2841278910636902,
      "learning_rate": 8.631578947368421e-05,
      "loss": 0.1114,
      "step": 1800
    },
    {
      "epoch": 6.02,
      "eval_loss": 0.1265089511871338,
      "eval_runtime": 847.2209,
      "eval_samples_per_second": 2.939,
      "eval_steps_per_second": 0.046,
      "eval_wer": 9.823932689311311,
      "step": 1800
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2919139564037323,
      "learning_rate": 8.630526315789475e-05,
      "loss": 0.1306,
      "step": 1801
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3036811947822571,
      "learning_rate": 8.629473684210527e-05,
      "loss": 0.0809,
      "step": 1802
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27619877457618713,
      "learning_rate": 8.628421052631578e-05,
      "loss": 0.0904,
      "step": 1803
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.29292750358581543,
      "learning_rate": 8.627368421052632e-05,
      "loss": 0.0932,
      "step": 1804
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.23121848702430725,
      "learning_rate": 8.626315789473685e-05,
      "loss": 0.079,
      "step": 1805
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27591097354888916,
      "learning_rate": 8.625263157894737e-05,
      "loss": 0.0897,
      "step": 1806
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26622772216796875,
      "learning_rate": 8.62421052631579e-05,
      "loss": 0.0872,
      "step": 1807
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3050782382488251,
      "learning_rate": 8.623157894736843e-05,
      "loss": 0.1294,
      "step": 1808
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2787322998046875,
      "learning_rate": 8.622105263157895e-05,
      "loss": 0.0936,
      "step": 1809
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26895585656166077,
      "learning_rate": 8.621052631578947e-05,
      "loss": 0.083,
      "step": 1810
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3108677566051483,
      "learning_rate": 8.620000000000001e-05,
      "loss": 0.141,
      "step": 1811
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.327226847410202,
      "learning_rate": 8.618947368421053e-05,
      "loss": 0.1381,
      "step": 1812
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3057214915752411,
      "learning_rate": 8.617894736842106e-05,
      "loss": 0.1031,
      "step": 1813
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.25520649552345276,
      "learning_rate": 8.616842105263158e-05,
      "loss": 0.0694,
      "step": 1814
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2598935067653656,
      "learning_rate": 8.61578947368421e-05,
      "loss": 0.0969,
      "step": 1815
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2823127806186676,
      "learning_rate": 8.614736842105263e-05,
      "loss": 0.0826,
      "step": 1816
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2819242477416992,
      "learning_rate": 8.613684210526316e-05,
      "loss": 0.0888,
      "step": 1817
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.23601756989955902,
      "learning_rate": 8.61263157894737e-05,
      "loss": 0.0719,
      "step": 1818
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2776593565940857,
      "learning_rate": 8.611578947368422e-05,
      "loss": 0.1133,
      "step": 1819
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3157635033130646,
      "learning_rate": 8.610526315789474e-05,
      "loss": 0.0923,
      "step": 1820
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2599054276943207,
      "learning_rate": 8.609473684210527e-05,
      "loss": 0.0858,
      "step": 1821
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3549737334251404,
      "learning_rate": 8.608421052631579e-05,
      "loss": 0.0814,
      "step": 1822
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3551084101200104,
      "learning_rate": 8.607368421052632e-05,
      "loss": 0.1512,
      "step": 1823
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27266624569892883,
      "learning_rate": 8.606315789473684e-05,
      "loss": 0.0745,
      "step": 1824
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2905403673648834,
      "learning_rate": 8.605263157894738e-05,
      "loss": 0.0926,
      "step": 1825
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.24124950170516968,
      "learning_rate": 8.60421052631579e-05,
      "loss": 0.0651,
      "step": 1826
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.30891212821006775,
      "learning_rate": 8.603157894736843e-05,
      "loss": 0.0927,
      "step": 1827
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3409908413887024,
      "learning_rate": 8.602105263157894e-05,
      "loss": 0.149,
      "step": 1828
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2684594988822937,
      "learning_rate": 8.601052631578948e-05,
      "loss": 0.1024,
      "step": 1829
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3000924289226532,
      "learning_rate": 8.6e-05,
      "loss": 0.085,
      "step": 1830
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3187602162361145,
      "learning_rate": 8.598947368421053e-05,
      "loss": 0.1021,
      "step": 1831
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2783682346343994,
      "learning_rate": 8.597894736842105e-05,
      "loss": 0.0844,
      "step": 1832
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3407561480998993,
      "learning_rate": 8.596842105263159e-05,
      "loss": 0.1287,
      "step": 1833
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2877713441848755,
      "learning_rate": 8.59578947368421e-05,
      "loss": 0.1143,
      "step": 1834
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3195389211177826,
      "learning_rate": 8.594736842105263e-05,
      "loss": 0.1425,
      "step": 1835
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2575927972793579,
      "learning_rate": 8.593684210526316e-05,
      "loss": 0.1153,
      "step": 1836
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3242800235748291,
      "learning_rate": 8.592631578947369e-05,
      "loss": 0.1232,
      "step": 1837
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.28094977140426636,
      "learning_rate": 8.591578947368421e-05,
      "loss": 0.0821,
      "step": 1838
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26225998997688293,
      "learning_rate": 8.590526315789474e-05,
      "loss": 0.0854,
      "step": 1839
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27837666869163513,
      "learning_rate": 8.589473684210528e-05,
      "loss": 0.0899,
      "step": 1840
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.25665074586868286,
      "learning_rate": 8.588421052631579e-05,
      "loss": 0.0745,
      "step": 1841
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2869988679885864,
      "learning_rate": 8.587368421052631e-05,
      "loss": 0.0735,
      "step": 1842
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.29905587434768677,
      "learning_rate": 8.586315789473685e-05,
      "loss": 0.1237,
      "step": 1843
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2896915376186371,
      "learning_rate": 8.585263157894738e-05,
      "loss": 0.0951,
      "step": 1844
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31085512042045593,
      "learning_rate": 8.58421052631579e-05,
      "loss": 0.1074,
      "step": 1845
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.33958321809768677,
      "learning_rate": 8.583157894736842e-05,
      "loss": 0.1242,
      "step": 1846
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2931591868400574,
      "learning_rate": 8.582105263157895e-05,
      "loss": 0.1067,
      "step": 1847
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3198997378349304,
      "learning_rate": 8.581052631578947e-05,
      "loss": 0.116,
      "step": 1848
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3427135944366455,
      "learning_rate": 8.58e-05,
      "loss": 0.0788,
      "step": 1849
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.318436861038208,
      "learning_rate": 8.578947368421054e-05,
      "loss": 0.0868,
      "step": 1850
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.28061792254447937,
      "learning_rate": 8.577894736842106e-05,
      "loss": 0.0777,
      "step": 1851
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2722087502479553,
      "learning_rate": 8.576842105263159e-05,
      "loss": 0.0953,
      "step": 1852
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3323862850666046,
      "learning_rate": 8.575789473684211e-05,
      "loss": 0.1351,
      "step": 1853
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.28806430101394653,
      "learning_rate": 8.574736842105264e-05,
      "loss": 0.1017,
      "step": 1854
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2671368718147278,
      "learning_rate": 8.573684210526316e-05,
      "loss": 0.1018,
      "step": 1855
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.368495374917984,
      "learning_rate": 8.572631578947368e-05,
      "loss": 0.1115,
      "step": 1856
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.27896246314048767,
      "learning_rate": 8.571578947368422e-05,
      "loss": 0.0622,
      "step": 1857
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2974429726600647,
      "learning_rate": 8.570526315789475e-05,
      "loss": 0.0828,
      "step": 1858
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.25387293100357056,
      "learning_rate": 8.569473684210527e-05,
      "loss": 0.0864,
      "step": 1859
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2455812245607376,
      "learning_rate": 8.568421052631578e-05,
      "loss": 0.0709,
      "step": 1860
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3337472975254059,
      "learning_rate": 8.567368421052632e-05,
      "loss": 0.1535,
      "step": 1861
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.25187188386917114,
      "learning_rate": 8.566315789473685e-05,
      "loss": 0.0763,
      "step": 1862
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3004002273082733,
      "learning_rate": 8.565263157894737e-05,
      "loss": 0.0961,
      "step": 1863
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2884657084941864,
      "learning_rate": 8.56421052631579e-05,
      "loss": 0.1566,
      "step": 1864
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3039683997631073,
      "learning_rate": 8.563157894736843e-05,
      "loss": 0.1224,
      "step": 1865
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3060944080352783,
      "learning_rate": 8.562105263157894e-05,
      "loss": 0.0903,
      "step": 1866
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2732325792312622,
      "learning_rate": 8.561052631578947e-05,
      "loss": 0.0911,
      "step": 1867
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3308317959308624,
      "learning_rate": 8.560000000000001e-05,
      "loss": 0.1038,
      "step": 1868
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2818208336830139,
      "learning_rate": 8.558947368421053e-05,
      "loss": 0.0655,
      "step": 1869
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.324225515127182,
      "learning_rate": 8.557894736842106e-05,
      "loss": 0.1257,
      "step": 1870
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.38032397627830505,
      "learning_rate": 8.556842105263158e-05,
      "loss": 0.1804,
      "step": 1871
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3423873484134674,
      "learning_rate": 8.555789473684212e-05,
      "loss": 0.1135,
      "step": 1872
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2845149040222168,
      "learning_rate": 8.554736842105263e-05,
      "loss": 0.0834,
      "step": 1873
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.30889177322387695,
      "learning_rate": 8.553684210526315e-05,
      "loss": 0.0597,
      "step": 1874
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3456932604312897,
      "learning_rate": 8.552631578947369e-05,
      "loss": 0.1081,
      "step": 1875
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31462693214416504,
      "learning_rate": 8.551578947368422e-05,
      "loss": 0.1353,
      "step": 1876
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2925668954849243,
      "learning_rate": 8.550526315789474e-05,
      "loss": 0.0884,
      "step": 1877
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31615349650382996,
      "learning_rate": 8.549473684210527e-05,
      "loss": 0.142,
      "step": 1878
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31817322969436646,
      "learning_rate": 8.548421052631579e-05,
      "loss": 0.1204,
      "step": 1879
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.31564316153526306,
      "learning_rate": 8.547368421052632e-05,
      "loss": 0.0915,
      "step": 1880
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.278639554977417,
      "learning_rate": 8.546315789473684e-05,
      "loss": 0.0868,
      "step": 1881
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.24031223356723785,
      "learning_rate": 8.545263157894738e-05,
      "loss": 0.0799,
      "step": 1882
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2300819456577301,
      "learning_rate": 8.54421052631579e-05,
      "loss": 0.0636,
      "step": 1883
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3462960124015808,
      "learning_rate": 8.543157894736843e-05,
      "loss": 0.1158,
      "step": 1884
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2935909330844879,
      "learning_rate": 8.542105263157894e-05,
      "loss": 0.1042,
      "step": 1885
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.3089875876903534,
      "learning_rate": 8.541052631578948e-05,
      "loss": 0.114,
      "step": 1886
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2803207039833069,
      "learning_rate": 8.54e-05,
      "loss": 0.1111,
      "step": 1887
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2760666012763977,
      "learning_rate": 8.538947368421053e-05,
      "loss": 0.0729,
      "step": 1888
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.30844417214393616,
      "learning_rate": 8.537894736842107e-05,
      "loss": 0.1158,
      "step": 1889
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2836395502090454,
      "learning_rate": 8.536842105263159e-05,
      "loss": 0.0837,
      "step": 1890
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.31440338492393494,
      "learning_rate": 8.535789473684211e-05,
      "loss": 0.1177,
      "step": 1891
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.36301058530807495,
      "learning_rate": 8.534736842105263e-05,
      "loss": 0.1514,
      "step": 1892
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2570710778236389,
      "learning_rate": 8.533684210526316e-05,
      "loss": 0.0734,
      "step": 1893
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.35781651735305786,
      "learning_rate": 8.532631578947369e-05,
      "loss": 0.1331,
      "step": 1894
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.3012244701385498,
      "learning_rate": 8.531578947368421e-05,
      "loss": 0.0719,
      "step": 1895
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.292336106300354,
      "learning_rate": 8.530526315789474e-05,
      "loss": 0.089,
      "step": 1896
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.30695825815200806,
      "learning_rate": 8.529473684210528e-05,
      "loss": 0.1415,
      "step": 1897
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2835392355918884,
      "learning_rate": 8.528421052631579e-05,
      "loss": 0.0846,
      "step": 1898
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2908015847206116,
      "learning_rate": 8.527368421052631e-05,
      "loss": 0.104,
      "step": 1899
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2934386730194092,
      "learning_rate": 8.526315789473685e-05,
      "loss": 0.077,
      "step": 1900
    },
    {
      "epoch": 6.03,
      "eval_loss": 0.12359227985143661,
      "eval_runtime": 844.4089,
      "eval_samples_per_second": 2.949,
      "eval_steps_per_second": 0.046,
      "eval_wer": 10.306949205359924,
      "step": 1900
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.278576135635376,
      "learning_rate": 8.525263157894737e-05,
      "loss": 0.1069,
      "step": 1901
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2908981442451477,
      "learning_rate": 8.52421052631579e-05,
      "loss": 0.0948,
      "step": 1902
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2903183102607727,
      "learning_rate": 8.523157894736842e-05,
      "loss": 0.0992,
      "step": 1903
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.32293158769607544,
      "learning_rate": 8.522105263157895e-05,
      "loss": 0.1332,
      "step": 1904
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.3340326249599457,
      "learning_rate": 8.521052631578947e-05,
      "loss": 0.1119,
      "step": 1905
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2898755371570587,
      "learning_rate": 8.52e-05,
      "loss": 0.1224,
      "step": 1906
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.35470035672187805,
      "learning_rate": 8.518947368421054e-05,
      "loss": 0.118,
      "step": 1907
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2646735906600952,
      "learning_rate": 8.517894736842106e-05,
      "loss": 0.063,
      "step": 1908
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3256917893886566,
      "learning_rate": 8.516842105263158e-05,
      "loss": 0.1172,
      "step": 1909
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.33688628673553467,
      "learning_rate": 8.515789473684211e-05,
      "loss": 0.1342,
      "step": 1910
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.308628112077713,
      "learning_rate": 8.514736842105263e-05,
      "loss": 0.0962,
      "step": 1911
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2985180616378784,
      "learning_rate": 8.513684210526316e-05,
      "loss": 0.1033,
      "step": 1912
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3075726330280304,
      "learning_rate": 8.512631578947368e-05,
      "loss": 0.09,
      "step": 1913
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.294952929019928,
      "learning_rate": 8.511578947368422e-05,
      "loss": 0.0946,
      "step": 1914
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3160320520401001,
      "learning_rate": 8.510526315789475e-05,
      "loss": 0.0841,
      "step": 1915
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3063354194164276,
      "learning_rate": 8.509473684210527e-05,
      "loss": 0.1062,
      "step": 1916
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3415917754173279,
      "learning_rate": 8.508421052631578e-05,
      "loss": 0.1419,
      "step": 1917
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.34236016869544983,
      "learning_rate": 8.507368421052632e-05,
      "loss": 0.1299,
      "step": 1918
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3297072947025299,
      "learning_rate": 8.506315789473684e-05,
      "loss": 0.1083,
      "step": 1919
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.33828070759773254,
      "learning_rate": 8.505263157894737e-05,
      "loss": 0.1334,
      "step": 1920
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.33355408906936646,
      "learning_rate": 8.50421052631579e-05,
      "loss": 0.1201,
      "step": 1921
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2981016933917999,
      "learning_rate": 8.503157894736843e-05,
      "loss": 0.0819,
      "step": 1922
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.34547486901283264,
      "learning_rate": 8.502105263157896e-05,
      "loss": 0.1246,
      "step": 1923
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2770160436630249,
      "learning_rate": 8.501052631578947e-05,
      "loss": 0.095,
      "step": 1924
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.4076566696166992,
      "learning_rate": 8.5e-05,
      "loss": 0.1234,
      "step": 1925
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.30834102630615234,
      "learning_rate": 8.498947368421053e-05,
      "loss": 0.1016,
      "step": 1926
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.24935369193553925,
      "learning_rate": 8.497894736842106e-05,
      "loss": 0.0748,
      "step": 1927
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.30775442719459534,
      "learning_rate": 8.496842105263158e-05,
      "loss": 0.1265,
      "step": 1928
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.31630244851112366,
      "learning_rate": 8.495789473684212e-05,
      "loss": 0.1195,
      "step": 1929
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.27348655462265015,
      "learning_rate": 8.494736842105263e-05,
      "loss": 0.0868,
      "step": 1930
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.34025588631629944,
      "learning_rate": 8.493684210526315e-05,
      "loss": 0.097,
      "step": 1931
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3635912239551544,
      "learning_rate": 8.492631578947369e-05,
      "loss": 0.1264,
      "step": 1932
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2945651113986969,
      "learning_rate": 8.491578947368422e-05,
      "loss": 0.0706,
      "step": 1933
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3164825439453125,
      "learning_rate": 8.490526315789474e-05,
      "loss": 0.0714,
      "step": 1934
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.30477720499038696,
      "learning_rate": 8.489473684210527e-05,
      "loss": 0.1087,
      "step": 1935
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3289928436279297,
      "learning_rate": 8.488421052631579e-05,
      "loss": 0.1027,
      "step": 1936
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.352488249540329,
      "learning_rate": 8.487368421052632e-05,
      "loss": 0.1029,
      "step": 1937
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3418242335319519,
      "learning_rate": 8.486315789473684e-05,
      "loss": 0.1257,
      "step": 1938
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2863060534000397,
      "learning_rate": 8.485263157894738e-05,
      "loss": 0.0997,
      "step": 1939
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2849973142147064,
      "learning_rate": 8.48421052631579e-05,
      "loss": 0.0918,
      "step": 1940
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.34162235260009766,
      "learning_rate": 8.483157894736843e-05,
      "loss": 0.0809,
      "step": 1941
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3154650330543518,
      "learning_rate": 8.482105263157895e-05,
      "loss": 0.0988,
      "step": 1942
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.30620068311691284,
      "learning_rate": 8.481052631578948e-05,
      "loss": 0.116,
      "step": 1943
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.35431694984436035,
      "learning_rate": 8.48e-05,
      "loss": 0.1467,
      "step": 1944
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.25108858942985535,
      "learning_rate": 8.478947368421053e-05,
      "loss": 0.1135,
      "step": 1945
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.33995187282562256,
      "learning_rate": 8.477894736842106e-05,
      "loss": 0.1021,
      "step": 1946
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3821974992752075,
      "learning_rate": 8.476842105263159e-05,
      "loss": 0.1067,
      "step": 1947
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2762429714202881,
      "learning_rate": 8.475789473684211e-05,
      "loss": 0.1148,
      "step": 1948
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.24994546175003052,
      "learning_rate": 8.474736842105262e-05,
      "loss": 0.0869,
      "step": 1949
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2926790714263916,
      "learning_rate": 8.473684210526316e-05,
      "loss": 0.0761,
      "step": 1950
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3523232638835907,
      "learning_rate": 8.472631578947369e-05,
      "loss": 0.0668,
      "step": 1951
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3350798487663269,
      "learning_rate": 8.471578947368421e-05,
      "loss": 0.1419,
      "step": 1952
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.28065136075019836,
      "learning_rate": 8.470526315789474e-05,
      "loss": 0.1055,
      "step": 1953
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.23922528326511383,
      "learning_rate": 8.469473684210527e-05,
      "loss": 0.0673,
      "step": 1954
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2440710812807083,
      "learning_rate": 8.468421052631579e-05,
      "loss": 0.1029,
      "step": 1955
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3033164143562317,
      "learning_rate": 8.467368421052631e-05,
      "loss": 0.0998,
      "step": 1956
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.2874339520931244,
      "learning_rate": 8.466315789473685e-05,
      "loss": 0.0945,
      "step": 1957
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3222496211528778,
      "learning_rate": 8.465263157894737e-05,
      "loss": 0.1122,
      "step": 1958
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2700293958187103,
      "learning_rate": 8.46421052631579e-05,
      "loss": 0.0864,
      "step": 1959
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.30579662322998047,
      "learning_rate": 8.463157894736842e-05,
      "loss": 0.0927,
      "step": 1960
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.23855049908161163,
      "learning_rate": 8.462105263157896e-05,
      "loss": 0.0715,
      "step": 1961
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3098030388355255,
      "learning_rate": 8.461052631578947e-05,
      "loss": 0.0961,
      "step": 1962
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3069363534450531,
      "learning_rate": 8.46e-05,
      "loss": 0.0684,
      "step": 1963
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3112044036388397,
      "learning_rate": 8.458947368421053e-05,
      "loss": 0.1073,
      "step": 1964
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2728496491909027,
      "learning_rate": 8.457894736842106e-05,
      "loss": 0.1017,
      "step": 1965
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.32412999868392944,
      "learning_rate": 8.456842105263158e-05,
      "loss": 0.0848,
      "step": 1966
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2912779152393341,
      "learning_rate": 8.455789473684211e-05,
      "loss": 0.0957,
      "step": 1967
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.33481618762016296,
      "learning_rate": 8.454736842105263e-05,
      "loss": 0.1707,
      "step": 1968
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.260699987411499,
      "learning_rate": 8.453684210526316e-05,
      "loss": 0.0939,
      "step": 1969
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3095528185367584,
      "learning_rate": 8.452631578947368e-05,
      "loss": 0.0906,
      "step": 1970
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.31928980350494385,
      "learning_rate": 8.451578947368422e-05,
      "loss": 0.0742,
      "step": 1971
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.31682685017585754,
      "learning_rate": 8.450526315789475e-05,
      "loss": 0.0841,
      "step": 1972
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25641122460365295,
      "learning_rate": 8.449473684210527e-05,
      "loss": 0.0713,
      "step": 1973
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25821900367736816,
      "learning_rate": 8.44842105263158e-05,
      "loss": 0.0703,
      "step": 1974
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3402215540409088,
      "learning_rate": 8.447368421052632e-05,
      "loss": 0.1176,
      "step": 1975
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.33567899465560913,
      "learning_rate": 8.446315789473684e-05,
      "loss": 0.0785,
      "step": 1976
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3020683526992798,
      "learning_rate": 8.445263157894737e-05,
      "loss": 0.114,
      "step": 1977
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25055626034736633,
      "learning_rate": 8.44421052631579e-05,
      "loss": 0.0681,
      "step": 1978
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.26926928758621216,
      "learning_rate": 8.443157894736843e-05,
      "loss": 0.0565,
      "step": 1979
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.22408302128314972,
      "learning_rate": 8.442105263157896e-05,
      "loss": 0.0689,
      "step": 1980
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.29774409532546997,
      "learning_rate": 8.441052631578947e-05,
      "loss": 0.1048,
      "step": 1981
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2693836987018585,
      "learning_rate": 8.44e-05,
      "loss": 0.0732,
      "step": 1982
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25515371561050415,
      "learning_rate": 8.438947368421053e-05,
      "loss": 0.082,
      "step": 1983
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.28962960839271545,
      "learning_rate": 8.437894736842105e-05,
      "loss": 0.095,
      "step": 1984
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.24660855531692505,
      "learning_rate": 8.436842105263158e-05,
      "loss": 0.0771,
      "step": 1985
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3130497336387634,
      "learning_rate": 8.435789473684212e-05,
      "loss": 0.1023,
      "step": 1986
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.27013763785362244,
      "learning_rate": 8.434736842105263e-05,
      "loss": 0.0842,
      "step": 1987
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2121742218732834,
      "learning_rate": 8.433684210526315e-05,
      "loss": 0.0527,
      "step": 1988
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2621551752090454,
      "learning_rate": 8.432631578947369e-05,
      "loss": 0.0791,
      "step": 1989
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3156560957431793,
      "learning_rate": 8.431578947368422e-05,
      "loss": 0.1475,
      "step": 1990
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.27952125668525696,
      "learning_rate": 8.430526315789474e-05,
      "loss": 0.0912,
      "step": 1991
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2928366959095001,
      "learning_rate": 8.429473684210526e-05,
      "loss": 0.0866,
      "step": 1992
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3025122880935669,
      "learning_rate": 8.42842105263158e-05,
      "loss": 0.0545,
      "step": 1993
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.33053532242774963,
      "learning_rate": 8.427368421052631e-05,
      "loss": 0.0664,
      "step": 1994
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2652941346168518,
      "learning_rate": 8.426315789473684e-05,
      "loss": 0.074,
      "step": 1995
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.30539584159851074,
      "learning_rate": 8.425263157894738e-05,
      "loss": 0.0737,
      "step": 1996
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.23977413773536682,
      "learning_rate": 8.42421052631579e-05,
      "loss": 0.0564,
      "step": 1997
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.32327789068222046,
      "learning_rate": 8.423157894736843e-05,
      "loss": 0.0699,
      "step": 1998
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.31561827659606934,
      "learning_rate": 8.422105263157895e-05,
      "loss": 0.0939,
      "step": 1999
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2736247777938843,
      "learning_rate": 8.421052631578948e-05,
      "loss": 0.0998,
      "step": 2000
    },
    {
      "epoch": 7.01,
      "eval_loss": 0.12181713432073593,
      "eval_runtime": 876.2477,
      "eval_samples_per_second": 2.842,
      "eval_steps_per_second": 0.045,
      "eval_wer": 10.334216266749767,
      "step": 2000
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2657729387283325,
      "learning_rate": 8.42e-05,
      "loss": 0.0941,
      "step": 2001
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.4033851623535156,
      "learning_rate": 8.418947368421052e-05,
      "loss": 0.1059,
      "step": 2002
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3764915466308594,
      "learning_rate": 8.417894736842106e-05,
      "loss": 0.1258,
      "step": 2003
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2880963981151581,
      "learning_rate": 8.416842105263159e-05,
      "loss": 0.0873,
      "step": 2004
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2910038232803345,
      "learning_rate": 8.415789473684211e-05,
      "loss": 0.0907,
      "step": 2005
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3011389970779419,
      "learning_rate": 8.414736842105264e-05,
      "loss": 0.1486,
      "step": 2006
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2778605818748474,
      "learning_rate": 8.413684210526316e-05,
      "loss": 0.0727,
      "step": 2007
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.26780739426612854,
      "learning_rate": 8.412631578947369e-05,
      "loss": 0.0714,
      "step": 2008
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.29140087962150574,
      "learning_rate": 8.411578947368421e-05,
      "loss": 0.0848,
      "step": 2009
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.30101290345191956,
      "learning_rate": 8.410526315789475e-05,
      "loss": 0.0853,
      "step": 2010
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.292571097612381,
      "learning_rate": 8.409473684210527e-05,
      "loss": 0.0769,
      "step": 2011
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2904236912727356,
      "learning_rate": 8.40842105263158e-05,
      "loss": 0.1095,
      "step": 2012
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.293267160654068,
      "learning_rate": 8.407368421052631e-05,
      "loss": 0.086,
      "step": 2013
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.29634422063827515,
      "learning_rate": 8.406315789473685e-05,
      "loss": 0.0967,
      "step": 2014
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.281644344329834,
      "learning_rate": 8.405263157894737e-05,
      "loss": 0.0932,
      "step": 2015
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2764025628566742,
      "learning_rate": 8.40421052631579e-05,
      "loss": 0.0946,
      "step": 2016
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25664204359054565,
      "learning_rate": 8.403157894736842e-05,
      "loss": 0.0709,
      "step": 2017
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.32086053490638733,
      "learning_rate": 8.402105263157896e-05,
      "loss": 0.098,
      "step": 2018
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2585082948207855,
      "learning_rate": 8.401052631578947e-05,
      "loss": 0.0803,
      "step": 2019
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3167758285999298,
      "learning_rate": 8.4e-05,
      "loss": 0.1254,
      "step": 2020
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3380465805530548,
      "learning_rate": 8.398947368421053e-05,
      "loss": 0.1405,
      "step": 2021
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2942507266998291,
      "learning_rate": 8.397894736842106e-05,
      "loss": 0.0817,
      "step": 2022
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3231518864631653,
      "learning_rate": 8.396842105263158e-05,
      "loss": 0.1123,
      "step": 2023
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.26638829708099365,
      "learning_rate": 8.395789473684211e-05,
      "loss": 0.0595,
      "step": 2024
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2712267339229584,
      "learning_rate": 8.394736842105263e-05,
      "loss": 0.0833,
      "step": 2025
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3750119209289551,
      "learning_rate": 8.393684210526316e-05,
      "loss": 0.083,
      "step": 2026
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.29545414447784424,
      "learning_rate": 8.392631578947368e-05,
      "loss": 0.0746,
      "step": 2027
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2673341929912567,
      "learning_rate": 8.391578947368422e-05,
      "loss": 0.0604,
      "step": 2028
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3196527063846588,
      "learning_rate": 8.390526315789474e-05,
      "loss": 0.0866,
      "step": 2029
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3540688753128052,
      "learning_rate": 8.389473684210527e-05,
      "loss": 0.1246,
      "step": 2030
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3278014659881592,
      "learning_rate": 8.38842105263158e-05,
      "loss": 0.0793,
      "step": 2031
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2567614018917084,
      "learning_rate": 8.387368421052632e-05,
      "loss": 0.0768,
      "step": 2032
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3039172291755676,
      "learning_rate": 8.386315789473684e-05,
      "loss": 0.0821,
      "step": 2033
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.25648388266563416,
      "learning_rate": 8.385263157894737e-05,
      "loss": 0.0865,
      "step": 2034
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2597982585430145,
      "learning_rate": 8.38421052631579e-05,
      "loss": 0.0787,
      "step": 2035
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3054894804954529,
      "learning_rate": 8.383157894736843e-05,
      "loss": 0.1009,
      "step": 2036
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.26315781474113464,
      "learning_rate": 8.382105263157895e-05,
      "loss": 0.0641,
      "step": 2037
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3016936182975769,
      "learning_rate": 8.381052631578948e-05,
      "loss": 0.0823,
      "step": 2038
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2634160816669464,
      "learning_rate": 8.38e-05,
      "loss": 0.0931,
      "step": 2039
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3276051878929138,
      "learning_rate": 8.378947368421053e-05,
      "loss": 0.0662,
      "step": 2040
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.24664521217346191,
      "learning_rate": 8.377894736842105e-05,
      "loss": 0.0583,
      "step": 2041
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2793326675891876,
      "learning_rate": 8.376842105263159e-05,
      "loss": 0.0787,
      "step": 2042
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2789125144481659,
      "learning_rate": 8.375789473684212e-05,
      "loss": 0.0676,
      "step": 2043
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.28828200697898865,
      "learning_rate": 8.374736842105264e-05,
      "loss": 0.0772,
      "step": 2044
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.27003422379493713,
      "learning_rate": 8.373684210526315e-05,
      "loss": 0.0755,
      "step": 2045
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2708222270011902,
      "learning_rate": 8.372631578947369e-05,
      "loss": 0.0985,
      "step": 2046
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.32963094115257263,
      "learning_rate": 8.371578947368421e-05,
      "loss": 0.1608,
      "step": 2047
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3128167986869812,
      "learning_rate": 8.370526315789474e-05,
      "loss": 0.155,
      "step": 2048
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2808327376842499,
      "learning_rate": 8.369473684210526e-05,
      "loss": 0.1163,
      "step": 2049
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.37440434098243713,
      "learning_rate": 8.36842105263158e-05,
      "loss": 0.0876,
      "step": 2050
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.28150179982185364,
      "learning_rate": 8.367368421052631e-05,
      "loss": 0.0923,
      "step": 2051
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3110315501689911,
      "learning_rate": 8.366315789473684e-05,
      "loss": 0.0968,
      "step": 2052
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.35127320885658264,
      "learning_rate": 8.365263157894738e-05,
      "loss": 0.0982,
      "step": 2053
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.27349168062210083,
      "learning_rate": 8.36421052631579e-05,
      "loss": 0.1049,
      "step": 2054
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.2518745958805084,
      "learning_rate": 8.363157894736843e-05,
      "loss": 0.0802,
      "step": 2055
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.22428426146507263,
      "learning_rate": 8.362105263157895e-05,
      "loss": 0.0538,
      "step": 2056
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.3719005584716797,
      "learning_rate": 8.361052631578947e-05,
      "loss": 0.0827,
      "step": 2057
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3171416223049164,
      "learning_rate": 8.36e-05,
      "loss": 0.1019,
      "step": 2058
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3155761659145355,
      "learning_rate": 8.358947368421052e-05,
      "loss": 0.092,
      "step": 2059
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2652496099472046,
      "learning_rate": 8.357894736842106e-05,
      "loss": 0.0778,
      "step": 2060
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3011951148509979,
      "learning_rate": 8.356842105263159e-05,
      "loss": 0.0759,
      "step": 2061
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3251767158508301,
      "learning_rate": 8.355789473684211e-05,
      "loss": 0.1047,
      "step": 2062
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2944650650024414,
      "learning_rate": 8.354736842105264e-05,
      "loss": 0.1092,
      "step": 2063
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.24163079261779785,
      "learning_rate": 8.353684210526316e-05,
      "loss": 0.068,
      "step": 2064
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.27978426218032837,
      "learning_rate": 8.352631578947369e-05,
      "loss": 0.0857,
      "step": 2065
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2880212366580963,
      "learning_rate": 8.351578947368421e-05,
      "loss": 0.1138,
      "step": 2066
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.24640314280986786,
      "learning_rate": 8.350526315789475e-05,
      "loss": 0.0684,
      "step": 2067
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.23830004036426544,
      "learning_rate": 8.349473684210527e-05,
      "loss": 0.069,
      "step": 2068
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.33129629492759705,
      "learning_rate": 8.34842105263158e-05,
      "loss": 0.1437,
      "step": 2069
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.30841800570487976,
      "learning_rate": 8.347368421052631e-05,
      "loss": 0.1042,
      "step": 2070
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26233991980552673,
      "learning_rate": 8.346315789473685e-05,
      "loss": 0.0814,
      "step": 2071
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.34890034794807434,
      "learning_rate": 8.345263157894737e-05,
      "loss": 0.0939,
      "step": 2072
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2792089283466339,
      "learning_rate": 8.34421052631579e-05,
      "loss": 0.0814,
      "step": 2073
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2260952889919281,
      "learning_rate": 8.343157894736843e-05,
      "loss": 0.0812,
      "step": 2074
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3290688395500183,
      "learning_rate": 8.342105263157896e-05,
      "loss": 0.1389,
      "step": 2075
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3235413134098053,
      "learning_rate": 8.341052631578947e-05,
      "loss": 0.0738,
      "step": 2076
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.35562682151794434,
      "learning_rate": 8.34e-05,
      "loss": 0.091,
      "step": 2077
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26388195157051086,
      "learning_rate": 8.338947368421053e-05,
      "loss": 0.0681,
      "step": 2078
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2799985706806183,
      "learning_rate": 8.337894736842106e-05,
      "loss": 0.0733,
      "step": 2079
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.23706114292144775,
      "learning_rate": 8.336842105263158e-05,
      "loss": 0.0674,
      "step": 2080
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.30978041887283325,
      "learning_rate": 8.33578947368421e-05,
      "loss": 0.0981,
      "step": 2081
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.31736651062965393,
      "learning_rate": 8.334736842105264e-05,
      "loss": 0.1051,
      "step": 2082
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2633378505706787,
      "learning_rate": 8.333684210526316e-05,
      "loss": 0.089,
      "step": 2083
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3468989133834839,
      "learning_rate": 8.332631578947368e-05,
      "loss": 0.0914,
      "step": 2084
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2370850145816803,
      "learning_rate": 8.331578947368422e-05,
      "loss": 0.0643,
      "step": 2085
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.38035494089126587,
      "learning_rate": 8.330526315789474e-05,
      "loss": 0.0967,
      "step": 2086
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29354438185691833,
      "learning_rate": 8.329473684210527e-05,
      "loss": 0.0863,
      "step": 2087
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3126194179058075,
      "learning_rate": 8.328421052631579e-05,
      "loss": 0.0916,
      "step": 2088
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.25973594188690186,
      "learning_rate": 8.327368421052632e-05,
      "loss": 0.0916,
      "step": 2089
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3482590913772583,
      "learning_rate": 8.326315789473684e-05,
      "loss": 0.0902,
      "step": 2090
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3038763701915741,
      "learning_rate": 8.325263157894737e-05,
      "loss": 0.0611,
      "step": 2091
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26392248272895813,
      "learning_rate": 8.32421052631579e-05,
      "loss": 0.0676,
      "step": 2092
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.24984388053417206,
      "learning_rate": 8.323157894736843e-05,
      "loss": 0.0836,
      "step": 2093
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3356013000011444,
      "learning_rate": 8.322105263157895e-05,
      "loss": 0.1501,
      "step": 2094
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2503645718097687,
      "learning_rate": 8.321052631578948e-05,
      "loss": 0.0603,
      "step": 2095
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2627218961715698,
      "learning_rate": 8.32e-05,
      "loss": 0.0612,
      "step": 2096
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3278588056564331,
      "learning_rate": 8.318947368421053e-05,
      "loss": 0.1115,
      "step": 2097
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29863134026527405,
      "learning_rate": 8.317894736842105e-05,
      "loss": 0.1258,
      "step": 2098
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2603546380996704,
      "learning_rate": 8.316842105263159e-05,
      "loss": 0.0646,
      "step": 2099
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2911725342273712,
      "learning_rate": 8.315789473684212e-05,
      "loss": 0.0783,
      "step": 2100
    },
    {
      "epoch": 7.02,
      "eval_loss": 0.11934352666139603,
      "eval_runtime": 834.9375,
      "eval_samples_per_second": 2.982,
      "eval_steps_per_second": 0.047,
      "eval_wer": 8.82284200685572,
      "step": 2100
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.22641701996326447,
      "learning_rate": 8.314736842105264e-05,
      "loss": 0.0493,
      "step": 2101
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.30397671461105347,
      "learning_rate": 8.313684210526315e-05,
      "loss": 0.123,
      "step": 2102
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.32640132308006287,
      "learning_rate": 8.312631578947369e-05,
      "loss": 0.1376,
      "step": 2103
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.20822744071483612,
      "learning_rate": 8.311578947368421e-05,
      "loss": 0.0516,
      "step": 2104
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29679855704307556,
      "learning_rate": 8.310526315789474e-05,
      "loss": 0.0855,
      "step": 2105
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2618352472782135,
      "learning_rate": 8.309473684210526e-05,
      "loss": 0.0688,
      "step": 2106
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2338971346616745,
      "learning_rate": 8.30842105263158e-05,
      "loss": 0.0729,
      "step": 2107
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3398768901824951,
      "learning_rate": 8.307368421052631e-05,
      "loss": 0.1545,
      "step": 2108
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.25738251209259033,
      "learning_rate": 8.306315789473684e-05,
      "loss": 0.0839,
      "step": 2109
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2717573642730713,
      "learning_rate": 8.305263157894737e-05,
      "loss": 0.0783,
      "step": 2110
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2976222336292267,
      "learning_rate": 8.30421052631579e-05,
      "loss": 0.0692,
      "step": 2111
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2518414556980133,
      "learning_rate": 8.303157894736842e-05,
      "loss": 0.0905,
      "step": 2112
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.27833446860313416,
      "learning_rate": 8.302105263157895e-05,
      "loss": 0.0709,
      "step": 2113
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.33426547050476074,
      "learning_rate": 8.301052631578949e-05,
      "loss": 0.1115,
      "step": 2114
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.32123613357543945,
      "learning_rate": 8.3e-05,
      "loss": 0.1033,
      "step": 2115
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29293394088745117,
      "learning_rate": 8.298947368421052e-05,
      "loss": 0.0889,
      "step": 2116
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.33841001987457275,
      "learning_rate": 8.297894736842106e-05,
      "loss": 0.0652,
      "step": 2117
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.263848215341568,
      "learning_rate": 8.296842105263159e-05,
      "loss": 0.0888,
      "step": 2118
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3056258261203766,
      "learning_rate": 8.295789473684211e-05,
      "loss": 0.0897,
      "step": 2119
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2846051752567291,
      "learning_rate": 8.294736842105263e-05,
      "loss": 0.0909,
      "step": 2120
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.25522980093955994,
      "learning_rate": 8.293684210526316e-05,
      "loss": 0.0778,
      "step": 2121
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2720431983470917,
      "learning_rate": 8.292631578947368e-05,
      "loss": 0.085,
      "step": 2122
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.25686684250831604,
      "learning_rate": 8.291578947368421e-05,
      "loss": 0.0649,
      "step": 2123
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2991351783275604,
      "learning_rate": 8.290526315789475e-05,
      "loss": 0.0915,
      "step": 2124
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3432985544204712,
      "learning_rate": 8.289473684210527e-05,
      "loss": 0.071,
      "step": 2125
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.27139168977737427,
      "learning_rate": 8.28842105263158e-05,
      "loss": 0.1022,
      "step": 2126
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3031452000141144,
      "learning_rate": 8.287368421052632e-05,
      "loss": 0.1099,
      "step": 2127
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.27875444293022156,
      "learning_rate": 8.286315789473685e-05,
      "loss": 0.0715,
      "step": 2128
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2513260841369629,
      "learning_rate": 8.285263157894737e-05,
      "loss": 0.064,
      "step": 2129
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26918351650238037,
      "learning_rate": 8.28421052631579e-05,
      "loss": 0.1034,
      "step": 2130
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26738372445106506,
      "learning_rate": 8.283157894736843e-05,
      "loss": 0.0714,
      "step": 2131
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.27701789140701294,
      "learning_rate": 8.282105263157896e-05,
      "loss": 0.0848,
      "step": 2132
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.34109124541282654,
      "learning_rate": 8.281052631578948e-05,
      "loss": 0.1012,
      "step": 2133
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2676490843296051,
      "learning_rate": 8.28e-05,
      "loss": 0.0664,
      "step": 2134
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.28299909830093384,
      "learning_rate": 8.278947368421053e-05,
      "loss": 0.101,
      "step": 2135
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29929518699645996,
      "learning_rate": 8.277894736842106e-05,
      "loss": 0.1086,
      "step": 2136
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.31288421154022217,
      "learning_rate": 8.276842105263158e-05,
      "loss": 0.1011,
      "step": 2137
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2687467038631439,
      "learning_rate": 8.27578947368421e-05,
      "loss": 0.084,
      "step": 2138
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.24673868715763092,
      "learning_rate": 8.274736842105264e-05,
      "loss": 0.0789,
      "step": 2139
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3154197335243225,
      "learning_rate": 8.273684210526315e-05,
      "loss": 0.0975,
      "step": 2140
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3294009566307068,
      "learning_rate": 8.272631578947368e-05,
      "loss": 0.1508,
      "step": 2141
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.29814642667770386,
      "learning_rate": 8.271578947368422e-05,
      "loss": 0.0984,
      "step": 2142
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.28321367502212524,
      "learning_rate": 8.270526315789474e-05,
      "loss": 0.0895,
      "step": 2143
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.30628344416618347,
      "learning_rate": 8.269473684210527e-05,
      "loss": 0.1104,
      "step": 2144
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3410477042198181,
      "learning_rate": 8.268421052631579e-05,
      "loss": 0.1095,
      "step": 2145
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2782745659351349,
      "learning_rate": 8.267368421052632e-05,
      "loss": 0.1014,
      "step": 2146
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3069624602794647,
      "learning_rate": 8.266315789473684e-05,
      "loss": 0.093,
      "step": 2147
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2906523644924164,
      "learning_rate": 8.265263157894737e-05,
      "loss": 0.0848,
      "step": 2148
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2599973678588867,
      "learning_rate": 8.26421052631579e-05,
      "loss": 0.0658,
      "step": 2149
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2797418534755707,
      "learning_rate": 8.263157894736843e-05,
      "loss": 0.1194,
      "step": 2150
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.26273030042648315,
      "learning_rate": 8.262105263157895e-05,
      "loss": 0.0534,
      "step": 2151
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.3483984172344208,
      "learning_rate": 8.261052631578948e-05,
      "loss": 0.1475,
      "step": 2152
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.31004828214645386,
      "learning_rate": 8.26e-05,
      "loss": 0.0792,
      "step": 2153
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.32356855273246765,
      "learning_rate": 8.258947368421053e-05,
      "loss": 0.1014,
      "step": 2154
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.31422120332717896,
      "learning_rate": 8.257894736842105e-05,
      "loss": 0.1118,
      "step": 2155
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.30214354395866394,
      "learning_rate": 8.256842105263159e-05,
      "loss": 0.0991,
      "step": 2156
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.24637214839458466,
      "learning_rate": 8.255789473684211e-05,
      "loss": 0.0687,
      "step": 2157
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.27543047070503235,
      "learning_rate": 8.254736842105264e-05,
      "loss": 0.063,
      "step": 2158
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.30397313833236694,
      "learning_rate": 8.253684210526316e-05,
      "loss": 0.0855,
      "step": 2159
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.30851614475250244,
      "learning_rate": 8.252631578947369e-05,
      "loss": 0.1033,
      "step": 2160
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.27363985776901245,
      "learning_rate": 8.251578947368421e-05,
      "loss": 0.0961,
      "step": 2161
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.26392924785614014,
      "learning_rate": 8.250526315789474e-05,
      "loss": 0.0837,
      "step": 2162
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.27227792143821716,
      "learning_rate": 8.249473684210528e-05,
      "loss": 0.0798,
      "step": 2163
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.28704342246055603,
      "learning_rate": 8.24842105263158e-05,
      "loss": 0.0915,
      "step": 2164
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.2789914011955261,
      "learning_rate": 8.247368421052632e-05,
      "loss": 0.0666,
      "step": 2165
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.24875646829605103,
      "learning_rate": 8.246315789473684e-05,
      "loss": 0.0786,
      "step": 2166
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.2629435360431671,
      "learning_rate": 8.245263157894737e-05,
      "loss": 0.0655,
      "step": 2167
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.27519506216049194,
      "learning_rate": 8.24421052631579e-05,
      "loss": 0.0811,
      "step": 2168
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.33155983686447144,
      "learning_rate": 8.243157894736842e-05,
      "loss": 0.1117,
      "step": 2169
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.2749364376068115,
      "learning_rate": 8.242105263157895e-05,
      "loss": 0.0951,
      "step": 2170
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.25705769658088684,
      "learning_rate": 8.241052631578949e-05,
      "loss": 0.1071,
      "step": 2171
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.2981470227241516,
      "learning_rate": 8.24e-05,
      "loss": 0.107,
      "step": 2172
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.35070598125457764,
      "learning_rate": 8.238947368421052e-05,
      "loss": 0.0958,
      "step": 2173
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.24129560589790344,
      "learning_rate": 8.237894736842106e-05,
      "loss": 0.083,
      "step": 2174
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.28368863463401794,
      "learning_rate": 8.236842105263158e-05,
      "loss": 0.0661,
      "step": 2175
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.26304811239242554,
      "learning_rate": 8.235789473684211e-05,
      "loss": 0.0784,
      "step": 2176
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.28197816014289856,
      "learning_rate": 8.234736842105263e-05,
      "loss": 0.0931,
      "step": 2177
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.299390584230423,
      "learning_rate": 8.233684210526316e-05,
      "loss": 0.1178,
      "step": 2178
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.2869234085083008,
      "learning_rate": 8.232631578947368e-05,
      "loss": 0.1004,
      "step": 2179
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.3132188022136688,
      "learning_rate": 8.231578947368421e-05,
      "loss": 0.0917,
      "step": 2180
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.29051926732063293,
      "learning_rate": 8.230526315789475e-05,
      "loss": 0.0957,
      "step": 2181
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.26815447211265564,
      "learning_rate": 8.229473684210527e-05,
      "loss": 0.082,
      "step": 2182
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2541210949420929,
      "learning_rate": 8.22842105263158e-05,
      "loss": 0.0831,
      "step": 2183
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24020937085151672,
      "learning_rate": 8.227368421052632e-05,
      "loss": 0.0955,
      "step": 2184
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2599084973335266,
      "learning_rate": 8.226315789473684e-05,
      "loss": 0.0805,
      "step": 2185
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.21158117055892944,
      "learning_rate": 8.225263157894737e-05,
      "loss": 0.0448,
      "step": 2186
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24718640744686127,
      "learning_rate": 8.22421052631579e-05,
      "loss": 0.0775,
      "step": 2187
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.22185054421424866,
      "learning_rate": 8.223157894736843e-05,
      "loss": 0.0437,
      "step": 2188
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.270487904548645,
      "learning_rate": 8.222105263157896e-05,
      "loss": 0.0943,
      "step": 2189
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2658725082874298,
      "learning_rate": 8.221052631578948e-05,
      "loss": 0.0867,
      "step": 2190
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.22092121839523315,
      "learning_rate": 8.22e-05,
      "loss": 0.0708,
      "step": 2191
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25010427832603455,
      "learning_rate": 8.218947368421053e-05,
      "loss": 0.0794,
      "step": 2192
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2858930230140686,
      "learning_rate": 8.217894736842106e-05,
      "loss": 0.0922,
      "step": 2193
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25128173828125,
      "learning_rate": 8.216842105263158e-05,
      "loss": 0.0841,
      "step": 2194
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.22769123315811157,
      "learning_rate": 8.215789473684212e-05,
      "loss": 0.0667,
      "step": 2195
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.34271493554115295,
      "learning_rate": 8.214736842105264e-05,
      "loss": 0.0794,
      "step": 2196
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.26683327555656433,
      "learning_rate": 8.213684210526315e-05,
      "loss": 0.08,
      "step": 2197
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.29450806975364685,
      "learning_rate": 8.212631578947368e-05,
      "loss": 0.133,
      "step": 2198
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2815782427787781,
      "learning_rate": 8.211578947368422e-05,
      "loss": 0.0875,
      "step": 2199
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25433921813964844,
      "learning_rate": 8.210526315789474e-05,
      "loss": 0.0857,
      "step": 2200
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.11805955320596695,
      "eval_runtime": 831.2754,
      "eval_samples_per_second": 2.995,
      "eval_steps_per_second": 0.047,
      "eval_wer": 8.65534434403241,
      "step": 2200
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.28742513060569763,
      "learning_rate": 8.209473684210527e-05,
      "loss": 0.0868,
      "step": 2201
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24363760650157928,
      "learning_rate": 8.208421052631579e-05,
      "loss": 0.0882,
      "step": 2202
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.23899145424365997,
      "learning_rate": 8.207368421052633e-05,
      "loss": 0.0546,
      "step": 2203
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.26142093539237976,
      "learning_rate": 8.206315789473684e-05,
      "loss": 0.0515,
      "step": 2204
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.23943926393985748,
      "learning_rate": 8.205263157894736e-05,
      "loss": 0.071,
      "step": 2205
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.22946441173553467,
      "learning_rate": 8.20421052631579e-05,
      "loss": 0.0634,
      "step": 2206
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.23480387032032013,
      "learning_rate": 8.203157894736843e-05,
      "loss": 0.0671,
      "step": 2207
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.22287578880786896,
      "learning_rate": 8.202105263157895e-05,
      "loss": 0.0493,
      "step": 2208
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.26076212525367737,
      "learning_rate": 8.201052631578948e-05,
      "loss": 0.0644,
      "step": 2209
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2598487436771393,
      "learning_rate": 8.2e-05,
      "loss": 0.0836,
      "step": 2210
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25972676277160645,
      "learning_rate": 8.198947368421053e-05,
      "loss": 0.0635,
      "step": 2211
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2602258324623108,
      "learning_rate": 8.197894736842105e-05,
      "loss": 0.0787,
      "step": 2212
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.29248490929603577,
      "learning_rate": 8.196842105263159e-05,
      "loss": 0.0655,
      "step": 2213
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.30871856212615967,
      "learning_rate": 8.195789473684211e-05,
      "loss": 0.0649,
      "step": 2214
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.26393869519233704,
      "learning_rate": 8.194736842105264e-05,
      "loss": 0.069,
      "step": 2215
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.3348006308078766,
      "learning_rate": 8.193684210526316e-05,
      "loss": 0.1003,
      "step": 2216
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.3006128966808319,
      "learning_rate": 8.192631578947369e-05,
      "loss": 0.0862,
      "step": 2217
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24094630777835846,
      "learning_rate": 8.191578947368421e-05,
      "loss": 0.0518,
      "step": 2218
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24508075416088104,
      "learning_rate": 8.190526315789474e-05,
      "loss": 0.0607,
      "step": 2219
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2536582350730896,
      "learning_rate": 8.189473684210527e-05,
      "loss": 0.0957,
      "step": 2220
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25336721539497375,
      "learning_rate": 8.18842105263158e-05,
      "loss": 0.0874,
      "step": 2221
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25117453932762146,
      "learning_rate": 8.187368421052632e-05,
      "loss": 0.0506,
      "step": 2222
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.25289106369018555,
      "learning_rate": 8.186315789473685e-05,
      "loss": 0.0561,
      "step": 2223
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.28813502192497253,
      "learning_rate": 8.185263157894737e-05,
      "loss": 0.1234,
      "step": 2224
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24786795675754547,
      "learning_rate": 8.18421052631579e-05,
      "loss": 0.079,
      "step": 2225
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2526094317436218,
      "learning_rate": 8.183157894736842e-05,
      "loss": 0.0672,
      "step": 2226
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.2748411297798157,
      "learning_rate": 8.182105263157896e-05,
      "loss": 0.0589,
      "step": 2227
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.20969846844673157,
      "learning_rate": 8.181052631578949e-05,
      "loss": 0.0455,
      "step": 2228
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.24262185394763947,
      "learning_rate": 8.18e-05,
      "loss": 0.0615,
      "step": 2229
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.22184550762176514,
      "learning_rate": 8.178947368421052e-05,
      "loss": 0.0524,
      "step": 2230
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27887681126594543,
      "learning_rate": 8.177894736842106e-05,
      "loss": 0.0721,
      "step": 2231
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.310932457447052,
      "learning_rate": 8.176842105263158e-05,
      "loss": 0.1237,
      "step": 2232
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27480244636535645,
      "learning_rate": 8.175789473684211e-05,
      "loss": 0.0778,
      "step": 2233
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2879692316055298,
      "learning_rate": 8.174736842105263e-05,
      "loss": 0.1137,
      "step": 2234
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.21124987304210663,
      "learning_rate": 8.173684210526317e-05,
      "loss": 0.0526,
      "step": 2235
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2584662139415741,
      "learning_rate": 8.172631578947368e-05,
      "loss": 0.0823,
      "step": 2236
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2505844831466675,
      "learning_rate": 8.17157894736842e-05,
      "loss": 0.0726,
      "step": 2237
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2830938398838043,
      "learning_rate": 8.170526315789474e-05,
      "loss": 0.0677,
      "step": 2238
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.28149059414863586,
      "learning_rate": 8.169473684210527e-05,
      "loss": 0.1073,
      "step": 2239
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24572992324829102,
      "learning_rate": 8.16842105263158e-05,
      "loss": 0.0506,
      "step": 2240
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2857033312320709,
      "learning_rate": 8.167368421052632e-05,
      "loss": 0.0657,
      "step": 2241
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2482443004846573,
      "learning_rate": 8.166315789473684e-05,
      "loss": 0.0469,
      "step": 2242
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3641913831233978,
      "learning_rate": 8.165263157894737e-05,
      "loss": 0.13,
      "step": 2243
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24220027029514313,
      "learning_rate": 8.164210526315789e-05,
      "loss": 0.0674,
      "step": 2244
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.30051398277282715,
      "learning_rate": 8.163157894736843e-05,
      "loss": 0.0833,
      "step": 2245
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3044663071632385,
      "learning_rate": 8.162105263157896e-05,
      "loss": 0.0982,
      "step": 2246
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25930094718933105,
      "learning_rate": 8.161052631578948e-05,
      "loss": 0.0674,
      "step": 2247
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24873991310596466,
      "learning_rate": 8.16e-05,
      "loss": 0.0584,
      "step": 2248
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25755926966667175,
      "learning_rate": 8.158947368421053e-05,
      "loss": 0.061,
      "step": 2249
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.22234222292900085,
      "learning_rate": 8.157894736842105e-05,
      "loss": 0.0448,
      "step": 2250
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2338351011276245,
      "learning_rate": 8.156842105263158e-05,
      "loss": 0.0646,
      "step": 2251
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.26213863492012024,
      "learning_rate": 8.155789473684212e-05,
      "loss": 0.0764,
      "step": 2252
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2289806753396988,
      "learning_rate": 8.154736842105264e-05,
      "loss": 0.0547,
      "step": 2253
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3016250729560852,
      "learning_rate": 8.153684210526317e-05,
      "loss": 0.1391,
      "step": 2254
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27239570021629333,
      "learning_rate": 8.152631578947368e-05,
      "loss": 0.0814,
      "step": 2255
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2611831724643707,
      "learning_rate": 8.151578947368422e-05,
      "loss": 0.0747,
      "step": 2256
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.253080815076828,
      "learning_rate": 8.150526315789474e-05,
      "loss": 0.0725,
      "step": 2257
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2719739079475403,
      "learning_rate": 8.149473684210526e-05,
      "loss": 0.0998,
      "step": 2258
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29205748438835144,
      "learning_rate": 8.14842105263158e-05,
      "loss": 0.0715,
      "step": 2259
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.23832404613494873,
      "learning_rate": 8.147368421052633e-05,
      "loss": 0.0648,
      "step": 2260
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.36292824149131775,
      "learning_rate": 8.146315789473684e-05,
      "loss": 0.1336,
      "step": 2261
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24249862134456635,
      "learning_rate": 8.145263157894736e-05,
      "loss": 0.0815,
      "step": 2262
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3395611643791199,
      "learning_rate": 8.14421052631579e-05,
      "loss": 0.1004,
      "step": 2263
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3201817572116852,
      "learning_rate": 8.143157894736843e-05,
      "loss": 0.0745,
      "step": 2264
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3243143558502197,
      "learning_rate": 8.142105263157895e-05,
      "loss": 0.1082,
      "step": 2265
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2701399028301239,
      "learning_rate": 8.141052631578948e-05,
      "loss": 0.0757,
      "step": 2266
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29046398401260376,
      "learning_rate": 8.14e-05,
      "loss": 0.0919,
      "step": 2267
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.360251784324646,
      "learning_rate": 8.138947368421052e-05,
      "loss": 0.0732,
      "step": 2268
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2931472361087799,
      "learning_rate": 8.137894736842105e-05,
      "loss": 0.0948,
      "step": 2269
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2693193256855011,
      "learning_rate": 8.136842105263159e-05,
      "loss": 0.0667,
      "step": 2270
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3445656895637512,
      "learning_rate": 8.135789473684211e-05,
      "loss": 0.085,
      "step": 2271
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.31034979224205017,
      "learning_rate": 8.134736842105264e-05,
      "loss": 0.0908,
      "step": 2272
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.26771000027656555,
      "learning_rate": 8.133684210526316e-05,
      "loss": 0.0766,
      "step": 2273
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2980234622955322,
      "learning_rate": 8.132631578947369e-05,
      "loss": 0.0776,
      "step": 2274
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.30039650201797485,
      "learning_rate": 8.131578947368421e-05,
      "loss": 0.0849,
      "step": 2275
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.273565411567688,
      "learning_rate": 8.130526315789474e-05,
      "loss": 0.0732,
      "step": 2276
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3275545537471771,
      "learning_rate": 8.129473684210527e-05,
      "loss": 0.1175,
      "step": 2277
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2662760615348816,
      "learning_rate": 8.12842105263158e-05,
      "loss": 0.0992,
      "step": 2278
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2898640036582947,
      "learning_rate": 8.127368421052632e-05,
      "loss": 0.0916,
      "step": 2279
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.26221340894699097,
      "learning_rate": 8.126315789473685e-05,
      "loss": 0.0844,
      "step": 2280
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3068625330924988,
      "learning_rate": 8.125263157894737e-05,
      "loss": 0.0756,
      "step": 2281
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.26665735244750977,
      "learning_rate": 8.12421052631579e-05,
      "loss": 0.0757,
      "step": 2282
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3113366961479187,
      "learning_rate": 8.123157894736842e-05,
      "loss": 0.1038,
      "step": 2283
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.28682103753089905,
      "learning_rate": 8.122105263157896e-05,
      "loss": 0.0945,
      "step": 2284
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3647478520870209,
      "learning_rate": 8.121052631578948e-05,
      "loss": 0.0989,
      "step": 2285
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.31136494874954224,
      "learning_rate": 8.120000000000001e-05,
      "loss": 0.0801,
      "step": 2286
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25466403365135193,
      "learning_rate": 8.118947368421052e-05,
      "loss": 0.0591,
      "step": 2287
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25142326951026917,
      "learning_rate": 8.117894736842106e-05,
      "loss": 0.0786,
      "step": 2288
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2838633358478546,
      "learning_rate": 8.116842105263158e-05,
      "loss": 0.0565,
      "step": 2289
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.22590655088424683,
      "learning_rate": 8.115789473684211e-05,
      "loss": 0.0565,
      "step": 2290
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3610725998878479,
      "learning_rate": 8.114736842105265e-05,
      "loss": 0.1105,
      "step": 2291
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27460792660713196,
      "learning_rate": 8.113684210526317e-05,
      "loss": 0.101,
      "step": 2292
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27415814995765686,
      "learning_rate": 8.112631578947368e-05,
      "loss": 0.0661,
      "step": 2293
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.40351223945617676,
      "learning_rate": 8.11157894736842e-05,
      "loss": 0.1337,
      "step": 2294
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2753511369228363,
      "learning_rate": 8.110526315789474e-05,
      "loss": 0.0779,
      "step": 2295
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24098077416419983,
      "learning_rate": 8.109473684210527e-05,
      "loss": 0.0719,
      "step": 2296
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.28925344347953796,
      "learning_rate": 8.108421052631579e-05,
      "loss": 0.0967,
      "step": 2297
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.342069536447525,
      "learning_rate": 8.107368421052632e-05,
      "loss": 0.1589,
      "step": 2298
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3016054332256317,
      "learning_rate": 8.106315789473684e-05,
      "loss": 0.0964,
      "step": 2299
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.31828320026397705,
      "learning_rate": 8.105263157894737e-05,
      "loss": 0.0648,
      "step": 2300
    },
    {
      "epoch": 8.01,
      "eval_loss": 0.11658427864313126,
      "eval_runtime": 841.6181,
      "eval_samples_per_second": 2.959,
      "eval_steps_per_second": 0.046,
      "eval_wer": 8.67092552196946,
      "step": 2300
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2905682921409607,
      "learning_rate": 8.104210526315789e-05,
      "loss": 0.0792,
      "step": 2301
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3119186460971832,
      "learning_rate": 8.103157894736843e-05,
      "loss": 0.0837,
      "step": 2302
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3565736413002014,
      "learning_rate": 8.102105263157895e-05,
      "loss": 0.1245,
      "step": 2303
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.30075371265411377,
      "learning_rate": 8.101052631578948e-05,
      "loss": 0.084,
      "step": 2304
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29145410656929016,
      "learning_rate": 8.1e-05,
      "loss": 0.071,
      "step": 2305
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.27234408259391785,
      "learning_rate": 8.098947368421053e-05,
      "loss": 0.0741,
      "step": 2306
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.39561840891838074,
      "learning_rate": 8.097894736842105e-05,
      "loss": 0.0892,
      "step": 2307
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2854582369327545,
      "learning_rate": 8.096842105263158e-05,
      "loss": 0.0644,
      "step": 2308
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3429185152053833,
      "learning_rate": 8.095789473684212e-05,
      "loss": 0.0936,
      "step": 2309
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.36112987995147705,
      "learning_rate": 8.094736842105264e-05,
      "loss": 0.0847,
      "step": 2310
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.28327295184135437,
      "learning_rate": 8.093684210526317e-05,
      "loss": 0.083,
      "step": 2311
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25025883316993713,
      "learning_rate": 8.092631578947369e-05,
      "loss": 0.0685,
      "step": 2312
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29247066378593445,
      "learning_rate": 8.091578947368421e-05,
      "loss": 0.0836,
      "step": 2313
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29188457131385803,
      "learning_rate": 8.090526315789474e-05,
      "loss": 0.0868,
      "step": 2314
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.29200467467308044,
      "learning_rate": 8.089473684210526e-05,
      "loss": 0.08,
      "step": 2315
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3327488601207733,
      "learning_rate": 8.08842105263158e-05,
      "loss": 0.1085,
      "step": 2316
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3305917978286743,
      "learning_rate": 8.087368421052633e-05,
      "loss": 0.0963,
      "step": 2317
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.31428444385528564,
      "learning_rate": 8.086315789473684e-05,
      "loss": 0.0698,
      "step": 2318
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3274242877960205,
      "learning_rate": 8.085263157894736e-05,
      "loss": 0.1097,
      "step": 2319
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.2601305842399597,
      "learning_rate": 8.08421052631579e-05,
      "loss": 0.0744,
      "step": 2320
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.40030571818351746,
      "learning_rate": 8.083157894736842e-05,
      "loss": 0.0857,
      "step": 2321
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.3066186308860779,
      "learning_rate": 8.082105263157895e-05,
      "loss": 0.0905,
      "step": 2322
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.33233001828193665,
      "learning_rate": 8.081052631578947e-05,
      "loss": 0.1063,
      "step": 2323
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.32231637835502625,
      "learning_rate": 8.080000000000001e-05,
      "loss": 0.0821,
      "step": 2324
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.318539023399353,
      "learning_rate": 8.078947368421052e-05,
      "loss": 0.0905,
      "step": 2325
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.318850576877594,
      "learning_rate": 8.077894736842105e-05,
      "loss": 0.0877,
      "step": 2326
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.38244834542274475,
      "learning_rate": 8.076842105263159e-05,
      "loss": 0.0775,
      "step": 2327
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.25266969203948975,
      "learning_rate": 8.075789473684211e-05,
      "loss": 0.0667,
      "step": 2328
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.32065051794052124,
      "learning_rate": 8.074736842105264e-05,
      "loss": 0.0963,
      "step": 2329
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2676653265953064,
      "learning_rate": 8.073684210526316e-05,
      "loss": 0.0686,
      "step": 2330
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29443782567977905,
      "learning_rate": 8.072631578947368e-05,
      "loss": 0.073,
      "step": 2331
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29643696546554565,
      "learning_rate": 8.071578947368421e-05,
      "loss": 0.089,
      "step": 2332
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.338724285364151,
      "learning_rate": 8.070526315789473e-05,
      "loss": 0.0985,
      "step": 2333
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.24107126891613007,
      "learning_rate": 8.069473684210527e-05,
      "loss": 0.0547,
      "step": 2334
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3082999885082245,
      "learning_rate": 8.06842105263158e-05,
      "loss": 0.0676,
      "step": 2335
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.384719580411911,
      "learning_rate": 8.067368421052632e-05,
      "loss": 0.0961,
      "step": 2336
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3394679129123688,
      "learning_rate": 8.066315789473685e-05,
      "loss": 0.1117,
      "step": 2337
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.321342796087265,
      "learning_rate": 8.065263157894737e-05,
      "loss": 0.1085,
      "step": 2338
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3090556561946869,
      "learning_rate": 8.06421052631579e-05,
      "loss": 0.1109,
      "step": 2339
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3443922996520996,
      "learning_rate": 8.063157894736842e-05,
      "loss": 0.0689,
      "step": 2340
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.31986939907073975,
      "learning_rate": 8.062105263157896e-05,
      "loss": 0.0642,
      "step": 2341
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.24407091736793518,
      "learning_rate": 8.061052631578948e-05,
      "loss": 0.0515,
      "step": 2342
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.25678178668022156,
      "learning_rate": 8.060000000000001e-05,
      "loss": 0.0457,
      "step": 2343
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.297714501619339,
      "learning_rate": 8.058947368421053e-05,
      "loss": 0.109,
      "step": 2344
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3433122932910919,
      "learning_rate": 8.057894736842106e-05,
      "loss": 0.0897,
      "step": 2345
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28534939885139465,
      "learning_rate": 8.056842105263158e-05,
      "loss": 0.0795,
      "step": 2346
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.41388335824012756,
      "learning_rate": 8.05578947368421e-05,
      "loss": 0.0928,
      "step": 2347
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28307804465293884,
      "learning_rate": 8.054736842105264e-05,
      "loss": 0.084,
      "step": 2348
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2595920264720917,
      "learning_rate": 8.053684210526317e-05,
      "loss": 0.0499,
      "step": 2349
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3318743109703064,
      "learning_rate": 8.052631578947368e-05,
      "loss": 0.097,
      "step": 2350
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.23500913381576538,
      "learning_rate": 8.05157894736842e-05,
      "loss": 0.0595,
      "step": 2351
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2768774926662445,
      "learning_rate": 8.050526315789474e-05,
      "loss": 0.084,
      "step": 2352
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2571371793746948,
      "learning_rate": 8.049473684210527e-05,
      "loss": 0.0724,
      "step": 2353
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29485902190208435,
      "learning_rate": 8.048421052631579e-05,
      "loss": 0.1043,
      "step": 2354
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30651405453681946,
      "learning_rate": 8.047368421052632e-05,
      "loss": 0.0987,
      "step": 2355
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30580803751945496,
      "learning_rate": 8.046315789473685e-05,
      "loss": 0.1025,
      "step": 2356
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.33664992451667786,
      "learning_rate": 8.045263157894737e-05,
      "loss": 0.1149,
      "step": 2357
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3298336863517761,
      "learning_rate": 8.044210526315789e-05,
      "loss": 0.1179,
      "step": 2358
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29563650488853455,
      "learning_rate": 8.043157894736843e-05,
      "loss": 0.0997,
      "step": 2359
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2762705087661743,
      "learning_rate": 8.042105263157895e-05,
      "loss": 0.096,
      "step": 2360
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.27813002467155457,
      "learning_rate": 8.041052631578948e-05,
      "loss": 0.0837,
      "step": 2361
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3218219578266144,
      "learning_rate": 8.04e-05,
      "loss": 0.0885,
      "step": 2362
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28843003511428833,
      "learning_rate": 8.038947368421053e-05,
      "loss": 0.0843,
      "step": 2363
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29478156566619873,
      "learning_rate": 8.037894736842105e-05,
      "loss": 0.0832,
      "step": 2364
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.24347564578056335,
      "learning_rate": 8.036842105263158e-05,
      "loss": 0.0578,
      "step": 2365
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3199440836906433,
      "learning_rate": 8.035789473684211e-05,
      "loss": 0.1071,
      "step": 2366
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.32130107283592224,
      "learning_rate": 8.034736842105264e-05,
      "loss": 0.0997,
      "step": 2367
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29907143115997314,
      "learning_rate": 8.033684210526316e-05,
      "loss": 0.0933,
      "step": 2368
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29578468203544617,
      "learning_rate": 8.032631578947369e-05,
      "loss": 0.1131,
      "step": 2369
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28510981798171997,
      "learning_rate": 8.031578947368421e-05,
      "loss": 0.0832,
      "step": 2370
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2542148530483246,
      "learning_rate": 8.030526315789474e-05,
      "loss": 0.0779,
      "step": 2371
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.31597980856895447,
      "learning_rate": 8.029473684210526e-05,
      "loss": 0.1037,
      "step": 2372
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3083520233631134,
      "learning_rate": 8.02842105263158e-05,
      "loss": 0.0948,
      "step": 2373
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.295087993144989,
      "learning_rate": 8.027368421052633e-05,
      "loss": 0.1176,
      "step": 2374
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3048592805862427,
      "learning_rate": 8.026315789473685e-05,
      "loss": 0.0853,
      "step": 2375
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28685471415519714,
      "learning_rate": 8.025263157894737e-05,
      "loss": 0.0858,
      "step": 2376
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.26092711091041565,
      "learning_rate": 8.02421052631579e-05,
      "loss": 0.0763,
      "step": 2377
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.25271642208099365,
      "learning_rate": 8.023157894736842e-05,
      "loss": 0.0546,
      "step": 2378
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2748582363128662,
      "learning_rate": 8.022105263157895e-05,
      "loss": 0.0811,
      "step": 2379
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2862153947353363,
      "learning_rate": 8.021052631578949e-05,
      "loss": 0.0738,
      "step": 2380
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3318733870983124,
      "learning_rate": 8.020000000000001e-05,
      "loss": 0.0722,
      "step": 2381
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2852936387062073,
      "learning_rate": 8.018947368421052e-05,
      "loss": 0.077,
      "step": 2382
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.39222806692123413,
      "learning_rate": 8.017894736842105e-05,
      "loss": 0.0892,
      "step": 2383
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3346773386001587,
      "learning_rate": 8.016842105263159e-05,
      "loss": 0.1013,
      "step": 2384
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3209902048110962,
      "learning_rate": 8.015789473684211e-05,
      "loss": 0.1107,
      "step": 2385
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.31099894642829895,
      "learning_rate": 8.014736842105263e-05,
      "loss": 0.0993,
      "step": 2386
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30050957202911377,
      "learning_rate": 8.013684210526316e-05,
      "loss": 0.0839,
      "step": 2387
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3054678440093994,
      "learning_rate": 8.012631578947368e-05,
      "loss": 0.0644,
      "step": 2388
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2901298701763153,
      "learning_rate": 8.011578947368421e-05,
      "loss": 0.0755,
      "step": 2389
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.23911769688129425,
      "learning_rate": 8.010526315789473e-05,
      "loss": 0.0766,
      "step": 2390
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.26680007576942444,
      "learning_rate": 8.009473684210527e-05,
      "loss": 0.086,
      "step": 2391
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3066819906234741,
      "learning_rate": 8.00842105263158e-05,
      "loss": 0.1134,
      "step": 2392
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30758947134017944,
      "learning_rate": 8.007368421052632e-05,
      "loss": 0.0893,
      "step": 2393
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.31776177883148193,
      "learning_rate": 8.006315789473685e-05,
      "loss": 0.1204,
      "step": 2394
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.27271613478660583,
      "learning_rate": 8.005263157894737e-05,
      "loss": 0.0741,
      "step": 2395
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.24315203726291656,
      "learning_rate": 8.00421052631579e-05,
      "loss": 0.071,
      "step": 2396
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2640438675880432,
      "learning_rate": 8.003157894736842e-05,
      "loss": 0.083,
      "step": 2397
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.31082484126091003,
      "learning_rate": 8.002105263157896e-05,
      "loss": 0.0884,
      "step": 2398
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3659609258174896,
      "learning_rate": 8.001052631578948e-05,
      "loss": 0.1018,
      "step": 2399
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29761260747909546,
      "learning_rate": 8e-05,
      "loss": 0.081,
      "step": 2400
    },
    {
      "epoch": 8.02,
      "eval_loss": 0.11527711898088455,
      "eval_runtime": 842.8469,
      "eval_samples_per_second": 2.954,
      "eval_steps_per_second": 0.046,
      "eval_wer": 8.620286693674043,
      "step": 2400
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3025068938732147,
      "learning_rate": 7.998947368421053e-05,
      "loss": 0.0766,
      "step": 2401
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3524443805217743,
      "learning_rate": 7.997894736842106e-05,
      "loss": 0.1063,
      "step": 2402
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.29690632224082947,
      "learning_rate": 7.996842105263158e-05,
      "loss": 0.0893,
      "step": 2403
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30385756492614746,
      "learning_rate": 7.99578947368421e-05,
      "loss": 0.0853,
      "step": 2404
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2960124909877777,
      "learning_rate": 7.994736842105264e-05,
      "loss": 0.0576,
      "step": 2405
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.35020872950553894,
      "learning_rate": 7.993684210526317e-05,
      "loss": 0.0962,
      "step": 2406
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2894992530345917,
      "learning_rate": 7.992631578947369e-05,
      "loss": 0.094,
      "step": 2407
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.28956377506256104,
      "learning_rate": 7.991578947368422e-05,
      "loss": 0.0626,
      "step": 2408
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30304500460624695,
      "learning_rate": 7.990526315789474e-05,
      "loss": 0.107,
      "step": 2409
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30961984395980835,
      "learning_rate": 7.989473684210527e-05,
      "loss": 0.0857,
      "step": 2410
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3778430223464966,
      "learning_rate": 7.988421052631579e-05,
      "loss": 0.083,
      "step": 2411
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.32558000087738037,
      "learning_rate": 7.987368421052633e-05,
      "loss": 0.0823,
      "step": 2412
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.35711434483528137,
      "learning_rate": 7.986315789473685e-05,
      "loss": 0.1221,
      "step": 2413
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.25861021876335144,
      "learning_rate": 7.985263157894736e-05,
      "loss": 0.0732,
      "step": 2414
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.30397093296051025,
      "learning_rate": 7.984210526315789e-05,
      "loss": 0.0992,
      "step": 2415
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3282579183578491,
      "learning_rate": 7.983157894736843e-05,
      "loss": 0.1053,
      "step": 2416
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.32317233085632324,
      "learning_rate": 7.982105263157895e-05,
      "loss": 0.0717,
      "step": 2417
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3350406289100647,
      "learning_rate": 7.981052631578948e-05,
      "loss": 0.1143,
      "step": 2418
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3020707368850708,
      "learning_rate": 7.98e-05,
      "loss": 0.0627,
      "step": 2419
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2918436825275421,
      "learning_rate": 7.978947368421053e-05,
      "loss": 0.0865,
      "step": 2420
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2500699460506439,
      "learning_rate": 7.977894736842105e-05,
      "loss": 0.0542,
      "step": 2421
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3264565169811249,
      "learning_rate": 7.976842105263158e-05,
      "loss": 0.0923,
      "step": 2422
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3081848621368408,
      "learning_rate": 7.975789473684211e-05,
      "loss": 0.1006,
      "step": 2423
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2817496359348297,
      "learning_rate": 7.974736842105264e-05,
      "loss": 0.0657,
      "step": 2424
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.27831560373306274,
      "learning_rate": 7.973684210526316e-05,
      "loss": 0.0642,
      "step": 2425
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.26061633229255676,
      "learning_rate": 7.972631578947369e-05,
      "loss": 0.0701,
      "step": 2426
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.3054140508174896,
      "learning_rate": 7.971578947368421e-05,
      "loss": 0.0843,
      "step": 2427
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.34252771735191345,
      "learning_rate": 7.970526315789474e-05,
      "loss": 0.119,
      "step": 2428
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2801195979118347,
      "learning_rate": 7.969473684210526e-05,
      "loss": 0.0617,
      "step": 2429
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3557366728782654,
      "learning_rate": 7.96842105263158e-05,
      "loss": 0.075,
      "step": 2430
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3718057870864868,
      "learning_rate": 7.967368421052632e-05,
      "loss": 0.0807,
      "step": 2431
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.4530172646045685,
      "learning_rate": 7.966315789473685e-05,
      "loss": 0.1185,
      "step": 2432
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.31987231969833374,
      "learning_rate": 7.965263157894737e-05,
      "loss": 0.0691,
      "step": 2433
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.300676167011261,
      "learning_rate": 7.96421052631579e-05,
      "loss": 0.0914,
      "step": 2434
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.2866744101047516,
      "learning_rate": 7.963157894736842e-05,
      "loss": 0.0836,
      "step": 2435
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.29142439365386963,
      "learning_rate": 7.962105263157895e-05,
      "loss": 0.0937,
      "step": 2436
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.2885640263557434,
      "learning_rate": 7.961052631578949e-05,
      "loss": 0.0986,
      "step": 2437
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3296266496181488,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.1075,
      "step": 2438
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.31804585456848145,
      "learning_rate": 7.958947368421052e-05,
      "loss": 0.0741,
      "step": 2439
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3445400297641754,
      "learning_rate": 7.957894736842106e-05,
      "loss": 0.0921,
      "step": 2440
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.28381073474884033,
      "learning_rate": 7.956842105263158e-05,
      "loss": 0.1008,
      "step": 2441
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.2665165364742279,
      "learning_rate": 7.955789473684211e-05,
      "loss": 0.0692,
      "step": 2442
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3053379952907562,
      "learning_rate": 7.954736842105263e-05,
      "loss": 0.0905,
      "step": 2443
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3129204213619232,
      "learning_rate": 7.953684210526317e-05,
      "loss": 0.0644,
      "step": 2444
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.29768747091293335,
      "learning_rate": 7.95263157894737e-05,
      "loss": 0.0753,
      "step": 2445
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.32694244384765625,
      "learning_rate": 7.951578947368421e-05,
      "loss": 0.1064,
      "step": 2446
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.28724205493927,
      "learning_rate": 7.950526315789473e-05,
      "loss": 0.0842,
      "step": 2447
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.2707872986793518,
      "learning_rate": 7.949473684210527e-05,
      "loss": 0.0896,
      "step": 2448
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.25661593675613403,
      "learning_rate": 7.94842105263158e-05,
      "loss": 0.0544,
      "step": 2449
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.3217010498046875,
      "learning_rate": 7.947368421052632e-05,
      "loss": 0.093,
      "step": 2450
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.260851114988327,
      "learning_rate": 7.946315789473684e-05,
      "loss": 0.0516,
      "step": 2451
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.31979095935821533,
      "learning_rate": 7.945263157894737e-05,
      "loss": 0.0721,
      "step": 2452
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.28024303913116455,
      "learning_rate": 7.94421052631579e-05,
      "loss": 0.0608,
      "step": 2453
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.23010848462581635,
      "learning_rate": 7.943157894736842e-05,
      "loss": 0.0545,
      "step": 2454
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3007284998893738,
      "learning_rate": 7.942105263157896e-05,
      "loss": 0.0869,
      "step": 2455
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.27114275097846985,
      "learning_rate": 7.941052631578948e-05,
      "loss": 0.0961,
      "step": 2456
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2744313180446625,
      "learning_rate": 7.94e-05,
      "loss": 0.0889,
      "step": 2457
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.24067363142967224,
      "learning_rate": 7.938947368421053e-05,
      "loss": 0.0519,
      "step": 2458
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.34488797187805176,
      "learning_rate": 7.937894736842105e-05,
      "loss": 0.1031,
      "step": 2459
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.30021408200263977,
      "learning_rate": 7.936842105263158e-05,
      "loss": 0.1116,
      "step": 2460
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.26082441210746765,
      "learning_rate": 7.93578947368421e-05,
      "loss": 0.0759,
      "step": 2461
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.25960227847099304,
      "learning_rate": 7.934736842105264e-05,
      "loss": 0.051,
      "step": 2462
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.22657683491706848,
      "learning_rate": 7.933684210526317e-05,
      "loss": 0.0489,
      "step": 2463
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3479190766811371,
      "learning_rate": 7.932631578947369e-05,
      "loss": 0.07,
      "step": 2464
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.278825968503952,
      "learning_rate": 7.931578947368422e-05,
      "loss": 0.0784,
      "step": 2465
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.22515146434307098,
      "learning_rate": 7.930526315789474e-05,
      "loss": 0.0653,
      "step": 2466
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.23150980472564697,
      "learning_rate": 7.929473684210527e-05,
      "loss": 0.0579,
      "step": 2467
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2791505455970764,
      "learning_rate": 7.928421052631579e-05,
      "loss": 0.0694,
      "step": 2468
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.258930504322052,
      "learning_rate": 7.927368421052633e-05,
      "loss": 0.0703,
      "step": 2469
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.32530853152275085,
      "learning_rate": 7.926315789473685e-05,
      "loss": 0.0938,
      "step": 2470
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.23764628171920776,
      "learning_rate": 7.925263157894736e-05,
      "loss": 0.0602,
      "step": 2471
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2837246358394623,
      "learning_rate": 7.924210526315789e-05,
      "loss": 0.0829,
      "step": 2472
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.28633183240890503,
      "learning_rate": 7.923157894736843e-05,
      "loss": 0.0648,
      "step": 2473
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2756052613258362,
      "learning_rate": 7.922105263157895e-05,
      "loss": 0.1034,
      "step": 2474
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2774088680744171,
      "learning_rate": 7.921052631578948e-05,
      "loss": 0.0714,
      "step": 2475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.26207929849624634,
      "learning_rate": 7.920000000000001e-05,
      "loss": 0.0671,
      "step": 2476
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2934816777706146,
      "learning_rate": 7.918947368421054e-05,
      "loss": 0.0891,
      "step": 2477
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3205241858959198,
      "learning_rate": 7.917894736842105e-05,
      "loss": 0.0825,
      "step": 2478
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.32082322239875793,
      "learning_rate": 7.916842105263157e-05,
      "loss": 0.1218,
      "step": 2479
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.33598214387893677,
      "learning_rate": 7.915789473684211e-05,
      "loss": 0.0784,
      "step": 2480
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2727277874946594,
      "learning_rate": 7.914736842105264e-05,
      "loss": 0.0727,
      "step": 2481
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.34186816215515137,
      "learning_rate": 7.913684210526316e-05,
      "loss": 0.0906,
      "step": 2482
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.24588008224964142,
      "learning_rate": 7.912631578947369e-05,
      "loss": 0.0702,
      "step": 2483
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.29743027687072754,
      "learning_rate": 7.911578947368421e-05,
      "loss": 0.1086,
      "step": 2484
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.24959494173526764,
      "learning_rate": 7.910526315789474e-05,
      "loss": 0.0776,
      "step": 2485
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2927325367927551,
      "learning_rate": 7.909473684210526e-05,
      "loss": 0.0718,
      "step": 2486
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3653208911418915,
      "learning_rate": 7.90842105263158e-05,
      "loss": 0.1289,
      "step": 2487
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.22182440757751465,
      "learning_rate": 7.907368421052632e-05,
      "loss": 0.0555,
      "step": 2488
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.29019585251808167,
      "learning_rate": 7.906315789473685e-05,
      "loss": 0.0885,
      "step": 2489
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.32086196541786194,
      "learning_rate": 7.905263157894737e-05,
      "loss": 0.0905,
      "step": 2490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.30354177951812744,
      "learning_rate": 7.90421052631579e-05,
      "loss": 0.071,
      "step": 2491
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3541529178619385,
      "learning_rate": 7.903157894736842e-05,
      "loss": 0.0947,
      "step": 2492
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.27565518021583557,
      "learning_rate": 7.902105263157895e-05,
      "loss": 0.0854,
      "step": 2493
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2599552869796753,
      "learning_rate": 7.901052631578948e-05,
      "loss": 0.064,
      "step": 2494
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2859959900379181,
      "learning_rate": 7.900000000000001e-05,
      "loss": 0.0802,
      "step": 2495
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.23136910796165466,
      "learning_rate": 7.898947368421053e-05,
      "loss": 0.0658,
      "step": 2496
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2798744738101959,
      "learning_rate": 7.897894736842106e-05,
      "loss": 0.0746,
      "step": 2497
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.292277067899704,
      "learning_rate": 7.896842105263158e-05,
      "loss": 0.0774,
      "step": 2498
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3180108964443207,
      "learning_rate": 7.895789473684211e-05,
      "loss": 0.1434,
      "step": 2499
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.276327520608902,
      "learning_rate": 7.894736842105263e-05,
      "loss": 0.1029,
      "step": 2500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.11397220194339752,
      "eval_runtime": 870.865,
      "eval_samples_per_second": 2.859,
      "eval_steps_per_second": 0.045,
      "eval_wer": 9.25132440012465,
      "step": 2500
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.2965320944786072,
      "learning_rate": 7.893684210526317e-05,
      "loss": 0.1137,
      "step": 2501
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.27566489577293396,
      "learning_rate": 7.89263157894737e-05,
      "loss": 0.0618,
      "step": 2502
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2838781177997589,
      "learning_rate": 7.89157894736842e-05,
      "loss": 0.0896,
      "step": 2503
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3469182252883911,
      "learning_rate": 7.890526315789473e-05,
      "loss": 0.0981,
      "step": 2504
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.26651158928871155,
      "learning_rate": 7.889473684210527e-05,
      "loss": 0.0821,
      "step": 2505
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24037334322929382,
      "learning_rate": 7.88842105263158e-05,
      "loss": 0.0528,
      "step": 2506
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.279813677072525,
      "learning_rate": 7.887368421052632e-05,
      "loss": 0.0937,
      "step": 2507
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28307467699050903,
      "learning_rate": 7.886315789473684e-05,
      "loss": 0.082,
      "step": 2508
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2625976502895355,
      "learning_rate": 7.885263157894737e-05,
      "loss": 0.0789,
      "step": 2509
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3704262673854828,
      "learning_rate": 7.884210526315789e-05,
      "loss": 0.115,
      "step": 2510
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2265527844429016,
      "learning_rate": 7.883157894736842e-05,
      "loss": 0.0526,
      "step": 2511
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3026043772697449,
      "learning_rate": 7.882105263157896e-05,
      "loss": 0.0891,
      "step": 2512
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.26022398471832275,
      "learning_rate": 7.881052631578948e-05,
      "loss": 0.0636,
      "step": 2513
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30723056197166443,
      "learning_rate": 7.88e-05,
      "loss": 0.1051,
      "step": 2514
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.26811087131500244,
      "learning_rate": 7.878947368421053e-05,
      "loss": 0.0622,
      "step": 2515
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.27281153202056885,
      "learning_rate": 7.877894736842105e-05,
      "loss": 0.0927,
      "step": 2516
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2560628354549408,
      "learning_rate": 7.876842105263158e-05,
      "loss": 0.0488,
      "step": 2517
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3029426038265228,
      "learning_rate": 7.87578947368421e-05,
      "loss": 0.113,
      "step": 2518
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3333367109298706,
      "learning_rate": 7.874736842105264e-05,
      "loss": 0.0956,
      "step": 2519
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2777763307094574,
      "learning_rate": 7.873684210526317e-05,
      "loss": 0.075,
      "step": 2520
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.27309122681617737,
      "learning_rate": 7.872631578947369e-05,
      "loss": 0.0708,
      "step": 2521
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.29364269971847534,
      "learning_rate": 7.871578947368422e-05,
      "loss": 0.0991,
      "step": 2522
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25562500953674316,
      "learning_rate": 7.870526315789474e-05,
      "loss": 0.0581,
      "step": 2523
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.26241591572761536,
      "learning_rate": 7.869473684210526e-05,
      "loss": 0.0462,
      "step": 2524
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2550757825374603,
      "learning_rate": 7.868421052631579e-05,
      "loss": 0.0497,
      "step": 2525
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24175210297107697,
      "learning_rate": 7.867368421052633e-05,
      "loss": 0.0535,
      "step": 2526
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2976747453212738,
      "learning_rate": 7.866315789473685e-05,
      "loss": 0.0752,
      "step": 2527
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28695034980773926,
      "learning_rate": 7.865263157894736e-05,
      "loss": 0.0771,
      "step": 2528
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28821861743927,
      "learning_rate": 7.86421052631579e-05,
      "loss": 0.0837,
      "step": 2529
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25979986786842346,
      "learning_rate": 7.863157894736843e-05,
      "loss": 0.0674,
      "step": 2530
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28710177540779114,
      "learning_rate": 7.862105263157895e-05,
      "loss": 0.084,
      "step": 2531
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3325011432170868,
      "learning_rate": 7.861052631578947e-05,
      "loss": 0.0554,
      "step": 2532
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28678828477859497,
      "learning_rate": 7.860000000000001e-05,
      "loss": 0.1009,
      "step": 2533
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.4075316786766052,
      "learning_rate": 7.858947368421054e-05,
      "loss": 0.084,
      "step": 2534
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3258734345436096,
      "learning_rate": 7.857894736842105e-05,
      "loss": 0.0861,
      "step": 2535
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2729989290237427,
      "learning_rate": 7.856842105263157e-05,
      "loss": 0.0683,
      "step": 2536
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3146798312664032,
      "learning_rate": 7.855789473684211e-05,
      "loss": 0.1029,
      "step": 2537
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25434449315071106,
      "learning_rate": 7.854736842105264e-05,
      "loss": 0.0868,
      "step": 2538
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2847457230091095,
      "learning_rate": 7.853684210526316e-05,
      "loss": 0.0808,
      "step": 2539
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2731055021286011,
      "learning_rate": 7.852631578947369e-05,
      "loss": 0.0823,
      "step": 2540
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2828899919986725,
      "learning_rate": 7.851578947368421e-05,
      "loss": 0.077,
      "step": 2541
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3044760823249817,
      "learning_rate": 7.850526315789473e-05,
      "loss": 0.0748,
      "step": 2542
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2697864770889282,
      "learning_rate": 7.849473684210526e-05,
      "loss": 0.0662,
      "step": 2543
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24008408188819885,
      "learning_rate": 7.84842105263158e-05,
      "loss": 0.0547,
      "step": 2544
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2649610936641693,
      "learning_rate": 7.847368421052632e-05,
      "loss": 0.0638,
      "step": 2545
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30807551741600037,
      "learning_rate": 7.846315789473685e-05,
      "loss": 0.081,
      "step": 2546
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3064039349555969,
      "learning_rate": 7.845263157894737e-05,
      "loss": 0.0895,
      "step": 2547
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25218939781188965,
      "learning_rate": 7.84421052631579e-05,
      "loss": 0.0711,
      "step": 2548
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2587197721004486,
      "learning_rate": 7.843157894736842e-05,
      "loss": 0.0559,
      "step": 2549
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.31399449706077576,
      "learning_rate": 7.842105263157895e-05,
      "loss": 0.1073,
      "step": 2550
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25250643491744995,
      "learning_rate": 7.841052631578948e-05,
      "loss": 0.0826,
      "step": 2551
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2550223469734192,
      "learning_rate": 7.840000000000001e-05,
      "loss": 0.0607,
      "step": 2552
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2922305762767792,
      "learning_rate": 7.838947368421053e-05,
      "loss": 0.0806,
      "step": 2553
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2683788537979126,
      "learning_rate": 7.837894736842106e-05,
      "loss": 0.0812,
      "step": 2554
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2620343267917633,
      "learning_rate": 7.836842105263158e-05,
      "loss": 0.0698,
      "step": 2555
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2607699930667877,
      "learning_rate": 7.835789473684211e-05,
      "loss": 0.0584,
      "step": 2556
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24145708978176117,
      "learning_rate": 7.834736842105263e-05,
      "loss": 0.0545,
      "step": 2557
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.270896315574646,
      "learning_rate": 7.833684210526317e-05,
      "loss": 0.0826,
      "step": 2558
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.22365225851535797,
      "learning_rate": 7.83263157894737e-05,
      "loss": 0.0591,
      "step": 2559
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2148585468530655,
      "learning_rate": 7.83157894736842e-05,
      "loss": 0.052,
      "step": 2560
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.26119253039360046,
      "learning_rate": 7.830526315789474e-05,
      "loss": 0.0479,
      "step": 2561
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24670027196407318,
      "learning_rate": 7.829473684210527e-05,
      "loss": 0.068,
      "step": 2562
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24473422765731812,
      "learning_rate": 7.828421052631579e-05,
      "loss": 0.0637,
      "step": 2563
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.32509058713912964,
      "learning_rate": 7.827368421052632e-05,
      "loss": 0.1026,
      "step": 2564
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3024413585662842,
      "learning_rate": 7.826315789473686e-05,
      "loss": 0.1031,
      "step": 2565
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.27618667483329773,
      "learning_rate": 7.825263157894738e-05,
      "loss": 0.0532,
      "step": 2566
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2728709578514099,
      "learning_rate": 7.824210526315789e-05,
      "loss": 0.077,
      "step": 2567
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2909224331378937,
      "learning_rate": 7.823157894736842e-05,
      "loss": 0.0935,
      "step": 2568
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25171539187431335,
      "learning_rate": 7.822105263157895e-05,
      "loss": 0.0713,
      "step": 2569
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.29583635926246643,
      "learning_rate": 7.821052631578948e-05,
      "loss": 0.0942,
      "step": 2570
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3125065565109253,
      "learning_rate": 7.82e-05,
      "loss": 0.0869,
      "step": 2571
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.22202377021312714,
      "learning_rate": 7.818947368421053e-05,
      "loss": 0.0533,
      "step": 2572
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28028586506843567,
      "learning_rate": 7.817894736842105e-05,
      "loss": 0.0736,
      "step": 2573
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25834137201309204,
      "learning_rate": 7.816842105263158e-05,
      "loss": 0.0433,
      "step": 2574
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.33468490839004517,
      "learning_rate": 7.81578947368421e-05,
      "loss": 0.0969,
      "step": 2575
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2569220960140228,
      "learning_rate": 7.814736842105264e-05,
      "loss": 0.0876,
      "step": 2576
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28755176067352295,
      "learning_rate": 7.813684210526316e-05,
      "loss": 0.0983,
      "step": 2577
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2741568088531494,
      "learning_rate": 7.812631578947369e-05,
      "loss": 0.0678,
      "step": 2578
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2726583480834961,
      "learning_rate": 7.811578947368421e-05,
      "loss": 0.0493,
      "step": 2579
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30494266748428345,
      "learning_rate": 7.810526315789474e-05,
      "loss": 0.0996,
      "step": 2580
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28168994188308716,
      "learning_rate": 7.809473684210526e-05,
      "loss": 0.063,
      "step": 2581
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30821844935417175,
      "learning_rate": 7.808421052631579e-05,
      "loss": 0.0886,
      "step": 2582
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2776738703250885,
      "learning_rate": 7.807368421052633e-05,
      "loss": 0.0939,
      "step": 2583
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2853354513645172,
      "learning_rate": 7.806315789473685e-05,
      "loss": 0.0672,
      "step": 2584
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.35970884561538696,
      "learning_rate": 7.805263157894738e-05,
      "loss": 0.0779,
      "step": 2585
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2687206268310547,
      "learning_rate": 7.80421052631579e-05,
      "loss": 0.0815,
      "step": 2586
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3810834586620331,
      "learning_rate": 7.803157894736842e-05,
      "loss": 0.1047,
      "step": 2587
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.23481102287769318,
      "learning_rate": 7.802105263157895e-05,
      "loss": 0.087,
      "step": 2588
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24437278509140015,
      "learning_rate": 7.801052631578947e-05,
      "loss": 0.0586,
      "step": 2589
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2522639036178589,
      "learning_rate": 7.800000000000001e-05,
      "loss": 0.0695,
      "step": 2590
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30042099952697754,
      "learning_rate": 7.798947368421054e-05,
      "loss": 0.0985,
      "step": 2591
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30390116572380066,
      "learning_rate": 7.797894736842105e-05,
      "loss": 0.0999,
      "step": 2592
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.30274680256843567,
      "learning_rate": 7.796842105263159e-05,
      "loss": 0.0811,
      "step": 2593
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2867841124534607,
      "learning_rate": 7.795789473684211e-05,
      "loss": 0.0826,
      "step": 2594
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.27868932485580444,
      "learning_rate": 7.794736842105264e-05,
      "loss": 0.084,
      "step": 2595
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.24894516170024872,
      "learning_rate": 7.793684210526316e-05,
      "loss": 0.0843,
      "step": 2596
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2349621057510376,
      "learning_rate": 7.79263157894737e-05,
      "loss": 0.0585,
      "step": 2597
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.28968143463134766,
      "learning_rate": 7.791578947368422e-05,
      "loss": 0.0732,
      "step": 2598
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2761697769165039,
      "learning_rate": 7.790526315789473e-05,
      "loss": 0.0817,
      "step": 2599
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25645679235458374,
      "learning_rate": 7.789473684210526e-05,
      "loss": 0.0568,
      "step": 2600
    },
    {
      "epoch": 9.01,
      "eval_loss": 0.11184658110141754,
      "eval_runtime": 840.4318,
      "eval_samples_per_second": 2.963,
      "eval_steps_per_second": 0.046,
      "eval_wer": 7.926924275475226,
      "step": 2600
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.3096525967121124,
      "learning_rate": 7.78842105263158e-05,
      "loss": 0.1123,
      "step": 2601
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.29896727204322815,
      "learning_rate": 7.787368421052632e-05,
      "loss": 0.0737,
      "step": 2602
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.32455188035964966,
      "learning_rate": 7.786315789473685e-05,
      "loss": 0.1183,
      "step": 2603
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27332210540771484,
      "learning_rate": 7.785263157894737e-05,
      "loss": 0.0753,
      "step": 2604
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27408114075660706,
      "learning_rate": 7.78421052631579e-05,
      "loss": 0.0654,
      "step": 2605
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2528039216995239,
      "learning_rate": 7.783157894736842e-05,
      "loss": 0.0763,
      "step": 2606
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.30885112285614014,
      "learning_rate": 7.782105263157894e-05,
      "loss": 0.0618,
      "step": 2607
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25807586312294006,
      "learning_rate": 7.781052631578948e-05,
      "loss": 0.0652,
      "step": 2608
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2975133955478668,
      "learning_rate": 7.780000000000001e-05,
      "loss": 0.0793,
      "step": 2609
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.29764339327812195,
      "learning_rate": 7.778947368421053e-05,
      "loss": 0.1012,
      "step": 2610
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2656683325767517,
      "learning_rate": 7.777894736842106e-05,
      "loss": 0.0859,
      "step": 2611
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2854539752006531,
      "learning_rate": 7.776842105263158e-05,
      "loss": 0.0746,
      "step": 2612
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27545109391212463,
      "learning_rate": 7.77578947368421e-05,
      "loss": 0.0781,
      "step": 2613
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2842475473880768,
      "learning_rate": 7.774736842105263e-05,
      "loss": 0.0808,
      "step": 2614
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.29074299335479736,
      "learning_rate": 7.773684210526317e-05,
      "loss": 0.0524,
      "step": 2615
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3545771539211273,
      "learning_rate": 7.77263157894737e-05,
      "loss": 0.0939,
      "step": 2616
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27900007367134094,
      "learning_rate": 7.771578947368422e-05,
      "loss": 0.0871,
      "step": 2617
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24852418899536133,
      "learning_rate": 7.770526315789474e-05,
      "loss": 0.0717,
      "step": 2618
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27938714623451233,
      "learning_rate": 7.769473684210527e-05,
      "loss": 0.0793,
      "step": 2619
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.35123977065086365,
      "learning_rate": 7.768421052631579e-05,
      "loss": 0.1089,
      "step": 2620
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2413562834262848,
      "learning_rate": 7.767368421052632e-05,
      "loss": 0.0561,
      "step": 2621
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2790142893791199,
      "learning_rate": 7.766315789473685e-05,
      "loss": 0.0776,
      "step": 2622
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.32639211416244507,
      "learning_rate": 7.765263157894738e-05,
      "loss": 0.121,
      "step": 2623
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.30916088819503784,
      "learning_rate": 7.764210526315789e-05,
      "loss": 0.1205,
      "step": 2624
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.29895830154418945,
      "learning_rate": 7.763157894736843e-05,
      "loss": 0.0929,
      "step": 2625
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27810418605804443,
      "learning_rate": 7.762105263157895e-05,
      "loss": 0.0681,
      "step": 2626
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.270612508058548,
      "learning_rate": 7.761052631578948e-05,
      "loss": 0.0801,
      "step": 2627
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24137525260448456,
      "learning_rate": 7.76e-05,
      "loss": 0.0522,
      "step": 2628
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.31410983204841614,
      "learning_rate": 7.758947368421054e-05,
      "loss": 0.0712,
      "step": 2629
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.33803486824035645,
      "learning_rate": 7.757894736842105e-05,
      "loss": 0.0867,
      "step": 2630
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.28604790568351746,
      "learning_rate": 7.756842105263158e-05,
      "loss": 0.0536,
      "step": 2631
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.23821669816970825,
      "learning_rate": 7.75578947368421e-05,
      "loss": 0.0428,
      "step": 2632
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2698228657245636,
      "learning_rate": 7.754736842105264e-05,
      "loss": 0.0624,
      "step": 2633
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2886081039905548,
      "learning_rate": 7.753684210526316e-05,
      "loss": 0.0745,
      "step": 2634
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.30466407537460327,
      "learning_rate": 7.752631578947369e-05,
      "loss": 0.0605,
      "step": 2635
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2401813268661499,
      "learning_rate": 7.751578947368421e-05,
      "loss": 0.0576,
      "step": 2636
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.21815788745880127,
      "learning_rate": 7.750526315789474e-05,
      "loss": 0.0583,
      "step": 2637
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2894987463951111,
      "learning_rate": 7.749473684210526e-05,
      "loss": 0.0716,
      "step": 2638
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2666180431842804,
      "learning_rate": 7.748421052631579e-05,
      "loss": 0.0834,
      "step": 2639
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25668463110923767,
      "learning_rate": 7.747368421052633e-05,
      "loss": 0.0526,
      "step": 2640
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.29699522256851196,
      "learning_rate": 7.746315789473685e-05,
      "loss": 0.0777,
      "step": 2641
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25810539722442627,
      "learning_rate": 7.745263157894737e-05,
      "loss": 0.06,
      "step": 2642
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2910359799861908,
      "learning_rate": 7.74421052631579e-05,
      "loss": 0.0878,
      "step": 2643
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24790996313095093,
      "learning_rate": 7.743157894736842e-05,
      "loss": 0.0532,
      "step": 2644
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3204565942287445,
      "learning_rate": 7.742105263157895e-05,
      "loss": 0.0821,
      "step": 2645
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3115462362766266,
      "learning_rate": 7.741052631578947e-05,
      "loss": 0.069,
      "step": 2646
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27857062220573425,
      "learning_rate": 7.740000000000001e-05,
      "loss": 0.057,
      "step": 2647
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.33455318212509155,
      "learning_rate": 7.738947368421054e-05,
      "loss": 0.0963,
      "step": 2648
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24443218111991882,
      "learning_rate": 7.737894736842105e-05,
      "loss": 0.0571,
      "step": 2649
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.22713150084018707,
      "learning_rate": 7.736842105263159e-05,
      "loss": 0.0475,
      "step": 2650
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25904813408851624,
      "learning_rate": 7.735789473684211e-05,
      "loss": 0.0616,
      "step": 2651
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3149191439151764,
      "learning_rate": 7.734736842105263e-05,
      "loss": 0.0665,
      "step": 2652
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.30513545870780945,
      "learning_rate": 7.733684210526316e-05,
      "loss": 0.0613,
      "step": 2653
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.22651027143001556,
      "learning_rate": 7.73263157894737e-05,
      "loss": 0.0548,
      "step": 2654
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24482202529907227,
      "learning_rate": 7.731578947368422e-05,
      "loss": 0.0639,
      "step": 2655
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2906489968299866,
      "learning_rate": 7.730526315789473e-05,
      "loss": 0.072,
      "step": 2656
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2869493067264557,
      "learning_rate": 7.729473684210527e-05,
      "loss": 0.0413,
      "step": 2657
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27457040548324585,
      "learning_rate": 7.72842105263158e-05,
      "loss": 0.0766,
      "step": 2658
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27385425567626953,
      "learning_rate": 7.727368421052632e-05,
      "loss": 0.0709,
      "step": 2659
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2936879098415375,
      "learning_rate": 7.726315789473684e-05,
      "loss": 0.0825,
      "step": 2660
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2516222298145294,
      "learning_rate": 7.725263157894738e-05,
      "loss": 0.0907,
      "step": 2661
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2206585705280304,
      "learning_rate": 7.72421052631579e-05,
      "loss": 0.0386,
      "step": 2662
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3006018102169037,
      "learning_rate": 7.723157894736842e-05,
      "loss": 0.1085,
      "step": 2663
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25929373502731323,
      "learning_rate": 7.722105263157894e-05,
      "loss": 0.0619,
      "step": 2664
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3555554151535034,
      "learning_rate": 7.721052631578948e-05,
      "loss": 0.0736,
      "step": 2665
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.26131588220596313,
      "learning_rate": 7.72e-05,
      "loss": 0.0554,
      "step": 2666
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.26215800642967224,
      "learning_rate": 7.718947368421053e-05,
      "loss": 0.0625,
      "step": 2667
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27271631360054016,
      "learning_rate": 7.717894736842106e-05,
      "loss": 0.0612,
      "step": 2668
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24752205610275269,
      "learning_rate": 7.716842105263158e-05,
      "loss": 0.0578,
      "step": 2669
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3686373829841614,
      "learning_rate": 7.71578947368421e-05,
      "loss": 0.1315,
      "step": 2670
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3214462995529175,
      "learning_rate": 7.714736842105263e-05,
      "loss": 0.0604,
      "step": 2671
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2577097713947296,
      "learning_rate": 7.713684210526317e-05,
      "loss": 0.0699,
      "step": 2672
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.36995255947113037,
      "learning_rate": 7.712631578947369e-05,
      "loss": 0.0859,
      "step": 2673
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24473388493061066,
      "learning_rate": 7.711578947368422e-05,
      "loss": 0.0499,
      "step": 2674
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2689260244369507,
      "learning_rate": 7.710526315789474e-05,
      "loss": 0.0697,
      "step": 2675
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.30574801564216614,
      "learning_rate": 7.709473684210527e-05,
      "loss": 0.0757,
      "step": 2676
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.28685200214385986,
      "learning_rate": 7.708421052631579e-05,
      "loss": 0.0743,
      "step": 2677
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2737120985984802,
      "learning_rate": 7.707368421052632e-05,
      "loss": 0.0807,
      "step": 2678
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3168925344944,
      "learning_rate": 7.706315789473685e-05,
      "loss": 0.0964,
      "step": 2679
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.32691213488578796,
      "learning_rate": 7.705263157894738e-05,
      "loss": 0.0566,
      "step": 2680
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.25501561164855957,
      "learning_rate": 7.704210526315789e-05,
      "loss": 0.0548,
      "step": 2681
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.352559357881546,
      "learning_rate": 7.703157894736843e-05,
      "loss": 0.1395,
      "step": 2682
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2287704348564148,
      "learning_rate": 7.702105263157895e-05,
      "loss": 0.0593,
      "step": 2683
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.27368807792663574,
      "learning_rate": 7.701052631578948e-05,
      "loss": 0.0626,
      "step": 2684
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2612183094024658,
      "learning_rate": 7.7e-05,
      "loss": 0.0517,
      "step": 2685
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2544402778148651,
      "learning_rate": 7.698947368421054e-05,
      "loss": 0.0592,
      "step": 2686
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.23936237394809723,
      "learning_rate": 7.697894736842106e-05,
      "loss": 0.0551,
      "step": 2687
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24929441511631012,
      "learning_rate": 7.696842105263158e-05,
      "loss": 0.0604,
      "step": 2688
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2618010342121124,
      "learning_rate": 7.69578947368421e-05,
      "loss": 0.0532,
      "step": 2689
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2707843482494354,
      "learning_rate": 7.694736842105264e-05,
      "loss": 0.0581,
      "step": 2690
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2960282862186432,
      "learning_rate": 7.693684210526316e-05,
      "loss": 0.0552,
      "step": 2691
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2772783637046814,
      "learning_rate": 7.692631578947369e-05,
      "loss": 0.0604,
      "step": 2692
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2668340504169464,
      "learning_rate": 7.691578947368423e-05,
      "loss": 0.0717,
      "step": 2693
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3076489269733429,
      "learning_rate": 7.690526315789474e-05,
      "loss": 0.0943,
      "step": 2694
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.20116373896598816,
      "learning_rate": 7.689473684210526e-05,
      "loss": 0.0452,
      "step": 2695
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.26451918482780457,
      "learning_rate": 7.688421052631579e-05,
      "loss": 0.0534,
      "step": 2696
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.29372522234916687,
      "learning_rate": 7.687368421052632e-05,
      "loss": 0.0712,
      "step": 2697
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.3150654733181,
      "learning_rate": 7.686315789473685e-05,
      "loss": 0.1095,
      "step": 2698
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.24378250539302826,
      "learning_rate": 7.685263157894737e-05,
      "loss": 0.0541,
      "step": 2699
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.28153330087661743,
      "learning_rate": 7.68421052631579e-05,
      "loss": 0.0948,
      "step": 2700
    },
    {
      "epoch": 9.02,
      "eval_loss": 0.10944422334432602,
      "eval_runtime": 844.9176,
      "eval_samples_per_second": 2.947,
      "eval_steps_per_second": 0.046,
      "eval_wer": 8.756622000623247,
      "step": 2700
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2924758791923523,
      "learning_rate": 7.683157894736842e-05,
      "loss": 0.07,
      "step": 2701
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.2825627326965332,
      "learning_rate": 7.682105263157895e-05,
      "loss": 0.0659,
      "step": 2702
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.29341939091682434,
      "learning_rate": 7.681052631578947e-05,
      "loss": 0.1223,
      "step": 2703
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.23008054494857788,
      "learning_rate": 7.680000000000001e-05,
      "loss": 0.045,
      "step": 2704
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.28992679715156555,
      "learning_rate": 7.678947368421053e-05,
      "loss": 0.0881,
      "step": 2705
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.24026846885681152,
      "learning_rate": 7.677894736842106e-05,
      "loss": 0.0605,
      "step": 2706
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.23920807242393494,
      "learning_rate": 7.676842105263158e-05,
      "loss": 0.0598,
      "step": 2707
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.2858671247959137,
      "learning_rate": 7.675789473684211e-05,
      "loss": 0.0747,
      "step": 2708
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.26603880524635315,
      "learning_rate": 7.674736842105263e-05,
      "loss": 0.0674,
      "step": 2709
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.27414679527282715,
      "learning_rate": 7.673684210526316e-05,
      "loss": 0.0792,
      "step": 2710
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.3245942294597626,
      "learning_rate": 7.67263157894737e-05,
      "loss": 0.0898,
      "step": 2711
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.36846843361854553,
      "learning_rate": 7.671578947368422e-05,
      "loss": 0.0861,
      "step": 2712
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.24782927334308624,
      "learning_rate": 7.670526315789473e-05,
      "loss": 0.072,
      "step": 2713
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.23346629738807678,
      "learning_rate": 7.669473684210527e-05,
      "loss": 0.0645,
      "step": 2714
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.32045820355415344,
      "learning_rate": 7.66842105263158e-05,
      "loss": 0.0942,
      "step": 2715
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.2576996982097626,
      "learning_rate": 7.667368421052632e-05,
      "loss": 0.0534,
      "step": 2716
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.23998497426509857,
      "learning_rate": 7.666315789473684e-05,
      "loss": 0.052,
      "step": 2717
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.2628532350063324,
      "learning_rate": 7.665263157894738e-05,
      "loss": 0.0631,
      "step": 2718
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.3663870692253113,
      "learning_rate": 7.66421052631579e-05,
      "loss": 0.0854,
      "step": 2719
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.25466230511665344,
      "learning_rate": 7.663157894736842e-05,
      "loss": 0.0599,
      "step": 2720
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.26122772693634033,
      "learning_rate": 7.662105263157894e-05,
      "loss": 0.0716,
      "step": 2721
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.32268720865249634,
      "learning_rate": 7.661052631578948e-05,
      "loss": 0.0562,
      "step": 2722
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.32405930757522583,
      "learning_rate": 7.66e-05,
      "loss": 0.0693,
      "step": 2723
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.24875321984291077,
      "learning_rate": 7.658947368421053e-05,
      "loss": 0.0735,
      "step": 2724
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.2542058229446411,
      "learning_rate": 7.657894736842105e-05,
      "loss": 0.0501,
      "step": 2725
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.26881471276283264,
      "learning_rate": 7.656842105263158e-05,
      "loss": 0.0892,
      "step": 2726
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.31297171115875244,
      "learning_rate": 7.65578947368421e-05,
      "loss": 0.0656,
      "step": 2727
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.23781254887580872,
      "learning_rate": 7.654736842105263e-05,
      "loss": 0.0617,
      "step": 2728
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.28670403361320496,
      "learning_rate": 7.653684210526317e-05,
      "loss": 0.0842,
      "step": 2729
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3016892671585083,
      "learning_rate": 7.652631578947369e-05,
      "loss": 0.0667,
      "step": 2730
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.29739680886268616,
      "learning_rate": 7.651578947368422e-05,
      "loss": 0.069,
      "step": 2731
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2618548572063446,
      "learning_rate": 7.650526315789474e-05,
      "loss": 0.0696,
      "step": 2732
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2585567235946655,
      "learning_rate": 7.649473684210527e-05,
      "loss": 0.0485,
      "step": 2733
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.25652989745140076,
      "learning_rate": 7.648421052631579e-05,
      "loss": 0.0569,
      "step": 2734
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.31538131833076477,
      "learning_rate": 7.647368421052631e-05,
      "loss": 0.0856,
      "step": 2735
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2941443622112274,
      "learning_rate": 7.646315789473685e-05,
      "loss": 0.0577,
      "step": 2736
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3359845280647278,
      "learning_rate": 7.645263157894738e-05,
      "loss": 0.1072,
      "step": 2737
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.27877381443977356,
      "learning_rate": 7.64421052631579e-05,
      "loss": 0.063,
      "step": 2738
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.29083821177482605,
      "learning_rate": 7.643157894736843e-05,
      "loss": 0.0938,
      "step": 2739
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.33252203464508057,
      "learning_rate": 7.642105263157895e-05,
      "loss": 0.0936,
      "step": 2740
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2805737257003784,
      "learning_rate": 7.641052631578948e-05,
      "loss": 0.0605,
      "step": 2741
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.27389413118362427,
      "learning_rate": 7.64e-05,
      "loss": 0.0473,
      "step": 2742
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.28317371010780334,
      "learning_rate": 7.638947368421054e-05,
      "loss": 0.0599,
      "step": 2743
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.32264217734336853,
      "learning_rate": 7.637894736842106e-05,
      "loss": 0.0756,
      "step": 2744
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.25297167897224426,
      "learning_rate": 7.636842105263157e-05,
      "loss": 0.06,
      "step": 2745
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.29561150074005127,
      "learning_rate": 7.635789473684211e-05,
      "loss": 0.0448,
      "step": 2746
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2770257592201233,
      "learning_rate": 7.634736842105264e-05,
      "loss": 0.0795,
      "step": 2747
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2768986225128174,
      "learning_rate": 7.633684210526316e-05,
      "loss": 0.0593,
      "step": 2748
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.26610079407691956,
      "learning_rate": 7.632631578947369e-05,
      "loss": 0.0819,
      "step": 2749
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.23412059247493744,
      "learning_rate": 7.631578947368422e-05,
      "loss": 0.0481,
      "step": 2750
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.32280898094177246,
      "learning_rate": 7.630526315789474e-05,
      "loss": 0.0735,
      "step": 2751
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2867049276828766,
      "learning_rate": 7.629473684210526e-05,
      "loss": 0.0857,
      "step": 2752
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.25287437438964844,
      "learning_rate": 7.628421052631578e-05,
      "loss": 0.0827,
      "step": 2753
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3420785963535309,
      "learning_rate": 7.627368421052632e-05,
      "loss": 0.1163,
      "step": 2754
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.23169538378715515,
      "learning_rate": 7.626315789473685e-05,
      "loss": 0.0574,
      "step": 2755
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2293948084115982,
      "learning_rate": 7.625263157894737e-05,
      "loss": 0.0619,
      "step": 2756
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2515731155872345,
      "learning_rate": 7.62421052631579e-05,
      "loss": 0.0462,
      "step": 2757
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.31987857818603516,
      "learning_rate": 7.623157894736842e-05,
      "loss": 0.0511,
      "step": 2758
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.28089720010757446,
      "learning_rate": 7.622105263157895e-05,
      "loss": 0.0527,
      "step": 2759
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.22678817808628082,
      "learning_rate": 7.621052631578947e-05,
      "loss": 0.0598,
      "step": 2760
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2884121835231781,
      "learning_rate": 7.620000000000001e-05,
      "loss": 0.0601,
      "step": 2761
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.20865313708782196,
      "learning_rate": 7.618947368421053e-05,
      "loss": 0.0353,
      "step": 2762
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2728794813156128,
      "learning_rate": 7.617894736842106e-05,
      "loss": 0.0831,
      "step": 2763
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.29595500230789185,
      "learning_rate": 7.616842105263158e-05,
      "loss": 0.0793,
      "step": 2764
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.1753360629081726,
      "learning_rate": 7.615789473684211e-05,
      "loss": 0.0391,
      "step": 2765
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.23861335217952728,
      "learning_rate": 7.614736842105263e-05,
      "loss": 0.0544,
      "step": 2766
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2626994252204895,
      "learning_rate": 7.613684210526316e-05,
      "loss": 0.0555,
      "step": 2767
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3075075149536133,
      "learning_rate": 7.61263157894737e-05,
      "loss": 0.0832,
      "step": 2768
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.23104676604270935,
      "learning_rate": 7.611578947368422e-05,
      "loss": 0.0645,
      "step": 2769
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3337601125240326,
      "learning_rate": 7.610526315789473e-05,
      "loss": 0.1125,
      "step": 2770
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2467474639415741,
      "learning_rate": 7.609473684210527e-05,
      "loss": 0.0485,
      "step": 2771
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.348856657743454,
      "learning_rate": 7.60842105263158e-05,
      "loss": 0.1333,
      "step": 2772
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.28924643993377686,
      "learning_rate": 7.607368421052632e-05,
      "loss": 0.0736,
      "step": 2773
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.32288798689842224,
      "learning_rate": 7.606315789473684e-05,
      "loss": 0.0857,
      "step": 2774
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2487242966890335,
      "learning_rate": 7.605263157894738e-05,
      "loss": 0.0607,
      "step": 2775
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2512705326080322,
      "learning_rate": 7.60421052631579e-05,
      "loss": 0.0553,
      "step": 2776
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2791190445423126,
      "learning_rate": 7.603157894736842e-05,
      "loss": 0.074,
      "step": 2777
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24626590311527252,
      "learning_rate": 7.602105263157895e-05,
      "loss": 0.0526,
      "step": 2778
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.31652209162712097,
      "learning_rate": 7.601052631578948e-05,
      "loss": 0.0705,
      "step": 2779
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2789452373981476,
      "learning_rate": 7.6e-05,
      "loss": 0.0391,
      "step": 2780
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25568118691444397,
      "learning_rate": 7.598947368421053e-05,
      "loss": 0.0661,
      "step": 2781
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2344055324792862,
      "learning_rate": 7.597894736842107e-05,
      "loss": 0.0537,
      "step": 2782
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.31116926670074463,
      "learning_rate": 7.596842105263158e-05,
      "loss": 0.0836,
      "step": 2783
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27208635210990906,
      "learning_rate": 7.59578947368421e-05,
      "loss": 0.0669,
      "step": 2784
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25665804743766785,
      "learning_rate": 7.594736842105263e-05,
      "loss": 0.061,
      "step": 2785
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2620125710964203,
      "learning_rate": 7.593684210526317e-05,
      "loss": 0.0685,
      "step": 2786
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3668370246887207,
      "learning_rate": 7.592631578947369e-05,
      "loss": 0.1121,
      "step": 2787
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.29192063212394714,
      "learning_rate": 7.591578947368421e-05,
      "loss": 0.0717,
      "step": 2788
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.330058753490448,
      "learning_rate": 7.590526315789474e-05,
      "loss": 0.0996,
      "step": 2789
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.28805163502693176,
      "learning_rate": 7.589473684210526e-05,
      "loss": 0.0627,
      "step": 2790
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2911226749420166,
      "learning_rate": 7.588421052631579e-05,
      "loss": 0.0721,
      "step": 2791
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30245664715766907,
      "learning_rate": 7.587368421052631e-05,
      "loss": 0.0819,
      "step": 2792
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27927732467651367,
      "learning_rate": 7.586315789473685e-05,
      "loss": 0.0747,
      "step": 2793
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2555190920829773,
      "learning_rate": 7.585263157894738e-05,
      "loss": 0.0696,
      "step": 2794
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.35554662346839905,
      "learning_rate": 7.58421052631579e-05,
      "loss": 0.144,
      "step": 2795
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2577095925807953,
      "learning_rate": 7.583157894736843e-05,
      "loss": 0.0783,
      "step": 2796
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2445845603942871,
      "learning_rate": 7.582105263157895e-05,
      "loss": 0.0573,
      "step": 2797
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.26482510566711426,
      "learning_rate": 7.581052631578947e-05,
      "loss": 0.0646,
      "step": 2798
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2653355896472931,
      "learning_rate": 7.58e-05,
      "loss": 0.0445,
      "step": 2799
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.28545254468917847,
      "learning_rate": 7.578947368421054e-05,
      "loss": 0.0612,
      "step": 2800
    },
    {
      "epoch": 10.01,
      "eval_loss": 0.11036276072263718,
      "eval_runtime": 850.061,
      "eval_samples_per_second": 2.929,
      "eval_steps_per_second": 0.046,
      "eval_wer": 8.92801495793082,
      "step": 2800
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2843952178955078,
      "learning_rate": 7.577894736842106e-05,
      "loss": 0.0872,
      "step": 2801
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27855268120765686,
      "learning_rate": 7.576842105263157e-05,
      "loss": 0.0888,
      "step": 2802
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2000086009502411,
      "learning_rate": 7.575789473684211e-05,
      "loss": 0.0461,
      "step": 2803
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2785719633102417,
      "learning_rate": 7.574736842105264e-05,
      "loss": 0.0476,
      "step": 2804
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2371135801076889,
      "learning_rate": 7.573684210526316e-05,
      "loss": 0.0434,
      "step": 2805
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25501778721809387,
      "learning_rate": 7.572631578947369e-05,
      "loss": 0.0656,
      "step": 2806
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.21071945130825043,
      "learning_rate": 7.571578947368422e-05,
      "loss": 0.0483,
      "step": 2807
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24355122447013855,
      "learning_rate": 7.570526315789475e-05,
      "loss": 0.073,
      "step": 2808
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24938175082206726,
      "learning_rate": 7.569473684210526e-05,
      "loss": 0.0462,
      "step": 2809
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3212195038795471,
      "learning_rate": 7.56842105263158e-05,
      "loss": 0.1041,
      "step": 2810
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30315059423446655,
      "learning_rate": 7.567368421052632e-05,
      "loss": 0.069,
      "step": 2811
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2699490189552307,
      "learning_rate": 7.566315789473685e-05,
      "loss": 0.0631,
      "step": 2812
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2858898341655731,
      "learning_rate": 7.565263157894737e-05,
      "loss": 0.0903,
      "step": 2813
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27572745084762573,
      "learning_rate": 7.564210526315791e-05,
      "loss": 0.0802,
      "step": 2814
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25827234983444214,
      "learning_rate": 7.563157894736842e-05,
      "loss": 0.0666,
      "step": 2815
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30938801169395447,
      "learning_rate": 7.562105263157895e-05,
      "loss": 0.0932,
      "step": 2816
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24436283111572266,
      "learning_rate": 7.561052631578947e-05,
      "loss": 0.0498,
      "step": 2817
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27731072902679443,
      "learning_rate": 7.560000000000001e-05,
      "loss": 0.0964,
      "step": 2818
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24037393927574158,
      "learning_rate": 7.558947368421053e-05,
      "loss": 0.0518,
      "step": 2819
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30719485878944397,
      "learning_rate": 7.557894736842106e-05,
      "loss": 0.1109,
      "step": 2820
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.29934582114219666,
      "learning_rate": 7.556842105263158e-05,
      "loss": 0.0833,
      "step": 2821
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.32399868965148926,
      "learning_rate": 7.55578947368421e-05,
      "loss": 0.0861,
      "step": 2822
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3274279832839966,
      "learning_rate": 7.554736842105263e-05,
      "loss": 0.1032,
      "step": 2823
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2508911192417145,
      "learning_rate": 7.553684210526316e-05,
      "loss": 0.0726,
      "step": 2824
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27204474806785583,
      "learning_rate": 7.55263157894737e-05,
      "loss": 0.0673,
      "step": 2825
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27843785285949707,
      "learning_rate": 7.551578947368422e-05,
      "loss": 0.0738,
      "step": 2826
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.28376448154449463,
      "learning_rate": 7.550526315789474e-05,
      "loss": 0.0553,
      "step": 2827
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.33749234676361084,
      "learning_rate": 7.549473684210527e-05,
      "loss": 0.1049,
      "step": 2828
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.26333820819854736,
      "learning_rate": 7.548421052631579e-05,
      "loss": 0.0524,
      "step": 2829
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2765999734401703,
      "learning_rate": 7.547368421052632e-05,
      "loss": 0.0738,
      "step": 2830
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.26060250401496887,
      "learning_rate": 7.546315789473684e-05,
      "loss": 0.0798,
      "step": 2831
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3087066411972046,
      "learning_rate": 7.545263157894738e-05,
      "loss": 0.1216,
      "step": 2832
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.31708207726478577,
      "learning_rate": 7.54421052631579e-05,
      "loss": 0.0677,
      "step": 2833
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30025556683540344,
      "learning_rate": 7.543157894736842e-05,
      "loss": 0.0903,
      "step": 2834
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2775934338569641,
      "learning_rate": 7.542105263157895e-05,
      "loss": 0.0631,
      "step": 2835
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2725174129009247,
      "learning_rate": 7.541052631578948e-05,
      "loss": 0.0541,
      "step": 2836
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3202504813671112,
      "learning_rate": 7.54e-05,
      "loss": 0.0999,
      "step": 2837
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2725295424461365,
      "learning_rate": 7.538947368421053e-05,
      "loss": 0.0763,
      "step": 2838
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3111588656902313,
      "learning_rate": 7.537894736842107e-05,
      "loss": 0.1085,
      "step": 2839
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.31566718220710754,
      "learning_rate": 7.536842105263158e-05,
      "loss": 0.0638,
      "step": 2840
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.33620914816856384,
      "learning_rate": 7.53578947368421e-05,
      "loss": 0.0565,
      "step": 2841
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.23500292003154755,
      "learning_rate": 7.534736842105264e-05,
      "loss": 0.0407,
      "step": 2842
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2717229425907135,
      "learning_rate": 7.533684210526316e-05,
      "loss": 0.0451,
      "step": 2843
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2885723412036896,
      "learning_rate": 7.532631578947369e-05,
      "loss": 0.0648,
      "step": 2844
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2261120229959488,
      "learning_rate": 7.531578947368421e-05,
      "loss": 0.0515,
      "step": 2845
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.325898677110672,
      "learning_rate": 7.530526315789475e-05,
      "loss": 0.0774,
      "step": 2846
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.27444222569465637,
      "learning_rate": 7.529473684210526e-05,
      "loss": 0.052,
      "step": 2847
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2187272608280182,
      "learning_rate": 7.528421052631579e-05,
      "loss": 0.0502,
      "step": 2848
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.29850709438323975,
      "learning_rate": 7.527368421052631e-05,
      "loss": 0.0526,
      "step": 2849
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24165357649326324,
      "learning_rate": 7.526315789473685e-05,
      "loss": 0.0548,
      "step": 2850
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24152888357639313,
      "learning_rate": 7.525263157894738e-05,
      "loss": 0.0701,
      "step": 2851
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.28577911853790283,
      "learning_rate": 7.52421052631579e-05,
      "loss": 0.0553,
      "step": 2852
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24227005243301392,
      "learning_rate": 7.523157894736842e-05,
      "loss": 0.063,
      "step": 2853
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.269118070602417,
      "learning_rate": 7.522105263157895e-05,
      "loss": 0.0656,
      "step": 2854
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24540108442306519,
      "learning_rate": 7.521052631578947e-05,
      "loss": 0.0839,
      "step": 2855
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25665003061294556,
      "learning_rate": 7.52e-05,
      "loss": 0.0389,
      "step": 2856
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2796580195426941,
      "learning_rate": 7.518947368421054e-05,
      "loss": 0.057,
      "step": 2857
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.36809873580932617,
      "learning_rate": 7.517894736842106e-05,
      "loss": 0.0875,
      "step": 2858
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.29761946201324463,
      "learning_rate": 7.516842105263159e-05,
      "loss": 0.0663,
      "step": 2859
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2199205905199051,
      "learning_rate": 7.515789473684211e-05,
      "loss": 0.0495,
      "step": 2860
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3491288423538208,
      "learning_rate": 7.514736842105264e-05,
      "loss": 0.08,
      "step": 2861
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2927956283092499,
      "learning_rate": 7.513684210526316e-05,
      "loss": 0.0799,
      "step": 2862
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2982194423675537,
      "learning_rate": 7.512631578947368e-05,
      "loss": 0.076,
      "step": 2863
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.24860289692878723,
      "learning_rate": 7.511578947368422e-05,
      "loss": 0.0583,
      "step": 2864
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2846025824546814,
      "learning_rate": 7.510526315789475e-05,
      "loss": 0.083,
      "step": 2865
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.30386194586753845,
      "learning_rate": 7.509473684210526e-05,
      "loss": 0.081,
      "step": 2866
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.25469112396240234,
      "learning_rate": 7.50842105263158e-05,
      "loss": 0.0749,
      "step": 2867
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3135415017604828,
      "learning_rate": 7.507368421052632e-05,
      "loss": 0.0453,
      "step": 2868
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.26680299639701843,
      "learning_rate": 7.506315789473685e-05,
      "loss": 0.0706,
      "step": 2869
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.28473472595214844,
      "learning_rate": 7.505263157894737e-05,
      "loss": 0.0684,
      "step": 2870
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.2751244902610779,
      "learning_rate": 7.504210526315791e-05,
      "loss": 0.0806,
      "step": 2871
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3536490499973297,
      "learning_rate": 7.503157894736842e-05,
      "loss": 0.1112,
      "step": 2872
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.3219967484474182,
      "learning_rate": 7.502105263157894e-05,
      "loss": 0.0872,
      "step": 2873
    },
    {
      "epoch": 10.01,
      "grad_norm": 0.29078662395477295,
      "learning_rate": 7.501052631578947e-05,
      "loss": 0.0543,
      "step": 2874
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2347051352262497,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0464,
      "step": 2875
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.32059845328330994,
      "learning_rate": 7.498947368421053e-05,
      "loss": 0.1145,
      "step": 2876
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26520758867263794,
      "learning_rate": 7.497894736842106e-05,
      "loss": 0.054,
      "step": 2877
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.33704426884651184,
      "learning_rate": 7.49684210526316e-05,
      "loss": 0.0486,
      "step": 2878
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2815496325492859,
      "learning_rate": 7.49578947368421e-05,
      "loss": 0.0481,
      "step": 2879
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.29295533895492554,
      "learning_rate": 7.494736842105263e-05,
      "loss": 0.081,
      "step": 2880
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27387693524360657,
      "learning_rate": 7.493684210526315e-05,
      "loss": 0.0875,
      "step": 2881
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.30238914489746094,
      "learning_rate": 7.492631578947369e-05,
      "loss": 0.0515,
      "step": 2882
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.33327972888946533,
      "learning_rate": 7.491578947368422e-05,
      "loss": 0.0955,
      "step": 2883
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3176220655441284,
      "learning_rate": 7.490526315789474e-05,
      "loss": 0.0641,
      "step": 2884
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.270193874835968,
      "learning_rate": 7.489473684210527e-05,
      "loss": 0.0789,
      "step": 2885
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2781490683555603,
      "learning_rate": 7.488421052631579e-05,
      "loss": 0.0847,
      "step": 2886
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24932822585105896,
      "learning_rate": 7.487368421052632e-05,
      "loss": 0.0555,
      "step": 2887
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24500137567520142,
      "learning_rate": 7.486315789473684e-05,
      "loss": 0.057,
      "step": 2888
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.32320213317871094,
      "learning_rate": 7.485263157894738e-05,
      "loss": 0.0571,
      "step": 2889
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2805314064025879,
      "learning_rate": 7.48421052631579e-05,
      "loss": 0.0688,
      "step": 2890
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.363312304019928,
      "learning_rate": 7.483157894736841e-05,
      "loss": 0.0851,
      "step": 2891
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24649682641029358,
      "learning_rate": 7.482105263157895e-05,
      "loss": 0.0632,
      "step": 2892
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2727869153022766,
      "learning_rate": 7.481052631578948e-05,
      "loss": 0.0401,
      "step": 2893
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27729102969169617,
      "learning_rate": 7.48e-05,
      "loss": 0.0535,
      "step": 2894
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.25392386317253113,
      "learning_rate": 7.478947368421053e-05,
      "loss": 0.0584,
      "step": 2895
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.371282160282135,
      "learning_rate": 7.477894736842106e-05,
      "loss": 0.1062,
      "step": 2896
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3015702962875366,
      "learning_rate": 7.476842105263159e-05,
      "loss": 0.0633,
      "step": 2897
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2877693474292755,
      "learning_rate": 7.47578947368421e-05,
      "loss": 0.071,
      "step": 2898
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2581121325492859,
      "learning_rate": 7.474736842105264e-05,
      "loss": 0.0774,
      "step": 2899
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24546769261360168,
      "learning_rate": 7.473684210526316e-05,
      "loss": 0.0686,
      "step": 2900
    },
    {
      "epoch": 10.02,
      "eval_loss": 0.10933523625135422,
      "eval_runtime": 834.6971,
      "eval_samples_per_second": 2.983,
      "eval_steps_per_second": 0.047,
      "eval_wer": 7.9775631037706445,
      "step": 2900
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26826217770576477,
      "learning_rate": 7.472631578947369e-05,
      "loss": 0.0781,
      "step": 2901
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2892274558544159,
      "learning_rate": 7.471578947368421e-05,
      "loss": 0.0866,
      "step": 2902
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3091752529144287,
      "learning_rate": 7.470526315789475e-05,
      "loss": 0.0837,
      "step": 2903
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28468090295791626,
      "learning_rate": 7.469473684210526e-05,
      "loss": 0.0537,
      "step": 2904
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2989676296710968,
      "learning_rate": 7.468421052631579e-05,
      "loss": 0.0868,
      "step": 2905
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.23224851489067078,
      "learning_rate": 7.467368421052631e-05,
      "loss": 0.0454,
      "step": 2906
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3109566271305084,
      "learning_rate": 7.466315789473685e-05,
      "loss": 0.0794,
      "step": 2907
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.260219007730484,
      "learning_rate": 7.465263157894737e-05,
      "loss": 0.0615,
      "step": 2908
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2527804970741272,
      "learning_rate": 7.46421052631579e-05,
      "loss": 0.0578,
      "step": 2909
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.326095312833786,
      "learning_rate": 7.463157894736844e-05,
      "loss": 0.1147,
      "step": 2910
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.4620349705219269,
      "learning_rate": 7.462105263157895e-05,
      "loss": 0.0816,
      "step": 2911
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.320684552192688,
      "learning_rate": 7.461052631578947e-05,
      "loss": 0.0916,
      "step": 2912
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28049978613853455,
      "learning_rate": 7.46e-05,
      "loss": 0.0717,
      "step": 2913
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.21068075299263,
      "learning_rate": 7.458947368421054e-05,
      "loss": 0.0433,
      "step": 2914
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26350027322769165,
      "learning_rate": 7.457894736842106e-05,
      "loss": 0.0567,
      "step": 2915
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.18903973698616028,
      "learning_rate": 7.456842105263158e-05,
      "loss": 0.0378,
      "step": 2916
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28254470229148865,
      "learning_rate": 7.455789473684211e-05,
      "loss": 0.056,
      "step": 2917
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2541348338127136,
      "learning_rate": 7.454736842105263e-05,
      "loss": 0.0385,
      "step": 2918
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2540118992328644,
      "learning_rate": 7.453684210526316e-05,
      "loss": 0.0812,
      "step": 2919
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26130515336990356,
      "learning_rate": 7.452631578947368e-05,
      "loss": 0.0416,
      "step": 2920
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2885594367980957,
      "learning_rate": 7.451578947368422e-05,
      "loss": 0.0701,
      "step": 2921
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27135828137397766,
      "learning_rate": 7.450526315789475e-05,
      "loss": 0.0582,
      "step": 2922
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28271767497062683,
      "learning_rate": 7.449473684210526e-05,
      "loss": 0.0832,
      "step": 2923
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27394118905067444,
      "learning_rate": 7.44842105263158e-05,
      "loss": 0.0672,
      "step": 2924
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2473239302635193,
      "learning_rate": 7.447368421052632e-05,
      "loss": 0.0534,
      "step": 2925
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.22852188348770142,
      "learning_rate": 7.446315789473684e-05,
      "loss": 0.052,
      "step": 2926
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2776294946670532,
      "learning_rate": 7.445263157894737e-05,
      "loss": 0.0836,
      "step": 2927
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.29941073060035706,
      "learning_rate": 7.444210526315791e-05,
      "loss": 0.0859,
      "step": 2928
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3097158372402191,
      "learning_rate": 7.443157894736843e-05,
      "loss": 0.0852,
      "step": 2929
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2618526220321655,
      "learning_rate": 7.442105263157894e-05,
      "loss": 0.06,
      "step": 2930
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24169448018074036,
      "learning_rate": 7.441052631578948e-05,
      "loss": 0.051,
      "step": 2931
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.25210610032081604,
      "learning_rate": 7.44e-05,
      "loss": 0.0419,
      "step": 2932
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28950080275535583,
      "learning_rate": 7.438947368421053e-05,
      "loss": 0.0724,
      "step": 2933
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2797415554523468,
      "learning_rate": 7.437894736842106e-05,
      "loss": 0.0696,
      "step": 2934
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.31560736894607544,
      "learning_rate": 7.43684210526316e-05,
      "loss": 0.0799,
      "step": 2935
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26829713582992554,
      "learning_rate": 7.43578947368421e-05,
      "loss": 0.061,
      "step": 2936
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2952216565608978,
      "learning_rate": 7.434736842105263e-05,
      "loss": 0.0789,
      "step": 2937
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.23584136366844177,
      "learning_rate": 7.433684210526315e-05,
      "loss": 0.0561,
      "step": 2938
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27077752351760864,
      "learning_rate": 7.432631578947369e-05,
      "loss": 0.064,
      "step": 2939
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.27992093563079834,
      "learning_rate": 7.431578947368422e-05,
      "loss": 0.0523,
      "step": 2940
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.28209248185157776,
      "learning_rate": 7.430526315789474e-05,
      "loss": 0.0815,
      "step": 2941
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.285137802362442,
      "learning_rate": 7.429473684210527e-05,
      "loss": 0.0742,
      "step": 2942
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24344223737716675,
      "learning_rate": 7.428421052631579e-05,
      "loss": 0.0441,
      "step": 2943
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2914360761642456,
      "learning_rate": 7.427368421052632e-05,
      "loss": 0.0748,
      "step": 2944
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.25459352135658264,
      "learning_rate": 7.426315789473684e-05,
      "loss": 0.0596,
      "step": 2945
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.26384395360946655,
      "learning_rate": 7.425263157894738e-05,
      "loss": 0.0686,
      "step": 2946
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2980601191520691,
      "learning_rate": 7.42421052631579e-05,
      "loss": 0.0864,
      "step": 2947
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2998605966567993,
      "learning_rate": 7.423157894736843e-05,
      "loss": 0.0893,
      "step": 2948
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24699480831623077,
      "learning_rate": 7.422105263157895e-05,
      "loss": 0.0592,
      "step": 2949
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.24887557327747345,
      "learning_rate": 7.421052631578948e-05,
      "loss": 0.055,
      "step": 2950
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.23047786951065063,
      "learning_rate": 7.42e-05,
      "loss": 0.0492,
      "step": 2951
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2604377567768097,
      "learning_rate": 7.418947368421053e-05,
      "loss": 0.0588,
      "step": 2952
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3267768919467926,
      "learning_rate": 7.417894736842106e-05,
      "loss": 0.0794,
      "step": 2953
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.37562474608421326,
      "learning_rate": 7.416842105263159e-05,
      "loss": 0.1019,
      "step": 2954
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2888185381889343,
      "learning_rate": 7.41578947368421e-05,
      "loss": 0.0491,
      "step": 2955
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.268076092004776,
      "learning_rate": 7.414736842105264e-05,
      "loss": 0.0549,
      "step": 2956
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.336709588766098,
      "learning_rate": 7.413684210526316e-05,
      "loss": 0.0848,
      "step": 2957
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2970658838748932,
      "learning_rate": 7.412631578947369e-05,
      "loss": 0.0659,
      "step": 2958
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.3057571053504944,
      "learning_rate": 7.411578947368421e-05,
      "loss": 0.0839,
      "step": 2959
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2136756032705307,
      "learning_rate": 7.410526315789475e-05,
      "loss": 0.0423,
      "step": 2960
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2960433065891266,
      "learning_rate": 7.409473684210526e-05,
      "loss": 0.0712,
      "step": 2961
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.29935139417648315,
      "learning_rate": 7.408421052631579e-05,
      "loss": 0.1095,
      "step": 2962
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.25741180777549744,
      "learning_rate": 7.407368421052632e-05,
      "loss": 0.0711,
      "step": 2963
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2921000123023987,
      "learning_rate": 7.406315789473685e-05,
      "loss": 0.0622,
      "step": 2964
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2755638659000397,
      "learning_rate": 7.405263157894737e-05,
      "loss": 0.0653,
      "step": 2965
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.21148210763931274,
      "learning_rate": 7.40421052631579e-05,
      "loss": 0.0453,
      "step": 2966
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.269296258687973,
      "learning_rate": 7.403157894736844e-05,
      "loss": 0.0534,
      "step": 2967
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.255702942609787,
      "learning_rate": 7.402105263157895e-05,
      "loss": 0.0639,
      "step": 2968
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.30426716804504395,
      "learning_rate": 7.401052631578947e-05,
      "loss": 0.0767,
      "step": 2969
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.23374496400356293,
      "learning_rate": 7.4e-05,
      "loss": 0.0545,
      "step": 2970
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2716537415981293,
      "learning_rate": 7.398947368421053e-05,
      "loss": 0.0619,
      "step": 2971
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.22342869639396667,
      "learning_rate": 7.397894736842106e-05,
      "loss": 0.0594,
      "step": 2972
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.2862579822540283,
      "learning_rate": 7.396842105263158e-05,
      "loss": 0.065,
      "step": 2973
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.23925204575061798,
      "learning_rate": 7.395789473684211e-05,
      "loss": 0.0516,
      "step": 2974
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.2371741086244583,
      "learning_rate": 7.394736842105263e-05,
      "loss": 0.0473,
      "step": 2975
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.24833542108535767,
      "learning_rate": 7.393684210526316e-05,
      "loss": 0.0561,
      "step": 2976
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.3502005636692047,
      "learning_rate": 7.392631578947368e-05,
      "loss": 0.0991,
      "step": 2977
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.23958222568035126,
      "learning_rate": 7.391578947368422e-05,
      "loss": 0.0588,
      "step": 2978
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.28486669063568115,
      "learning_rate": 7.390526315789475e-05,
      "loss": 0.0814,
      "step": 2979
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.2508782148361206,
      "learning_rate": 7.389473684210527e-05,
      "loss": 0.048,
      "step": 2980
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.20688851177692413,
      "learning_rate": 7.38842105263158e-05,
      "loss": 0.0476,
      "step": 2981
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.256625235080719,
      "learning_rate": 7.387368421052632e-05,
      "loss": 0.0656,
      "step": 2982
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.27489542961120605,
      "learning_rate": 7.386315789473684e-05,
      "loss": 0.0606,
      "step": 2983
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.27223122119903564,
      "learning_rate": 7.385263157894737e-05,
      "loss": 0.0598,
      "step": 2984
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.30290329456329346,
      "learning_rate": 7.38421052631579e-05,
      "loss": 0.0655,
      "step": 2985
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.3008803427219391,
      "learning_rate": 7.383157894736843e-05,
      "loss": 0.0753,
      "step": 2986
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.23726728558540344,
      "learning_rate": 7.382105263157894e-05,
      "loss": 0.0592,
      "step": 2987
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.2849024534225464,
      "learning_rate": 7.381052631578948e-05,
      "loss": 0.07,
      "step": 2988
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.2840595245361328,
      "learning_rate": 7.38e-05,
      "loss": 0.0612,
      "step": 2989
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.256687194108963,
      "learning_rate": 7.378947368421053e-05,
      "loss": 0.0688,
      "step": 2990
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.30057376623153687,
      "learning_rate": 7.377894736842105e-05,
      "loss": 0.0722,
      "step": 2991
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.32499492168426514,
      "learning_rate": 7.376842105263159e-05,
      "loss": 0.0526,
      "step": 2992
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.3101641833782196,
      "learning_rate": 7.37578947368421e-05,
      "loss": 0.0536,
      "step": 2993
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.27726688981056213,
      "learning_rate": 7.374736842105263e-05,
      "loss": 0.0641,
      "step": 2994
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.28931909799575806,
      "learning_rate": 7.373684210526317e-05,
      "loss": 0.0802,
      "step": 2995
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.24299411475658417,
      "learning_rate": 7.372631578947369e-05,
      "loss": 0.0651,
      "step": 2996
    },
    {
      "epoch": 10.03,
      "grad_norm": 0.3498060405254364,
      "learning_rate": 7.371578947368422e-05,
      "loss": 0.0637,
      "step": 2997
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.28334060311317444,
      "learning_rate": 7.370526315789474e-05,
      "loss": 0.042,
      "step": 2998
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.1918027549982071,
      "learning_rate": 7.369473684210528e-05,
      "loss": 0.0488,
      "step": 2999
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.2512742280960083,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.0602,
      "step": 3000
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.10731397569179535,
      "eval_runtime": 810.6431,
      "eval_samples_per_second": 3.072,
      "eval_steps_per_second": 0.048,
      "eval_wer": 7.572452477407292,
      "step": 3000
    }
  ],
  "logging_steps": 1,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100,
  "total_flos": 7.8889603608576e+20,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
